CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config/seqcla.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data RunDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config OutputDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu DeviceId=-1 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug  4 2016 13:05:36
		Last modified date: Thu Aug  4 12:33:33 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
		Built by philly on 643085f7f8c2
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
08/04/2016 13:56:55: -------------------------------------------------------------------
08/04/2016 13:56:55: Build info: 

08/04/2016 13:56:55: 		Built time: Aug  4 2016 13:05:36
08/04/2016 13:56:55: 		Last modified date: Thu Aug  4 12:33:33 2016
08/04/2016 13:56:55: 		Build type: release
08/04/2016 13:56:55: 		Build target: GPU
08/04/2016 13:56:55: 		With 1bit-SGD: no
08/04/2016 13:56:55: 		Math lib: mkl
08/04/2016 13:56:55: 		CUDA_PATH: /usr/local/cuda-7.5
08/04/2016 13:56:55: 		CUB_PATH: /usr/local/cub-1.4.1
08/04/2016 13:56:55: 		CUDNN_PATH: /usr/local/cudnn-4.0
08/04/2016 13:56:55: 		Build Branch: HEAD
08/04/2016 13:56:55: 		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
08/04/2016 13:56:55: 		Built by philly on 643085f7f8c2
08/04/2016 13:56:55: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
08/04/2016 13:56:55: -------------------------------------------------------------------
08/04/2016 13:56:56: -------------------------------------------------------------------
08/04/2016 13:56:56: GPU info:

08/04/2016 13:56:56: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:56:56: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:56:56: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:56:56: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:56:56: -------------------------------------------------------------------

08/04/2016 13:56:56: Running on localhost at 2016/08/04 13:56:56
08/04/2016 13:56:56: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config/seqcla.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data  RunDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config  OutputDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu  DeviceId=-1  timestamping=true



08/04/2016 13:56:56: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/04/2016 13:56:56: RootDir = ".."
ConfigDir = "$RootDir$/Config"
DataDir   = "$RootDir$/Data"
OutputDir = "$RootDir$/Output"
ModelDir  = "$OutputDir$/Models"
command=Train 
deviceId = $DeviceId$
modelPath="$ModelDir$/seqcla.dnn"
Train=[
    action="train"
    run=BrainScriptNetworkBuilder
    BrainScriptNetworkBuilder=[
        Layers = [
            EmbeddingLayer(input, vocabSize, embeddingDim, embeddingPath) = [
                embedding = Transpose(LearnableParameter(vocabSize, embeddingDim, learningRateMultiplier = 0.0, init = 'fromFile', initFromFilePath = embeddingPath))          
                lookup = GatherPacked(features, embedding)
            ].lookup
            DenseLayer(input, inputSize, outputSize, activation) = [
               z = BFF(input, outputSize, inputSize).z
               act = activation(z)
            ].act
            LSTMLayer (input, inputSize, outputSize, cellSize, selector) = [ 
               lstm = BS.RNNs.RecurrentLSTMP (outputSize, cellDim=cellSize, input, inputDim=inputSize).h
               result = selector(lstm)
            ].result
        ]        
        // LSTM params
        lstmDim = 25
        cellDim = 25
        // model
        numLabels = 5        
        vocab = 2000
        embedDim = 50        
        // set up features and labels
        t = DynamicAxis()
features = Input(1, dynamicAxis=t)   
labels   = Input(numLabels)          
        // load the pre-learned word embedding matrix
        l1 = Layers.EmbeddingLayer(features, vocab, embedDim, 'embeddingmatrix.txt')
        l2 = Layers.LSTMLayer(l1, embedDim, lstmDim, cellDim, BS.Sequences.Last)
        l3 = Layers.DenseLayer(l2, lstmDim, numLabels, Pass)
        out = Pass(l3, tag='output')   
        // Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        l3p = ReconcileDynamicAxis(l3, labels)
        // training criteria
        ce  = CrossEntropyWithSoftmax(labels, l3p, tag='criterion')   // this is the training objective
        err = ErrorPrediction        (labels, l3p, tag='evaluation')  // this also gets tracked
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Train.txt"            
        input = [            
            features=[
                alias = "x"                
                dim = 1               
                format = "dense"
            ]
            labels=[
                alias = "y"                
                dim = 5           
                format = "dense"
            ]
        ]
   ]    
outputPath = "$OutputDir$/output.txt"        
]
Write=[
    action="test"
    run=BrainScriptNetworkBuilder
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    modelFile = "$ModelDir$/seqcla.dnn"    
    reader = [
            readerType = "CNTKTextFormatReader"
            file = "$DataDir$/Train.txt"            
            input = [            
                features=[
                    alias = "x"                
                    dim = 1               
                    format = "dense"
                ]
                labels=[
                    alias = "y"                
                    dim = 5           
                    format = "dense"
                ]
            ]
   ]    
outputPath = "$OutputDir$/output.txt"        
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
RunDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config
OutputDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu
DeviceId=-1
timestamping=true

08/04/2016 13:56:56: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/04/2016 13:56:56: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/04/2016 13:56:56: RootDir = ".."
ConfigDir = "../Config"
DataDir   = "../Data"
OutputDir = "../Output"
ModelDir  = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models"
command=Train 
deviceId = -1
modelPath="/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn"
Train=[
    action="train"
    run=BrainScriptNetworkBuilder
    BrainScriptNetworkBuilder=[
        Layers = [
            EmbeddingLayer(input, vocabSize, embeddingDim, embeddingPath) = [
                embedding = Transpose(LearnableParameter(vocabSize, embeddingDim, learningRateMultiplier = 0.0, init = 'fromFile', initFromFilePath = embeddingPath))          
                lookup = GatherPacked(features, embedding)
            ].lookup
            DenseLayer(input, inputSize, outputSize, activation) = [
               z = BFF(input, outputSize, inputSize).z
               act = activation(z)
            ].act
            LSTMLayer (input, inputSize, outputSize, cellSize, selector) = [ 
               lstm = BS.RNNs.RecurrentLSTMP (outputSize, cellDim=cellSize, input, inputDim=inputSize).h
               result = selector(lstm)
            ].result
        ]        
        // LSTM params
        lstmDim = 25
        cellDim = 25
        // model
        numLabels = 5        
        vocab = 2000
        embedDim = 50        
        // set up features and labels
        t = DynamicAxis()
features = Input(1, dynamicAxis=t)   
labels   = Input(numLabels)          
        // load the pre-learned word embedding matrix
        l1 = Layers.EmbeddingLayer(features, vocab, embedDim, 'embeddingmatrix.txt')
        l2 = Layers.LSTMLayer(l1, embedDim, lstmDim, cellDim, BS.Sequences.Last)
        l3 = Layers.DenseLayer(l2, lstmDim, numLabels, Pass)
        out = Pass(l3, tag='output')   
        // Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        l3p = ReconcileDynamicAxis(l3, labels)
        // training criteria
        ce  = CrossEntropyWithSoftmax(labels, l3p, tag='criterion')   // this is the training objective
        err = ErrorPrediction        (labels, l3p, tag='evaluation')  // this also gets tracked
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data/Train.txt"            
        input = [            
            features=[
                alias = "x"                
                dim = 1               
                format = "dense"
            ]
            labels=[
                alias = "y"                
                dim = 5           
                format = "dense"
            ]
        ]
   ]    
outputPath = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/output.txt"        
]
Write=[
    action="test"
    run=BrainScriptNetworkBuilder
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    modelFile = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn"    
    reader = [
            readerType = "CNTKTextFormatReader"
            file = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data/Train.txt"            
            input = [            
                features=[
                    alias = "x"                
                    dim = 1               
                    format = "dense"
                ]
                labels=[
                    alias = "y"                
                    dim = 5           
                    format = "dense"
                ]
            ]
   ]    
outputPath = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/output.txt"        
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
RunDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config
OutputDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu
DeviceId=-1
timestamping=true

08/04/2016 13:56:56: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/04/2016 13:56:56: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: seqcla.cntk:command=Train
configparameters: seqcla.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config
configparameters: seqcla.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
configparameters: seqcla.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
configparameters: seqcla.cntk:deviceId=-1
configparameters: seqcla.cntk:ModelDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models
configparameters: seqcla.cntk:modelPath=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn
configparameters: seqcla.cntk:OutputDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu
configparameters: seqcla.cntk:RootDir=..
configparameters: seqcla.cntk:RunDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu
configparameters: seqcla.cntk:timestamping=true
configparameters: seqcla.cntk:Train=[
    action="train"
    run=BrainScriptNetworkBuilder
    BrainScriptNetworkBuilder=[
        Layers = [
            EmbeddingLayer(input, vocabSize, embeddingDim, embeddingPath) = [
                embedding = Transpose(LearnableParameter(vocabSize, embeddingDim, learningRateMultiplier = 0.0, init = 'fromFile', initFromFilePath = embeddingPath))          
                lookup = GatherPacked(features, embedding)
            ].lookup
            DenseLayer(input, inputSize, outputSize, activation) = [
               z = BFF(input, outputSize, inputSize).z
               act = activation(z)
            ].act
            LSTMLayer (input, inputSize, outputSize, cellSize, selector) = [ 
               lstm = BS.RNNs.RecurrentLSTMP (outputSize, cellDim=cellSize, input, inputDim=inputSize).h
               result = selector(lstm)
            ].result
        ]        
        // LSTM params
        lstmDim = 25
        cellDim = 25
        // model
        numLabels = 5        
        vocab = 2000
        embedDim = 50        
        // set up features and labels
        t = DynamicAxis()
features = Input(1, dynamicAxis=t)   
labels   = Input(numLabels)          
        // load the pre-learned word embedding matrix
        l1 = Layers.EmbeddingLayer(features, vocab, embedDim, 'embeddingmatrix.txt')
        l2 = Layers.LSTMLayer(l1, embedDim, lstmDim, cellDim, BS.Sequences.Last)
        l3 = Layers.DenseLayer(l2, lstmDim, numLabels, Pass)
        out = Pass(l3, tag='output')   
        // Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        l3p = ReconcileDynamicAxis(l3, labels)
        // training criteria
        ce  = CrossEntropyWithSoftmax(labels, l3p, tag='criterion')   // this is the training objective
        err = ErrorPrediction        (labels, l3p, tag='evaluation')  // this also gets tracked
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data/Train.txt"            
        input = [            
            features=[
                alias = "x"                
                dim = 1               
                format = "dense"
            ]
            labels=[
                alias = "y"                
                dim = 5           
                format = "dense"
            ]
        ]
   ]    
outputPath = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/output.txt"        
]

configparameters: seqcla.cntk:Write=[
    action="test"
    run=BrainScriptNetworkBuilder
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    modelFile = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn"    
    reader = [
            readerType = "CNTKTextFormatReader"
            file = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data/Train.txt"            
            input = [            
                features=[
                    alias = "x"                
                    dim = 1               
                    format = "dense"
                ]
                labels=[
                    alias = "y"                
                    dim = 5           
                    format = "dense"
                ]
            ]
   ]    
outputPath = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/output.txt"        
]

08/04/2016 13:56:56: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/04/2016 13:56:56: Commands: Train
08/04/2016 13:56:56: Precision = "float"
08/04/2016 13:56:56: CNTKModelPath: /tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn
08/04/2016 13:56:56: CNTKCommandTrainInfo: Train : 5
08/04/2016 13:56:56: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5

08/04/2016 13:56:56: ##############################################################################
08/04/2016 13:56:56: #                                                                            #
08/04/2016 13:56:56: # Action "train"                                                             #
08/04/2016 13:56:56: #                                                                            #
08/04/2016 13:56:56: ##############################################################################

08/04/2016 13:56:56: CNTKCommandTrainBegin: Train

08/04/2016 13:56:56: Creating virgin network.

Post-processing network...

4 roots:
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()
	out = Pass()
	t = DynamicAxis()

Loop[0] --> Loop_l2.lstm.lstmState._privateInnards.ht -> 25 nodes

	l2.lstm.prevState.h	l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1]	l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0]
	l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1]	l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0]	l2.lstm.prevState.c
	l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1]	l2.lstm.lstmState._privateInnards.ft._	l2.lstm.lstmState._privateInnards.ft
	l2.lstm.lstmState._privateInnards.bft	l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1]	l2.lstm.lstmState._privateInnards.it._.PlusArgs[0]
	l2.lstm.lstmState._privateInnards.it._.PlusArgs[1]	l2.lstm.lstmState._privateInnards.it._	l2.lstm.lstmState._privateInnards.it
	l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1]	l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z	l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1]
	l2.lstm.lstmState._privateInnards.bit	l2.lstm.lstmState._privateInnards.ct	l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1]
	l2.lstm.lstmState._privateInnards.ot._	l2.lstm.lstmState._privateInnards.ot	l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1]
	l2.lstm.lstmState._privateInnards.ht

Validating network. 71 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [5 x *]
Validating --> l3.z.W = LearnableParameter() :  -> [5 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> features = InputValue() :  -> [1 x t]
Validating --> l1.embedding.x = LearnableParameter() :  -> [2000 x 50]
Validating --> l1.embedding = TransposeDimensions (l1.embedding.x) : [2000 x 50] -> [50 x 2000]
Validating --> l1.lookup = GatherPacked (features, l1.embedding) : [1 x t], [50 x 2000] -> [50 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1]) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [0] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [0] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [0] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._ = Plus (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0], l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft = Sigmoid (l2.lstm.lstmState._privateInnards.ft._) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bft = ElementTimes (l2.lstm.lstmState._privateInnards.ft, l2.lstm.prevState.c) : [25 x t], [0] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [0] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [0] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._ = Plus (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0], l2.lstm.lstmState._privateInnards.it._.PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it = Sigmoid (l2.lstm.lstmState._privateInnards.it._) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [0] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z = Plus (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0], l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1]) : [25 x t], [25] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1] = Tanh (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bit = ElementTimes (l2.lstm.lstmState._privateInnards.it, l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1]) : [25 x t], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ct = Plus (l2.lstm.lstmState._privateInnards.bft, l2.lstm.lstmState._privateInnards.bit) : [25 x t], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.lstmState._privateInnards.ct) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot._ = Plus (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0], l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1]) : [25 x t], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot = Sigmoid (l2.lstm.lstmState._privateInnards.ot._) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1] = Tanh (l2.lstm.lstmState._privateInnards.ct) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ht = ElementTimes (l2.lstm.lstmState._privateInnards.ot, l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1]) : [25 x t], [25 x t] -> [25 x t]
Validating --> l2.result.beginFlags.input.z.ElementTimesArgs[0] = Slice (l2.lstm.lstmState._privateInnards.ht) : [25 x t] -> [1 x t]
Validating --> BS.Constants.Zero = LearnableParameter() :  -> [1]
Validating --> l2.result.beginFlags.input.z = ElementTimes (l2.result.beginFlags.input.z.ElementTimesArgs[0], BS.Constants.Zero) : [1 x t], [1] -> [1 x t]
Validating --> l2.result.beginFlags.input = SumColumnElements (l2.result.beginFlags.input.z) : [1 x t] -> [1 x t]
Validating --> l2.result.beginFlags = FutureValue (l2.result.beginFlags.input) : [1 x t] -> [1 x t]
Validating --> l2.result.out.indexSequence.indexSequence = Where (l2.result.beginFlags) : [1 x t] -> [1 x WhereNodeAxis]
Validating --> l2.result.out.indexSequence = PackedIndex (l2.lstm.lstmState._privateInnards.ht, l2.result.out.indexSequence.indexSequence) : [25 x t], [1 x WhereNodeAxis] -> [1 x WhereNodeAxis]
Validating --> l2.result.out = GatherPacked (l2.result.out.indexSequence, l2.lstm.lstmState._privateInnards.ht) : [1 x WhereNodeAxis], [25 x t] -> [25 x WhereNodeAxis]
Validating --> l3.z.z.PlusArgs[0] = Times (l3.z.W, l2.result.out) : [5 x 25], [25 x WhereNodeAxis] -> [5 x WhereNodeAxis]
Validating --> l3.z.B = LearnableParameter() :  -> [5 x 1]
Validating --> l3.z.z = Plus (l3.z.z.PlusArgs[0], l3.z.B) : [5 x WhereNodeAxis], [5 x 1] -> [5 x 1 x WhereNodeAxis]
Validating --> l3.act = Pass (l3.z.z) : [5 x 1 x WhereNodeAxis] -> [5 x 1 x WhereNodeAxis]
Validating --> l3p = ReconcileDynamicAxis (l3.act, labels) : [5 x 1 x WhereNodeAxis], [5 x *] -> [5 x 1 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, l3p) : [5 x *], [5 x 1 x *] -> [1]
Validating --> err = ErrorPrediction (labels, l3p) : [5 x *], [5 x 1 x *] -> [1]
Validating --> out = Pass (l3.act) : [5 x 1 x WhereNodeAxis] -> [5 x 1 x WhereNodeAxis]
Validating --> t = DynamicAxis() :  -> [1 x 1 x t]

Validating network. 49 nodes to process in pass 2.

Validating --> l2.lstm.prevState.h = PastValue (l2.lstm.lstmState._privateInnards.ht) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t] -> [25 x t]
Validating --> l2.lstm.prevState.c = PastValue (l2.lstm.lstmState._privateInnards.ct) : [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [25 x t] -> [25 x t]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t] -> [25 x t]

Validating network. 8 nodes to process in pass 3.


Validating network, final pass.



69 out of 71 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/04/2016 13:56:57: Created model with 71 nodes on CPU.

08/04/2016 13:56:57: Training criterion node(s):
08/04/2016 13:56:57: 	ce = CrossEntropyWithSoftmax

08/04/2016 13:56:57: Evaluation criterion node(s):

08/04/2016 13:56:57: 	err = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[BS.Constants.Zero Gradient[1]] [err Gradient[1]] [features Gradient[1 x t]] [l1.embedding Gradient[50 x 2000]] [l1.embedding.x Gradient[2000 x 50]] [l1.lookup Gradient[50 x t]] [labels Gradient[5 x *]] [out Gradient[5 x 1 x WhereNodeAxis]] [t Gradient[1 x 1 x t]] [t Value[1 x 1 x t]] }
0x7fd23eded898: {[l2.lstm.lstmState._privateInnards.ot._ Gradient[25 x t]] [l2.result.beginFlags Value[1 x t]] [l2.result.beginFlags.input.z Gradient[1 x t]] }
0x7fd23edfd3e8: {[labels Value[5 x *]] }
0x7fd23f702668: {[l3.z.W Value[5 x 25]] }
0x7fd23f7042f8: {[l3.z.B Value[5 x 1]] }
0x7fd23f706428: {[l1.embedding Value[50 x 2000]] }
0x7fd23f706d48: {[l2.result.out.indexSequence Value[1 x WhereNodeAxis]] }
0x7fd23f70a158: {[BS.Constants.Zero Value[1]] }
0x7fd23f70fea8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Value[25]] }
0x7fd23f710be8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
0x7fd23f714ca8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
0x7fd23f716928: {[features Value[1 x t]] }
0x7fd23f718c18: {[err Value[1]] }
0x7fd23f7199b8: {[l1.embedding.x Value[2000 x 50]] }
0x7fd23f71a238: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] Gradient[25]] [l2.lstm.prevState.h Value[25 x t]] }
0x7fd23f71c1c8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0] Value[25]] }
0x7fd23f71c388: {[ce Value[1]] }
0x7fd23f71c688: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
0x7fd23f71d5a8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
0x7fd23f71e0d8: {[out Value[5 x 1 x WhereNodeAxis]] }
0x7fd23f71ece8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Value[25]] }
0x7fd23f722828: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0] Value[25]] }
0x7fd23f7228c8: {[l2.result.out.indexSequence.indexSequence Value[1 x WhereNodeAxis]] }
0x7fd23f723068: {[l2.lstm.prevState.c Value[25 x t]] }
0x7fd23f7256c8: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Value[25]] }
0x7fd23f726418: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
0x7fd23f7289b8: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
0x7fd23f729988: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0] Value[25]] }
0x7fd23f72ac78: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] Value[25]] }
0x7fd23f72ba38: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
0x7fd23f72d8f8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
0x7fd23f735158: {[l1.lookup Value[50 x t]] }
0x7fd23f735408: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0] Value[25 x t]] [l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
0x7fd23f735a48: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Value[25 x t]] }
0x7fd23f735f28: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Value[25 x t]] [l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Gradient[25]] }
0x7fd23f7360e8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0] Value[25 x t]] [l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
0x7fd23f7362a8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Gradient[25]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Value[25 x t]] }
0x7fd23f736c98: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0] Value[25 x t]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
0x7fd23f736df8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] Value[25 x t]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Gradient[25]] }
0x7fd23f736fb8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0] Value[25 x t]] [l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
0x7fd23f737178: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] Value[25 x t]] }
0x7fd23f737338: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0] Value[25 x t]] }
0x7fd23f7374f8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] Value[25 x t]] }
0x7fd23f7376b8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0] Value[25 x t]] }
0x7fd23f737878: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] Value[25 x t]] }
0x7fd23f737a38: {[l2.lstm.lstmState._privateInnards.ft._ Value[25 x t]] }
0x7fd23f737bf8: {[l2.lstm.lstmState._privateInnards.ft Value[25 x t]] }
0x7fd23f737db8: {[l2.lstm.lstmState._privateInnards.bft Value[25 x t]] }
0x7fd23f737f78: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] Value[25 x t]] }
0x7fd23f738138: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0] Value[25 x t]] }
0x7fd23f7382f8: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] Value[25 x t]] }
0x7fd23f7384b8: {[l2.lstm.lstmState._privateInnards.it._ Value[25 x t]] }
0x7fd23f738678: {[l2.lstm.lstmState._privateInnards.it Value[25 x t]] }
0x7fd23f738838: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] Value[25 x t]] }
0x7fd23f7389f8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z Value[25 x t]] }
0x7fd23f738bb8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1] Value[25 x t]] }
0x7fd23f738d78: {[l2.lstm.lstmState._privateInnards.bit Value[25 x t]] }
0x7fd23f738f38: {[l2.lstm.lstmState._privateInnards.ct Value[25 x t]] }
0x7fd23f7390f8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1] Value[25 x t]] }
0x7fd23f7392b8: {[l2.lstm.lstmState._privateInnards.ot._ Value[25 x t]] }
0x7fd23f739478: {[l2.lstm.lstmState._privateInnards.ot Value[25 x t]] }
0x7fd23f739638: {[l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1] Value[25 x t]] }
0x7fd23f7397f8: {[l2.lstm.lstmState._privateInnards.ht Value[25 x t]] }
0x7fd23f7399b8: {[l2.lstm.lstmState._privateInnards.ot Gradient[25 x t]] [l2.result.beginFlags.input.z.ElementTimesArgs[0] Value[1 x t]] }
0x7fd23f739b78: {[l2.lstm.lstmState._privateInnards.ct Gradient[25 x t]] [l2.result.beginFlags.input.z Value[1 x t]] }
0x7fd23f739d38: {[l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1] Gradient[25 x t]] [l2.result.beginFlags.input Value[1 x t]] [l2.result.beginFlags.input.z.ElementTimesArgs[0] Gradient[1 x t]] }
0x7fd23f739ef8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0] Gradient[25 x t]] [l2.result.beginFlags.input Gradient[1 x t]] [l2.result.out Value[25 x WhereNodeAxis]] [l2.result.out.indexSequence.indexSequence Gradient[1 x WhereNodeAxis]] }
0x7fd23f73a0b8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1] Gradient[25 x t]] [l2.result.beginFlags Gradient[1 x t]] [l2.result.out.indexSequence Gradient[1 x WhereNodeAxis]] [l3.z.z.PlusArgs[0] Value[5 x WhereNodeAxis]] }
0x7fd23f73a278: {[l3.z.W Gradient[5 x 25]] [l3.z.z Value[5 x 1 x WhereNodeAxis]] }
0x7fd23f73a438: {[l2.lstm.lstmState._privateInnards.ht Gradient[25 x t]] [l3.act Value[5 x 1 x WhereNodeAxis]] [l3.z.z.PlusArgs[0] Gradient[5 x WhereNodeAxis]] }
0x7fd23f73a5f8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0] Gradient[25]] [l2.result.out Gradient[25 x WhereNodeAxis]] [l3.z.z Gradient[5 x 1 x WhereNodeAxis]] [l3p Value[5 x 1 x *]] }
0x7fd23f73b078: {[ce Gradient[1]] }
0x7fd23f73b238: {[l2.lstm.lstmState._privateInnards.bft Gradient[25 x t]] [l3p Gradient[5 x 1 x *]] }
0x7fd23f73b3f8: {[l3.act Gradient[5 x 1 x WhereNodeAxis]] [l3.z.B Gradient[5 x 1]] }
0x7fd23f73b708: {[l2.lstm.lstmState._privateInnards.bit Gradient[25 x t]] }
0x7fd23f73b8c8: {[l2.lstm.lstmState._privateInnards.it Gradient[25 x t]] }
0x7fd23f73ba88: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1] Gradient[25 x t]] }
0x7fd23f73bc48: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z Gradient[25 x t]] }
0x7fd23f73be08: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0] Gradient[25 x t]] }
0x7fd23f73bfc8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] Gradient[25 x t]] }
0x7fd23f73c128: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
0x7fd23f73c2e8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] Gradient[25 x t]] [l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Gradient[25 x t]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Gradient[25 x t]] [l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Gradient[25 x t]] [l2.lstm.prevState.h Gradient[25 x t]] }
0x7fd23f73c4a8: {[l2.lstm.lstmState._privateInnards.it._ Gradient[25 x t]] }
0x7fd23f73c668: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0] Gradient[25 x t]] }
0x7fd23f73c828: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] Gradient[25 x t]] }
0x7fd23f73c9e8: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0] Gradient[25]] }
0x7fd23f73cba8: {[l2.lstm.prevState.c Gradient[25 x t]] }
0x7fd23f73cd68: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0] Gradient[25 x t]] }
0x7fd23f73cf28: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] Gradient[25 x t]] }
0x7fd23f73d0e8: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
0x7fd23f73d2a8: {[l2.lstm.lstmState._privateInnards.ft Gradient[25 x t]] }
0x7fd23f73d468: {[l2.lstm.lstmState._privateInnards.ft._ Gradient[25 x t]] }
0x7fd23f73d628: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0] Gradient[25 x t]] }
0x7fd23f73d7e8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] Gradient[25 x t]] }
0x7fd23f73d9a8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0] Gradient[25]] }
0x7fd23f73db68: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0] Gradient[25 x t]] }
0x7fd23f73dd28: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] Gradient[25 x t]] }
0x7fd23f73dee8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
0x7fd23f73e0a8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0] Gradient[25 x t]] }
0x7fd23f73e268: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] Gradient[25 x t]] }
0x7fd23f73e428: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }

08/04/2016 13:56:57: No PreCompute nodes found, skipping PreCompute step.

08/04/2016 13:56:57: Starting Epoch 1: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..5433] (first sequence at sample 0), data subset 0 of 1

08/04/2016 13:56:57: Starting minibatch loop.
08/04/2016 13:56:58: Finished Epoch[ 1 of 5]: [Training] ce = 1.58084334 * 1247; err = 0.49478749 * 1247; totalSamplesSeen = 1247; learningRatePerSample = 0.00050000002; epochTime=1.31651s
08/04/2016 13:56:58: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn.1'

08/04/2016 13:56:58: Starting Epoch 2: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 1: frames [5433..10866] (first sequence at sample 5433), data subset 0 of 1

08/04/2016 13:56:58: Starting minibatch loop.
08/04/2016 13:56:58: Finished Epoch[ 2 of 5]: [Training] ce = 1.49446523 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 2494; learningRatePerSample = 0.00050000002; epochTime=0.557699s
08/04/2016 13:56:58: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn.2'

08/04/2016 13:56:58: Starting Epoch 3: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 2: frames [10866..16299] (first sequence at sample 10866), data subset 0 of 1

08/04/2016 13:56:58: Starting minibatch loop.
08/04/2016 13:56:59: Finished Epoch[ 3 of 5]: [Training] ce = 1.42184377 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 3741; learningRatePerSample = 0.00050000002; epochTime=0.596357s
08/04/2016 13:56:59: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn.3'

08/04/2016 13:56:59: Starting Epoch 4: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 3: frames [16299..21732] (first sequence at sample 16299), data subset 0 of 1

08/04/2016 13:56:59: Starting minibatch loop.
08/04/2016 13:57:00: Finished Epoch[ 4 of 5]: [Training] ce = 1.36949274 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 4988; learningRatePerSample = 0.00050000002; epochTime=0.544771s
08/04/2016 13:57:00: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn.4'

08/04/2016 13:57:00: Starting Epoch 5: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 4: frames [21732..27165] (first sequence at sample 21732), data subset 0 of 1

08/04/2016 13:57:00: Starting minibatch loop.
08/04/2016 13:57:00: Finished Epoch[ 5 of 5]: [Training] ce = 1.33199611 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 6235; learningRatePerSample = 0.00050000002; epochTime=0.571076s
08/04/2016 13:57:00: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn'
08/04/2016 13:57:00: CNTKCommandTrainEnd: Train

08/04/2016 13:57:00: Action "train" complete.

08/04/2016 13:57:00: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config/seqcla.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data RunDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config OutputDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu DeviceId=-1 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug  4 2016 13:05:36
		Last modified date: Thu Aug  4 12:33:33 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
		Built by philly on 643085f7f8c2
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
08/04/2016 13:57:00: -------------------------------------------------------------------
08/04/2016 13:57:00: Build info: 

08/04/2016 13:57:00: 		Built time: Aug  4 2016 13:05:36
08/04/2016 13:57:00: 		Last modified date: Thu Aug  4 12:33:33 2016
08/04/2016 13:57:00: 		Build type: release
08/04/2016 13:57:00: 		Build target: GPU
08/04/2016 13:57:00: 		With 1bit-SGD: no
08/04/2016 13:57:00: 		Math lib: mkl
08/04/2016 13:57:00: 		CUDA_PATH: /usr/local/cuda-7.5
08/04/2016 13:57:00: 		CUB_PATH: /usr/local/cub-1.4.1
08/04/2016 13:57:00: 		CUDNN_PATH: /usr/local/cudnn-4.0
08/04/2016 13:57:00: 		Build Branch: HEAD
08/04/2016 13:57:00: 		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
08/04/2016 13:57:00: 		Built by philly on 643085f7f8c2
08/04/2016 13:57:00: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
08/04/2016 13:57:00: -------------------------------------------------------------------
08/04/2016 13:57:01: -------------------------------------------------------------------
08/04/2016 13:57:01: GPU info:

08/04/2016 13:57:01: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:57:01: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:57:01: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:57:01: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:57:01: -------------------------------------------------------------------

08/04/2016 13:57:01: Running on localhost at 2016/08/04 13:57:01
08/04/2016 13:57:01: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config/seqcla.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data  RunDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config  OutputDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu  DeviceId=-1  timestamping=true  makeMode=true



08/04/2016 13:57:01: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/04/2016 13:57:01: RootDir = ".."
ConfigDir = "$RootDir$/Config"
DataDir   = "$RootDir$/Data"
OutputDir = "$RootDir$/Output"
ModelDir  = "$OutputDir$/Models"
command=Train 
deviceId = $DeviceId$
modelPath="$ModelDir$/seqcla.dnn"
Train=[
    action="train"
    run=BrainScriptNetworkBuilder
    BrainScriptNetworkBuilder=[
        Layers = [
            EmbeddingLayer(input, vocabSize, embeddingDim, embeddingPath) = [
                embedding = Transpose(LearnableParameter(vocabSize, embeddingDim, learningRateMultiplier = 0.0, init = 'fromFile', initFromFilePath = embeddingPath))          
                lookup = GatherPacked(features, embedding)
            ].lookup
            DenseLayer(input, inputSize, outputSize, activation) = [
               z = BFF(input, outputSize, inputSize).z
               act = activation(z)
            ].act
            LSTMLayer (input, inputSize, outputSize, cellSize, selector) = [ 
               lstm = BS.RNNs.RecurrentLSTMP (outputSize, cellDim=cellSize, input, inputDim=inputSize).h
               result = selector(lstm)
            ].result
        ]        
        // LSTM params
        lstmDim = 25
        cellDim = 25
        // model
        numLabels = 5        
        vocab = 2000
        embedDim = 50        
        // set up features and labels
        t = DynamicAxis()
features = Input(1, dynamicAxis=t)   
labels   = Input(numLabels)          
        // load the pre-learned word embedding matrix
        l1 = Layers.EmbeddingLayer(features, vocab, embedDim, 'embeddingmatrix.txt')
        l2 = Layers.LSTMLayer(l1, embedDim, lstmDim, cellDim, BS.Sequences.Last)
        l3 = Layers.DenseLayer(l2, lstmDim, numLabels, Pass)
        out = Pass(l3, tag='output')   
        // Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        l3p = ReconcileDynamicAxis(l3, labels)
        // training criteria
        ce  = CrossEntropyWithSoftmax(labels, l3p, tag='criterion')   // this is the training objective
        err = ErrorPrediction        (labels, l3p, tag='evaluation')  // this also gets tracked
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "$DataDir$/Train.txt"            
        input = [            
            features=[
                alias = "x"                
                dim = 1               
                format = "dense"
            ]
            labels=[
                alias = "y"                
                dim = 5           
                format = "dense"
            ]
        ]
   ]    
outputPath = "$OutputDir$/output.txt"        
]
Write=[
    action="test"
    run=BrainScriptNetworkBuilder
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    modelFile = "$ModelDir$/seqcla.dnn"    
    reader = [
            readerType = "CNTKTextFormatReader"
            file = "$DataDir$/Train.txt"            
            input = [            
                features=[
                    alias = "x"                
                    dim = 1               
                    format = "dense"
                ]
                labels=[
                    alias = "y"                
                    dim = 5           
                    format = "dense"
                ]
            ]
   ]    
outputPath = "$OutputDir$/output.txt"        
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
RunDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config
OutputDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/04/2016 13:57:01: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/04/2016 13:57:01: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/04/2016 13:57:01: RootDir = ".."
ConfigDir = "../Config"
DataDir   = "../Data"
OutputDir = "../Output"
ModelDir  = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models"
command=Train 
deviceId = -1
modelPath="/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn"
Train=[
    action="train"
    run=BrainScriptNetworkBuilder
    BrainScriptNetworkBuilder=[
        Layers = [
            EmbeddingLayer(input, vocabSize, embeddingDim, embeddingPath) = [
                embedding = Transpose(LearnableParameter(vocabSize, embeddingDim, learningRateMultiplier = 0.0, init = 'fromFile', initFromFilePath = embeddingPath))          
                lookup = GatherPacked(features, embedding)
            ].lookup
            DenseLayer(input, inputSize, outputSize, activation) = [
               z = BFF(input, outputSize, inputSize).z
               act = activation(z)
            ].act
            LSTMLayer (input, inputSize, outputSize, cellSize, selector) = [ 
               lstm = BS.RNNs.RecurrentLSTMP (outputSize, cellDim=cellSize, input, inputDim=inputSize).h
               result = selector(lstm)
            ].result
        ]        
        // LSTM params
        lstmDim = 25
        cellDim = 25
        // model
        numLabels = 5        
        vocab = 2000
        embedDim = 50        
        // set up features and labels
        t = DynamicAxis()
features = Input(1, dynamicAxis=t)   
labels   = Input(numLabels)          
        // load the pre-learned word embedding matrix
        l1 = Layers.EmbeddingLayer(features, vocab, embedDim, 'embeddingmatrix.txt')
        l2 = Layers.LSTMLayer(l1, embedDim, lstmDim, cellDim, BS.Sequences.Last)
        l3 = Layers.DenseLayer(l2, lstmDim, numLabels, Pass)
        out = Pass(l3, tag='output')   
        // Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        l3p = ReconcileDynamicAxis(l3, labels)
        // training criteria
        ce  = CrossEntropyWithSoftmax(labels, l3p, tag='criterion')   // this is the training objective
        err = ErrorPrediction        (labels, l3p, tag='evaluation')  // this also gets tracked
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data/Train.txt"            
        input = [            
            features=[
                alias = "x"                
                dim = 1               
                format = "dense"
            ]
            labels=[
                alias = "y"                
                dim = 5           
                format = "dense"
            ]
        ]
   ]    
outputPath = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/output.txt"        
]
Write=[
    action="test"
    run=BrainScriptNetworkBuilder
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    modelFile = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn"    
    reader = [
            readerType = "CNTKTextFormatReader"
            file = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data/Train.txt"            
            input = [            
                features=[
                    alias = "x"                
                    dim = 1               
                    format = "dense"
                ]
                labels=[
                    alias = "y"                
                    dim = 5           
                    format = "dense"
                ]
            ]
   ]    
outputPath = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/output.txt"        
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
RunDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config
OutputDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/04/2016 13:57:01: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/04/2016 13:57:01: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: seqcla.cntk:command=Train
configparameters: seqcla.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Config
configparameters: seqcla.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
configparameters: seqcla.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data
configparameters: seqcla.cntk:deviceId=-1
configparameters: seqcla.cntk:makeMode=true
configparameters: seqcla.cntk:ModelDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models
configparameters: seqcla.cntk:modelPath=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn
configparameters: seqcla.cntk:OutputDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu
configparameters: seqcla.cntk:RootDir=..
configparameters: seqcla.cntk:RunDir=/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu
configparameters: seqcla.cntk:timestamping=true
configparameters: seqcla.cntk:Train=[
    action="train"
    run=BrainScriptNetworkBuilder
    BrainScriptNetworkBuilder=[
        Layers = [
            EmbeddingLayer(input, vocabSize, embeddingDim, embeddingPath) = [
                embedding = Transpose(LearnableParameter(vocabSize, embeddingDim, learningRateMultiplier = 0.0, init = 'fromFile', initFromFilePath = embeddingPath))          
                lookup = GatherPacked(features, embedding)
            ].lookup
            DenseLayer(input, inputSize, outputSize, activation) = [
               z = BFF(input, outputSize, inputSize).z
               act = activation(z)
            ].act
            LSTMLayer (input, inputSize, outputSize, cellSize, selector) = [ 
               lstm = BS.RNNs.RecurrentLSTMP (outputSize, cellDim=cellSize, input, inputDim=inputSize).h
               result = selector(lstm)
            ].result
        ]        
        // LSTM params
        lstmDim = 25
        cellDim = 25
        // model
        numLabels = 5        
        vocab = 2000
        embedDim = 50        
        // set up features and labels
        t = DynamicAxis()
features = Input(1, dynamicAxis=t)   
labels   = Input(numLabels)          
        // load the pre-learned word embedding matrix
        l1 = Layers.EmbeddingLayer(features, vocab, embedDim, 'embeddingmatrix.txt')
        l2 = Layers.LSTMLayer(l1, embedDim, lstmDim, cellDim, BS.Sequences.Last)
        l3 = Layers.DenseLayer(l2, lstmDim, numLabels, Pass)
        out = Pass(l3, tag='output')   
        // Make sure the trainer understands that the time dimension of l3 is actually the same as that of labels.
        l3p = ReconcileDynamicAxis(l3, labels)
        // training criteria
        ce  = CrossEntropyWithSoftmax(labels, l3p, tag='criterion')   // this is the training objective
        err = ErrorPrediction        (labels, l3p, tag='evaluation')  // this also gets tracked
    ]
    SGD = [	
        epochSize = 0
        minibatchSize = 200
        maxEpochs = 5
        momentumPerMB = 0.9
        learningRatesPerMB = 0.1
        keepCheckPointFiles = true
    ]
    reader = [
        readerType = "CNTKTextFormatReader"
        file = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data/Train.txt"            
        input = [            
            features=[
                alias = "x"                
                dim = 1               
                format = "dense"
            ]
            labels=[
                alias = "y"                
                dim = 5           
                format = "dense"
            ]
        ]
   ]    
outputPath = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/output.txt"        
]

configparameters: seqcla.cntk:Write=[
    action="test"
    run=BrainScriptNetworkBuilder
    format = [
      sequencePrologue=%d\t|w.shape %x\n%d\t|w\s
      sampleSeparator=\n%d\t|w\s
      elementSeparator=\s
    ]
    modelFile = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn"    
    reader = [
            readerType = "CNTKTextFormatReader"
            file = "/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Text/SequenceClassification/Data/Train.txt"            
            input = [            
                features=[
                    alias = "x"                
                    dim = 1               
                    format = "dense"
                ]
                labels=[
                    alias = "y"                
                    dim = 5           
                    format = "dense"
                ]
            ]
   ]    
outputPath = "/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/output.txt"        
]

08/04/2016 13:57:01: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/04/2016 13:57:01: Commands: Train
08/04/2016 13:57:01: Precision = "float"
08/04/2016 13:57:01: CNTKModelPath: /tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn
08/04/2016 13:57:01: CNTKCommandTrainInfo: Train : 5
08/04/2016 13:57:01: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5

08/04/2016 13:57:01: ##############################################################################
08/04/2016 13:57:01: #                                                                            #
08/04/2016 13:57:01: # Action "train"                                                             #
08/04/2016 13:57:01: #                                                                            #
08/04/2016 13:57:01: ##############################################################################

08/04/2016 13:57:01: CNTKCommandTrainBegin: Train

08/04/2016 13:57:01: Starting from checkpoint. Loading network from '/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn.4'.

Post-processing network...

4 roots:
	ce = CrossEntropyWithSoftmax()
	err = ErrorPrediction()
	out = Pass()
	t = DynamicAxis()

Loop[0] --> Loop_l2.lstm.lstmState._privateInnards.ht -> 25 nodes

	l2.lstm.prevState.h	l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1]	l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0]
	l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1]	l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0]	l2.lstm.prevState.c
	l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1]	l2.lstm.lstmState._privateInnards.ft._	l2.lstm.lstmState._privateInnards.ft
	l2.lstm.lstmState._privateInnards.bft	l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1]	l2.lstm.lstmState._privateInnards.it._.PlusArgs[0]
	l2.lstm.lstmState._privateInnards.it._.PlusArgs[1]	l2.lstm.lstmState._privateInnards.it._	l2.lstm.lstmState._privateInnards.it
	l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1]	l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z	l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1]
	l2.lstm.lstmState._privateInnards.bit	l2.lstm.lstmState._privateInnards.ct	l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1]
	l2.lstm.lstmState._privateInnards.ot._	l2.lstm.lstmState._privateInnards.ot	l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1]
	l2.lstm.lstmState._privateInnards.ht

Validating network. 71 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [5 x *]
Validating --> l3.z.W = LearnableParameter() :  -> [5 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> features = InputValue() :  -> [1 x t1]
Validating --> l1.embedding.x = LearnableParameter() :  -> [2000 x 50]
Validating --> l1.embedding = TransposeDimensions (l1.embedding.x) : [2000 x 50] -> [50 x 2000]
Validating --> l1.lookup = GatherPacked (features, l1.embedding) : [1 x t1], [50 x 2000] -> [50 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1]) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] = LearnableParameter() :  -> [25]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 50]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0], l1.lookup) : [25 x 50], [50 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1]) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] = LearnableParameter() :  -> [25 x 25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [25] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.ft._ = Plus (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0], l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft = Sigmoid (l2.lstm.lstmState._privateInnards.ft._) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bft = ElementTimes (l2.lstm.lstmState._privateInnards.ft, l2.lstm.prevState.c) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0] = Plus (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0], l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [25] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.it._ = Plus (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0], l2.lstm.lstmState._privateInnards.it._.PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it = Sigmoid (l2.lstm.lstmState._privateInnards.it._) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25] -> [25]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z = Plus (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0], l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1]) : [25 x t1], [25] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1] = Tanh (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bit = ElementTimes (l2.lstm.lstmState._privateInnards.it, l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1]) : [25 x t1], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ct = Plus (l2.lstm.lstmState._privateInnards.bft, l2.lstm.lstmState._privateInnards.bit) : [25 x t1], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.lstmState._privateInnards.ct) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot._ = Plus (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0], l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1]) : [25 x t1], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot = Sigmoid (l2.lstm.lstmState._privateInnards.ot._) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1] = Tanh (l2.lstm.lstmState._privateInnards.ct) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ht = ElementTimes (l2.lstm.lstmState._privateInnards.ot, l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1]) : [25 x t1], [25 x t1] -> [25 x t1]
Validating --> l2.result.beginFlags.input.z.ElementTimesArgs[0] = Slice (l2.lstm.lstmState._privateInnards.ht) : [25 x t1] -> [1 x t1]
Validating --> BS.Constants.Zero = LearnableParameter() :  -> [1]
Validating --> l2.result.beginFlags.input.z = ElementTimes (l2.result.beginFlags.input.z.ElementTimesArgs[0], BS.Constants.Zero) : [1 x t1], [1] -> [1 x t1]
Validating --> l2.result.beginFlags.input = SumColumnElements (l2.result.beginFlags.input.z) : [1 x t1] -> [1 x t1]
Validating --> l2.result.beginFlags = FutureValue (l2.result.beginFlags.input) : [1 x t1] -> [1 x t1]
Validating --> l2.result.out.indexSequence.indexSequence = Where (l2.result.beginFlags) : [1 x t1] -> [1 x WhereNodeAxis]
Validating --> l2.result.out.indexSequence = PackedIndex (l2.lstm.lstmState._privateInnards.ht, l2.result.out.indexSequence.indexSequence) : [25 x t1], [1 x WhereNodeAxis] -> [1 x WhereNodeAxis]
Validating --> l2.result.out = GatherPacked (l2.result.out.indexSequence, l2.lstm.lstmState._privateInnards.ht) : [1 x WhereNodeAxis], [25 x t1] -> [25 x WhereNodeAxis]
Validating --> l3.z.z.PlusArgs[0] = Times (l3.z.W, l2.result.out) : [5 x 25], [25 x WhereNodeAxis] -> [5 x WhereNodeAxis]
Validating --> l3.z.B = LearnableParameter() :  -> [5 x 1]
Validating --> l3.z.z = Plus (l3.z.z.PlusArgs[0], l3.z.B) : [5 x WhereNodeAxis], [5 x 1] -> [5 x 1 x WhereNodeAxis]
Validating --> l3.act = Pass (l3.z.z) : [5 x 1 x WhereNodeAxis] -> [5 x 1 x WhereNodeAxis]
Validating --> l3p = ReconcileDynamicAxis (l3.act, labels) : [5 x 1 x WhereNodeAxis], [5 x *] -> [5 x 1 x *]
Validating --> ce = CrossEntropyWithSoftmax (labels, l3p) : [5 x *], [5 x 1 x *] -> [1]
Validating --> err = ErrorPrediction (labels, l3p) : [5 x *], [5 x 1 x *] -> [1]
Validating --> out = Pass (l3.act) : [5 x 1 x WhereNodeAxis] -> [5 x 1 x WhereNodeAxis]
Validating --> t = DynamicAxis() :  -> [1 x 1 x t1]

Validating network. 49 nodes to process in pass 2.

Validating --> l2.lstm.prevState.h = PastValue (l2.lstm.lstmState._privateInnards.ht) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.prevState.c = PastValue (l2.lstm.lstmState._privateInnards.ct) : [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] = ElementTimes (l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0], l2.lstm.prevState.c) : [25], [25 x t1] -> [25 x t1]
Validating --> l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] = Times (l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0], l2.lstm.prevState.h) : [25 x 25], [25 x t1] -> [25 x t1]

Validating network. 8 nodes to process in pass 3.


Validating network, final pass.



69 out of 71 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/04/2016 13:57:01: Loaded model with 71 nodes on CPU.

08/04/2016 13:57:01: Training criterion node(s):
08/04/2016 13:57:01: 	ce = CrossEntropyWithSoftmax

08/04/2016 13:57:01: Evaluation criterion node(s):

08/04/2016 13:57:01: 	err = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[BS.Constants.Zero Gradient[1]] [err Gradient[1]] [features Gradient[1 x t1]] [l1.embedding Gradient[50 x 2000]] [l1.embedding.x Gradient[2000 x 50]] [l1.lookup Gradient[50 x t1]] [labels Gradient[5 x *]] [out Gradient[5 x 1 x WhereNodeAxis]] [t Gradient[1 x 1 x t1]] [t Value[1 x 1 x t1]] }
0x7f0d58e01888: {[l2.lstm.prevState.c Value[25 x t1]] }
0x7f0d58e01fa8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] Gradient[25]] [l2.lstm.prevState.h Value[25 x t1]] }
0x7f0d58e026c8: {[l2.lstm.lstmState._privateInnards.ot._ Gradient[25 x t1]] [l2.result.beginFlags Value[1 x t1]] [l2.result.beginFlags.input.z Gradient[1 x t1]] }
0x7f0d58e039f8: {[l2.result.out.indexSequence Value[1 x WhereNodeAxis]] }
0x7f0d58e03b58: {[l2.result.out.indexSequence.indexSequence Value[1 x WhereNodeAxis]] }
0x7f0d58e044c8: {[l3.z.W Value[5 x 25]] }
0x7f0d58e047e8: {[l3.z.B Value[5 x 1]] }
0x7f0d58e05d08: {[labels Value[5 x *]] }
0x7f0d58e0ba88: {[l1.embedding Value[50 x 2000]] }
0x7f0d58e0bcd8: {[out Value[5 x 1 x WhereNodeAxis]] }
0x7f0d58e0bf28: {[err Value[1]] }
0x7f0d58e0d098: {[ce Value[1]] }
0x7f0d58e13298: {[l1.lookup Value[50 x t1]] }
0x7f0d58e13e88: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0] Value[25 x t1]] [l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
0x7f0d58e14048: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Value[25 x t1]] [l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Gradient[25]] }
0x7f0d58e14148: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] Value[25 x t1]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Gradient[25]] }
0x7f0d58e146a8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Value[25 x t1]] }
0x7f0d58e14b88: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0] Value[25 x t1]] [l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
0x7f0d58e14d48: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Gradient[25]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Value[25 x t1]] }
0x7f0d58e14f08: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0] Value[25 x t1]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
0x7f0d58e159b8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0] Value[25 x t1]] [l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 50]] }
0x7f0d58e15b18: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] Value[25 x t1]] }
0x7f0d58e15cd8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0] Value[25 x t1]] }
0x7f0d58e15e98: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] Value[25 x t1]] }
0x7f0d58e16058: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0] Value[25 x t1]] }
0x7f0d58e16218: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] Value[25 x t1]] }
0x7f0d58e163d8: {[l2.lstm.lstmState._privateInnards.ft._ Value[25 x t1]] }
0x7f0d58e16598: {[l2.lstm.lstmState._privateInnards.ft Value[25 x t1]] }
0x7f0d58e16758: {[l2.lstm.lstmState._privateInnards.bft Value[25 x t1]] }
0x7f0d58e16918: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] Value[25 x t1]] }
0x7f0d58e16ad8: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0] Value[25 x t1]] }
0x7f0d58e16c98: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] Value[25 x t1]] }
0x7f0d58e16e58: {[l2.lstm.lstmState._privateInnards.it._ Value[25 x t1]] }
0x7f0d58e17018: {[l2.lstm.lstmState._privateInnards.it Value[25 x t1]] }
0x7f0d58e171d8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] Value[25 x t1]] }
0x7f0d58e17398: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z Value[25 x t1]] }
0x7f0d58e17558: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1] Value[25 x t1]] }
0x7f0d58e17718: {[l2.lstm.lstmState._privateInnards.bit Value[25 x t1]] }
0x7f0d58e178d8: {[l2.lstm.lstmState._privateInnards.ct Value[25 x t1]] }
0x7f0d58e17a98: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1] Value[25 x t1]] }
0x7f0d58e17c58: {[l2.lstm.lstmState._privateInnards.ot._ Value[25 x t1]] }
0x7f0d58e17e18: {[l2.lstm.lstmState._privateInnards.ot Value[25 x t1]] }
0x7f0d58e17fd8: {[l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1] Value[25 x t1]] }
0x7f0d58e18198: {[l2.lstm.lstmState._privateInnards.ht Value[25 x t1]] }
0x7f0d58e18358: {[l2.lstm.lstmState._privateInnards.ot Gradient[25 x t1]] [l2.result.beginFlags.input.z.ElementTimesArgs[0] Value[1 x t1]] }
0x7f0d58e18518: {[l2.lstm.lstmState._privateInnards.ct Gradient[25 x t1]] [l2.result.beginFlags.input.z Value[1 x t1]] }
0x7f0d58e186d8: {[l2.lstm.lstmState._privateInnards.ht.ElementTimesArgs[1] Gradient[25 x t1]] [l2.result.beginFlags.input Value[1 x t1]] [l2.result.beginFlags.input.z.ElementTimesArgs[0] Gradient[1 x t1]] }
0x7f0d58e18898: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0] Gradient[25 x t1]] [l2.result.beginFlags.input Gradient[1 x t1]] [l2.result.out Value[25 x WhereNodeAxis]] [l2.result.out.indexSequence.indexSequence Gradient[1 x WhereNodeAxis]] }
0x7f0d58e18a58: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1] Gradient[25 x t1]] [l2.result.beginFlags Gradient[1 x t1]] [l2.result.out.indexSequence Gradient[1 x WhereNodeAxis]] [l3.z.z.PlusArgs[0] Value[5 x WhereNodeAxis]] }
0x7f0d58e18c18: {[l3.z.W Gradient[5 x 25]] [l3.z.z Value[5 x 1 x WhereNodeAxis]] }
0x7f0d58e18dd8: {[l2.lstm.lstmState._privateInnards.ht Gradient[25 x t1]] [l3.act Value[5 x 1 x WhereNodeAxis]] [l3.z.z.PlusArgs[0] Gradient[5 x WhereNodeAxis]] }
0x7f0d58e18f98: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0] Gradient[25]] [l2.result.out Gradient[25 x WhereNodeAxis]] [l3.z.z Gradient[5 x 1 x WhereNodeAxis]] [l3p Value[5 x 1 x *]] }
0x7f0d58e19a18: {[ce Gradient[1]] }
0x7f0d58e19bd8: {[l2.lstm.lstmState._privateInnards.bft Gradient[25 x t1]] [l3p Gradient[5 x 1 x *]] }
0x7f0d58e19d98: {[l3.act Gradient[5 x 1 x WhereNodeAxis]] [l3.z.B Gradient[5 x 1]] }
0x7f0d58e1a038: {[l2.lstm.lstmState._privateInnards.bit Gradient[25 x t1]] }
0x7f0d58e1a1f8: {[l2.lstm.lstmState._privateInnards.it Gradient[25 x t1]] }
0x7f0d58e1a3b8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1] Gradient[25 x t1]] }
0x7f0d58e1a578: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z Gradient[25 x t1]] }
0x7f0d58e1a738: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0] Gradient[25 x t1]] }
0x7f0d58e1a8f8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1] Gradient[25 x t1]] }
0x7f0d58e1aab8: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
0x7f0d58e1ac78: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] [l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] [l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] [l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] [l2.lstm.prevState.h Gradient[25 x t1]] }
0x7f0d58e1ae38: {[l2.lstm.lstmState._privateInnards.it._ Gradient[25 x t1]] }
0x7f0d58e1aff8: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0] Gradient[25 x t1]] }
0x7f0d58e1b1b8: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1] Gradient[25 x t1]] }
0x7f0d58e1b378: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0] Gradient[25]] }
0x7f0d58e1b538: {[l2.lstm.prevState.c Gradient[25 x t1]] }
0x7f0d58e1b6f8: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0] Gradient[25 x t1]] }
0x7f0d58e1b8b8: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] }
0x7f0d58e1ba78: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
0x7f0d58e1bc38: {[l2.lstm.lstmState._privateInnards.ft Gradient[25 x t1]] }
0x7f0d58e1bdf8: {[l2.lstm.lstmState._privateInnards.ft._ Gradient[25 x t1]] }
0x7f0d58e1bfb8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0] Gradient[25 x t1]] }
0x7f0d58e1c178: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1] Gradient[25 x t1]] }
0x7f0d58e1c338: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0] Gradient[25]] }
0x7f0d58e1c4f8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0] Gradient[25 x t1]] }
0x7f0d58e1c6b8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] }
0x7f0d58e1c878: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
0x7f0d58e1ca38: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0] Gradient[25 x t1]] }
0x7f0d58e1cbf8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1] Gradient[25 x t1]] }
0x7f0d58e1cdb8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Gradient[25 x 25]] }
0x7f0d596c0c28: {[BS.Constants.Zero Value[1]] }
0x7f0d596e9398: {[features Value[1 x t1]] }
0x7f0d596ea968: {[l1.embedding.x Value[2000 x 50]] }
0x7f0d596eb498: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
0x7f0d596eb548: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[0].PlusArgs[0] Value[25]] }
0x7f0d596edd38: {[l2.lstm.lstmState._privateInnards.bit.ElementTimesArgs[1].z.PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
0x7f0d596ee2c8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
0x7f0d596f0d18: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Value[25]] }
0x7f0d596f2ce8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
0x7f0d596f3fc8: {[l2.lstm.lstmState._privateInnards.ft._.PlusArgs[1].ElementTimesArgs[0] Value[25]] }
0x7f0d596f7388: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Value[25]] }
0x7f0d596f84c8: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
0x7f0d596f8a98: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
0x7f0d596f8fa8: {[l2.lstm.lstmState._privateInnards.it._.PlusArgs[1].ElementTimesArgs[0] Value[25]] }
0x7f0d596fb7b8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[0] Value[25]] }
0x7f0d596fcee8: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 50]] }
0x7f0d596fe038: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[0].PlusArgs[1].TimesArgs[0] Value[25 x 25]] }
0x7f0d596fff58: {[l2.lstm.lstmState._privateInnards.ot._.PlusArgs[1].ElementTimesArgs[0] Value[25]] }

08/04/2016 13:57:01: No PreCompute nodes found, skipping PreCompute step.

08/04/2016 13:57:01: Starting Epoch 5: learning rate per sample = 0.000500  effective momentum = 0.900000  momentum as time constant = 1898.2 samples
BlockRandomizer::StartEpoch: epoch 4: frames [21732..27165] (first sequence at sample 21732), data subset 0 of 1

08/04/2016 13:57:01: Starting minibatch loop.
08/04/2016 13:57:02: Finished Epoch[ 5 of 5]: [Training] ce = 1.33199611 * 1247; err = 0.44667201 * 1247; totalSamplesSeen = 6235; learningRatePerSample = 0.00050000002; epochTime=0.803906s
08/04/2016 13:57:02: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Text_SequenceClassification@release_cpu/Models/seqcla.dnn'
08/04/2016 13:57:02: CNTKCommandTrainEnd: Train

08/04/2016 13:57:02: Action "train" complete.

08/04/2016 13:57:02: __COMPLETED__