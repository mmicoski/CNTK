CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU W3550 @ 3.07GHz
    Hardware threads: 4
    Total Memory: 12580388 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu DeviceId=0 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug  4 2016 06:18:04
		Last modified date: Thu Aug  4 03:39:14 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
		Built by svcphil on dphaim-26-new
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows@3\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
08/04/2016 09:24:45: -------------------------------------------------------------------
08/04/2016 09:24:45: Build info: 

08/04/2016 09:24:45: 		Built time: Aug  4 2016 06:18:04
08/04/2016 09:24:45: 		Last modified date: Thu Aug  4 03:39:14 2016
08/04/2016 09:24:45: 		Build type: Release
08/04/2016 09:24:45: 		Build target: GPU
08/04/2016 09:24:45: 		With 1bit-SGD: no
08/04/2016 09:24:45: 		Math lib: mkl
08/04/2016 09:24:45: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/04/2016 09:24:45: 		CUB_PATH: C:\src\cub-1.4.1
08/04/2016 09:24:45: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
08/04/2016 09:24:45: 		Build Branch: HEAD
08/04/2016 09:24:45: 		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
08/04/2016 09:24:45: 		Built by svcphil on dphaim-26-new
08/04/2016 09:24:45: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows@3\Source\CNTK\
08/04/2016 09:24:45: -------------------------------------------------------------------
08/04/2016 09:24:45: -------------------------------------------------------------------
08/04/2016 09:24:45: GPU info:

08/04/2016 09:24:45: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8192 MB
08/04/2016 09:24:45: -------------------------------------------------------------------

08/04/2016 09:24:45: Running on cntk-muc02 at 2016/08/04 09:24:45
08/04/2016 09:24:45: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu  DeviceId=0  timestamping=true



08/04/2016 09:24:45: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/04/2016 09:24:45: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu
DeviceId=0
timestamping=true

08/04/2016 09:24:45: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/04/2016 09:24:45: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/04/2016 09:24:45: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu
DeviceId=0
timestamping=true

08/04/2016 09:24:45: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/04/2016 09:24:45: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=0
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/04/2016 09:24:45: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/04/2016 09:24:45: Commands: Simple_Demo Simple_Demo_Output
08/04/2016 09:24:45: Precision = "float"
08/04/2016 09:24:45: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn
08/04/2016 09:24:45: CNTKCommandTrainInfo: Simple_Demo : 50
08/04/2016 09:24:45: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/04/2016 09:24:45: ##############################################################################
08/04/2016 09:24:45: #                                                                            #
08/04/2016 09:24:45: # Action "train"                                                             #
08/04/2016 09:24:45: #                                                                            #
08/04/2016 09:24:45: ##############################################################################

08/04/2016 09:24:45: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using GPU 0

08/04/2016 09:24:45: Creating virgin network.
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/04/2016 09:24:45: Created model with 25 nodes on GPU 0.

08/04/2016 09:24:45: Training criterion node(s):
08/04/2016 09:24:45: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/04/2016 09:24:45: Evaluation criterion node(s):

08/04/2016 09:24:45: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *]] [PosteriorProb Value[2 x 1 x *]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *]] [features Gradient[2 x *]] [labels Gradient[2 x *]] }
000000BB183509D0: {[W0*features+B0 Gradient[50 x 1 x *]] [W1*H1 Value[50 x 1 x *]] }
000000BB18350A70: {[H2 Value[50 x 1 x *]] [W1*H1 Gradient[50 x 1 x *]] }
000000BB18350B10: {[B2 Value[2 x 1]] }
000000BB18350C50: {[Prior Value[2]] }
000000BB18350F70: {[EvalErrorPrediction Value[1]] }
000000BB18351010: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *]] [W1*H1+B1 Gradient[50 x 1 x *]] [W2*H1 Value[2 x 1 x *]] }
000000BB18351150: {[HLast Value[2 x 1 x *]] [W2 Gradient[2 x 50]] }
000000BB183511F0: {[W2 Value[2 x 50]] }
000000BB18351330: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *]] }
000000BB18351470: {[CrossEntropyWithSoftmax Gradient[1]] }
000000BB18351830: {[MVNormalizedFeatures Value[2 x *]] }
000000BB183518D0: {[W0*features Value[50 x *]] }
000000BB18351AB0: {[ScaledLogLikelihood Value[2 x 1 x *]] }
000000BB18351B50: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *]] [HLast Gradient[2 x 1 x *]] }
000000BB18351BF0: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *]] }
000000BB18351C90: {[W2*H1 Gradient[2 x 1 x *]] }
000000BB18351DD0: {[B2 Gradient[2 x 1]] }
000000BB18351F10: {[labels Value[2 x *]] }
000000BB18351FB0: {[H1 Value[50 x 1 x *]] [W0*features Gradient[50 x *]] }
000000BB18352230: {[CrossEntropyWithSoftmax Value[1]] }
000000BB18352690: {[LogOfPrior Value[2]] }
000000BB7C99B6A0: {[W1 Value[50 x 50]] }
000000BB7C99BCE0: {[MeanOfFeatures Value[2]] }
000000BB7C99BEC0: {[W0 Value[50 x 2]] }
000000BB7C99C3C0: {[B1 Value[50 x 1]] }
000000BB7C99C820: {[InvStdOfFeatures Value[2]] }
000000BB7C99CFA0: {[B0 Value[50 x 1]] }
000000BB7CA6FEC0: {[features Value[2 x *]] }


08/04/2016 09:24:45: Precomputing --> 3 PreCompute nodes found.

08/04/2016 09:24:45: 	MeanOfFeatures = Mean()
08/04/2016 09:24:45: 	InvStdOfFeatures = InvStdDev()
08/04/2016 09:24:45: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

08/04/2016 09:24:45: Precomputing --> Completed.


08/04/2016 09:24:45: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

08/04/2016 09:24:45: Starting minibatch loop.
08/04/2016 09:24:45:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.71512318 * 1280; EvalErrorPrediction = 0.47734375 * 1280; time = 0.0173s; samplesPerSecond = 74035.5
08/04/2016 09:24:45:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.73317490 * 1280; EvalErrorPrediction = 0.47343750 * 1280; time = 0.0166s; samplesPerSecond = 77187.5
08/04/2016 09:24:45:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.69626369 * 1280; EvalErrorPrediction = 0.51640625 * 1280; time = 0.0168s; samplesPerSecond = 76231.3
08/04/2016 09:24:45:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.69332314 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.0169s; samplesPerSecond = 75551.9
08/04/2016 09:24:45:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.59974632 * 1280; EvalErrorPrediction = 0.29921875 * 1280; time = 0.0170s; samplesPerSecond = 75413.9
08/04/2016 09:24:45:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.26053467 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0170s; samplesPerSecond = 75320.7
08/04/2016 09:24:45:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.14376297 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0171s; samplesPerSecond = 74748.9
08/04/2016 09:24:45: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.51086699 * 10000; EvalErrorPrediction = 0.31510000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.13604s
08/04/2016 09:24:45: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.1'

08/04/2016 09:24:45: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: frames [10000..20000] (first sequence at sample 10000), data subset 0 of 1

08/04/2016 09:24:45: Starting minibatch loop.
08/04/2016 09:24:45:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.26108458 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0167s; samplesPerSecond = 76555.0
08/04/2016 09:24:45:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.31391876 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0171s; samplesPerSecond = 75068.9
08/04/2016 09:24:46:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.28372641 * 1280; EvalErrorPrediction = 0.09531250 * 1280; time = 0.0171s; samplesPerSecond = 74692.2
08/04/2016 09:24:46:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.26705055 * 1280; EvalErrorPrediction = 0.09296875 * 1280; time = 0.0171s; samplesPerSecond = 74648.6
08/04/2016 09:24:46:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.21732979 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0174s; samplesPerSecond = 73432.4
08/04/2016 09:24:46:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.23777008 * 1280; EvalErrorPrediction = 0.10078125 * 1280; time = 0.0171s; samplesPerSecond = 74941.5
08/04/2016 09:24:46:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19739647 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0173s; samplesPerSecond = 73915.8
08/04/2016 09:24:46: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.24826287 * 10000; EvalErrorPrediction = 0.08420000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.136175s
08/04/2016 09:24:46: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.2'

08/04/2016 09:24:46: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: frames [20000..30000] (first sequence at sample 20000), data subset 0 of 1

08/04/2016 09:24:46: Starting minibatch loop.
08/04/2016 09:24:46:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18019217 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0172s; samplesPerSecond = 74392.7
08/04/2016 09:24:46:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.21376134 * 1280; EvalErrorPrediction = 0.09296875 * 1280; time = 0.0173s; samplesPerSecond = 74099.8
08/04/2016 09:24:46:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18463340 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0170s; samplesPerSecond = 75214.5
08/04/2016 09:24:46:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19754114 * 1280; EvalErrorPrediction = 0.09609375 * 1280; time = 0.0166s; samplesPerSecond = 77075.9
08/04/2016 09:24:46:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17424359 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0165s; samplesPerSecond = 77792.6
08/04/2016 09:24:46:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16837311 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0165s; samplesPerSecond = 77604.0
08/04/2016 09:24:46:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15755539 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0178s; samplesPerSecond = 71801.2
08/04/2016 09:24:46: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.18000575 * 10000; EvalErrorPrediction = 0.07880000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.136099s
08/04/2016 09:24:46: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.3'

08/04/2016 09:24:46: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: frames [30000..40000] (first sequence at sample 30000), data subset 0 of 1

08/04/2016 09:24:46: Starting minibatch loop.
08/04/2016 09:24:46:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16080968 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0195s; samplesPerSecond = 65732.0
08/04/2016 09:24:46:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17185786 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0196s; samplesPerSecond = 65469.8
08/04/2016 09:24:46:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15687308 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0200s; samplesPerSecond = 63977.6
08/04/2016 09:24:46:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15924721 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0202s; samplesPerSecond = 63498.4
08/04/2016 09:24:46:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18977828 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0199s; samplesPerSecond = 64250.6
08/04/2016 09:24:46:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17631273 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0195s; samplesPerSecond = 65520.1
08/04/2016 09:24:46:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19228029 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0197s; samplesPerSecond = 64951.5
08/04/2016 09:24:46: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.16987485 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.156187s
08/04/2016 09:24:46: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.4'

08/04/2016 09:24:46: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: frames [40000..50000] (first sequence at sample 40000), data subset 0 of 1

08/04/2016 09:24:46: Starting minibatch loop.
08/04/2016 09:24:46:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18302362 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0192s; samplesPerSecond = 66708.4
08/04/2016 09:24:46:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18110201 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0197s; samplesPerSecond = 65047.3
08/04/2016 09:24:46:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16424689 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0194s; samplesPerSecond = 65830.1
08/04/2016 09:24:46:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15424871 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0200s; samplesPerSecond = 64006.4
08/04/2016 09:24:46:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17534499 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0197s; samplesPerSecond = 64823.3
08/04/2016 09:24:46:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16816807 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0201s; samplesPerSecond = 63637.3
08/04/2016 09:24:46:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16452742 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0199s; samplesPerSecond = 64418.7
08/04/2016 09:24:46: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16671438 * 10000; EvalErrorPrediction = 0.07700000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.156348s
08/04/2016 09:24:46: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.5'

08/04/2016 09:24:46: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: frames [50000..60000] (first sequence at sample 50000), data subset 0 of 1

08/04/2016 09:24:46: Starting minibatch loop.
08/04/2016 09:24:46:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16387001 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0191s; samplesPerSecond = 67149.3
08/04/2016 09:24:46:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16557273 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0200s; samplesPerSecond = 63996.8
08/04/2016 09:24:46:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15140233 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0200s; samplesPerSecond = 64044.8
08/04/2016 09:24:46:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13718820 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0199s; samplesPerSecond = 64221.6
08/04/2016 09:24:46:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14191904 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0201s; samplesPerSecond = 63773.6
08/04/2016 09:24:46:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17365947 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0199s; samplesPerSecond = 64460.9
08/04/2016 09:24:46:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17076263 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0198s; samplesPerSecond = 64607.3
08/04/2016 09:24:46: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.16154489 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.156576s
08/04/2016 09:24:46: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.6'

08/04/2016 09:24:46: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: frames [60000..70000] (first sequence at sample 60000), data subset 0 of 1

08/04/2016 09:24:46: Starting minibatch loop.
08/04/2016 09:24:46:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16636192 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0182s; samplesPerSecond = 70376.1
08/04/2016 09:24:46:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16234299 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0196s; samplesPerSecond = 65163.2
08/04/2016 09:24:46:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16522081 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0199s; samplesPerSecond = 64315.1
08/04/2016 09:24:46:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16651578 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0199s; samplesPerSecond = 64363.7
08/04/2016 09:24:46:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16438904 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0202s; samplesPerSecond = 63432.3
08/04/2016 09:24:46:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18188524 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0194s; samplesPerSecond = 66129.4
08/04/2016 09:24:46:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14202251 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0196s; samplesPerSecond = 65379.5
08/04/2016 09:24:46: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.16473855 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.154281s
08/04/2016 09:24:46: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.7'

08/04/2016 09:24:46: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: frames [70000..80000] (first sequence at sample 70000), data subset 0 of 1

08/04/2016 09:24:46: Starting minibatch loop.
08/04/2016 09:24:46:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17953711 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0180s; samplesPerSecond = 71048.0
08/04/2016 09:24:46:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17383342 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0179s; samplesPerSecond = 71672.5
08/04/2016 09:24:46:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17488918 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0199s; samplesPerSecond = 64425.2
08/04/2016 09:24:46:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17644272 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0200s; samplesPerSecond = 64057.7
08/04/2016 09:24:47:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16565862 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0197s; samplesPerSecond = 64892.3
08/04/2016 09:24:47:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14829702 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0197s; samplesPerSecond = 65024.1
08/04/2016 09:24:47:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14856091 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0195s; samplesPerSecond = 65759.1
08/04/2016 09:24:47: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.16748629 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.152266s
08/04/2016 09:24:47: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.8'

08/04/2016 09:24:47: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: frames [80000..90000] (first sequence at sample 80000), data subset 0 of 1

08/04/2016 09:24:47: Starting minibatch loop.
08/04/2016 09:24:47:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16864276 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0186s; samplesPerSecond = 68861.6
08/04/2016 09:24:47:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15251369 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0195s; samplesPerSecond = 65614.1
08/04/2016 09:24:47:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17620068 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0194s; samplesPerSecond = 65860.6
08/04/2016 09:24:47:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16483545 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0200s; samplesPerSecond = 64105.8
08/04/2016 09:24:47:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.20390840 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0195s; samplesPerSecond = 65637.7
08/04/2016 09:24:47:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16236467 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0199s; samplesPerSecond = 64341.0
08/04/2016 09:24:47:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15798311 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0198s; samplesPerSecond = 64630.1
08/04/2016 09:24:47: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.16688885 * 10000; EvalErrorPrediction = 0.07640000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.154759s
08/04/2016 09:24:47: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.9'

08/04/2016 09:24:47: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: frames [90000..100000] (first sequence at sample 90000), data subset 0 of 1

08/04/2016 09:24:47: Starting minibatch loop.
08/04/2016 09:24:47:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17675778 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0178s; samplesPerSecond = 72076.1
08/04/2016 09:24:47:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16434399 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0161s; samplesPerSecond = 79517.9
08/04/2016 09:24:47:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17353199 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0160s; samplesPerSecond = 79900.1
08/04/2016 09:24:47:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16640921 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0161s; samplesPerSecond = 79537.7
08/04/2016 09:24:47:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15549984 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0159s; samplesPerSecond = 80432.3
08/04/2016 09:24:47:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15423985 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0173s; samplesPerSecond = 73979.9
08/04/2016 09:24:47:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16300344 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0181s; samplesPerSecond = 70859.2
08/04/2016 09:24:47: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.17023618 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.13475s
08/04/2016 09:24:47: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.10'

08/04/2016 09:24:47: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: frames [100000..110000] (first sequence at sample 100000), data subset 0 of 1

08/04/2016 09:24:47: Starting minibatch loop.
08/04/2016 09:24:47:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16718870 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0191s; samplesPerSecond = 67012.2
08/04/2016 09:24:47:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17143420 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0189s; samplesPerSecond = 67742.8
08/04/2016 09:24:47:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17570496 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0199s; samplesPerSecond = 64454.4
08/04/2016 09:24:47:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16229787 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0198s; samplesPerSecond = 64542.2
08/04/2016 09:24:47:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15825319 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0196s; samplesPerSecond = 65216.3
08/04/2016 09:24:47:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16414423 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0202s; samplesPerSecond = 63306.8
08/04/2016 09:24:47:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14462833 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0201s; samplesPerSecond = 63745.0
08/04/2016 09:24:47: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16323230 * 10000; EvalErrorPrediction = 0.07500000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.155782s
08/04/2016 09:24:47: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.11'

08/04/2016 09:24:47: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: frames [110000..120000] (first sequence at sample 110000), data subset 0 of 1

08/04/2016 09:24:47: Starting minibatch loop.
08/04/2016 09:24:47:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15089105 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0195s; samplesPerSecond = 65725.3
08/04/2016 09:24:47:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17891301 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0201s; samplesPerSecond = 63748.2
08/04/2016 09:24:47:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17338006 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0200s; samplesPerSecond = 64070.5
08/04/2016 09:24:47:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15537610 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0195s; samplesPerSecond = 65772.6
08/04/2016 09:24:47:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14915977 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0190s; samplesPerSecond = 67443.0
08/04/2016 09:24:47:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17316236 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0196s; samplesPerSecond = 65173.1
08/04/2016 09:24:47:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15632277 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0202s; samplesPerSecond = 63435.4
08/04/2016 09:24:47: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16362993 * 10000; EvalErrorPrediction = 0.07400000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.156456s
08/04/2016 09:24:47: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.12'

08/04/2016 09:24:47: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: frames [120000..130000] (first sequence at sample 120000), data subset 0 of 1

08/04/2016 09:24:47: Starting minibatch loop.
08/04/2016 09:24:47:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19953163 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0192s; samplesPerSecond = 66819.8
08/04/2016 09:24:47:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20423648 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0196s; samplesPerSecond = 65312.8
08/04/2016 09:24:47:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16470652 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0200s; samplesPerSecond = 64067.3
08/04/2016 09:24:47:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19042869 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0197s; samplesPerSecond = 65126.7
08/04/2016 09:24:47:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18428297 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0194s; samplesPerSecond = 65959.0
08/04/2016 09:24:47:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16252375 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0192s; samplesPerSecond = 66500.4
08/04/2016 09:24:47:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15715923 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0197s; samplesPerSecond = 64859.4
08/04/2016 09:24:47: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.17984280 * 10000; EvalErrorPrediction = 0.08080000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.155328s
08/04/2016 09:24:47: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.13'

08/04/2016 09:24:47: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: frames [130000..140000] (first sequence at sample 130000), data subset 0 of 1

08/04/2016 09:24:47: Starting minibatch loop.
08/04/2016 09:24:47:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17116748 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0191s; samplesPerSecond = 66865.2
08/04/2016 09:24:47:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14795855 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0199s; samplesPerSecond = 64418.7
08/04/2016 09:24:47:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17224183 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0179s; samplesPerSecond = 71584.4
08/04/2016 09:24:47:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16774073 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0177s; samplesPerSecond = 72414.6
08/04/2016 09:24:47:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16705785 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0178s; samplesPerSecond = 72084.2
08/04/2016 09:24:47:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16627474 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0202s; samplesPerSecond = 63250.5
08/04/2016 09:24:48:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15878906 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0206s; samplesPerSecond = 62196.3
08/04/2016 09:24:48: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.16444779 * 10000; EvalErrorPrediction = 0.07690000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.151586s
08/04/2016 09:24:48: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.14'

08/04/2016 09:24:48: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: frames [140000..150000] (first sequence at sample 140000), data subset 0 of 1

08/04/2016 09:24:48: Starting minibatch loop.
08/04/2016 09:24:48:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16890872 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0186s; samplesPerSecond = 68943.2
08/04/2016 09:24:48:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16308315 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0192s; samplesPerSecond = 66514.2
08/04/2016 09:24:48:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17382927 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0203s; samplesPerSecond = 63116.4
08/04/2016 09:24:48:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17057834 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0203s; samplesPerSecond = 63094.6
08/04/2016 09:24:48:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18306699 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0200s; samplesPerSecond = 64112.2
08/04/2016 09:24:48:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17019348 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0205s; samplesPerSecond = 62302.3
08/04/2016 09:24:48:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17580585 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0202s; samplesPerSecond = 63306.8
08/04/2016 09:24:48: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.17080481 * 10000; EvalErrorPrediction = 0.07820000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.158322s
08/04/2016 09:24:48: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.15'

08/04/2016 09:24:48: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: frames [150000..160000] (first sequence at sample 150000), data subset 0 of 1

08/04/2016 09:24:48: Starting minibatch loop.
08/04/2016 09:24:48:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15764480 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0206s; samplesPerSecond = 62075.7
08/04/2016 09:24:48:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16706996 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0199s; samplesPerSecond = 64477.1
08/04/2016 09:24:48:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18866863 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0205s; samplesPerSecond = 62408.6
08/04/2016 09:24:48:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16292338 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0205s; samplesPerSecond = 62582.5
08/04/2016 09:24:48:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15786405 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0203s; samplesPerSecond = 63097.7
08/04/2016 09:24:48:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15845280 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0205s; samplesPerSecond = 62451.2
08/04/2016 09:24:48:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15810080 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0203s; samplesPerSecond = 63004.5
08/04/2016 09:24:48: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.16457255 * 10000; EvalErrorPrediction = 0.07830000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.161656s
08/04/2016 09:24:48: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.16'

08/04/2016 09:24:48: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: frames [160000..170000] (first sequence at sample 160000), data subset 0 of 1

08/04/2016 09:24:48: Starting minibatch loop.
08/04/2016 09:24:48:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15267706 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0168s; samplesPerSecond = 76018.5
08/04/2016 09:24:48:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16230602 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0168s; samplesPerSecond = 76354.1
08/04/2016 09:24:48:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16798558 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0177s; samplesPerSecond = 72300.0
08/04/2016 09:24:48:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15736418 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0193s; samplesPerSecond = 66286.9
08/04/2016 09:24:48:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14835858 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0200s; samplesPerSecond = 63885.0
08/04/2016 09:24:48:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15916224 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0200s; samplesPerSecond = 63984.0
08/04/2016 09:24:48:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15667982 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0194s; samplesPerSecond = 65823.3
08/04/2016 09:24:48: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.15823134 * 10000; EvalErrorPrediction = 0.07420000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.147896s
08/04/2016 09:24:48: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.17'

08/04/2016 09:24:48: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: frames [170000..180000] (first sequence at sample 170000), data subset 0 of 1

08/04/2016 09:24:48: Starting minibatch loop.
08/04/2016 09:24:48:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15802855 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0178s; samplesPerSecond = 71805.2
08/04/2016 09:24:48:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15136783 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0196s; samplesPerSecond = 65466.4
08/04/2016 09:24:48:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16910307 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0200s; samplesPerSecond = 63891.4
08/04/2016 09:24:48:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15041537 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0199s; samplesPerSecond = 64189.4
08/04/2016 09:24:48:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18120737 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0187s; samplesPerSecond = 68281.2
08/04/2016 09:24:48:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16757936 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0195s; samplesPerSecond = 65637.7
08/04/2016 09:24:48:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18040800 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0196s; samplesPerSecond = 65286.1
08/04/2016 09:24:48: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.16585511 * 10000; EvalErrorPrediction = 0.07640000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.152703s
08/04/2016 09:24:48: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.18'

08/04/2016 09:24:48: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: frames [180000..190000] (first sequence at sample 180000), data subset 0 of 1

08/04/2016 09:24:48: Starting minibatch loop.
08/04/2016 09:24:48:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15786763 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0182s; samplesPerSecond = 70364.5
08/04/2016 09:24:48:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15283519 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0195s; samplesPerSecond = 65557.0
08/04/2016 09:24:48:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15608346 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0181s; samplesPerSecond = 70823.9
08/04/2016 09:24:48:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16858716 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0159s; samplesPerSecond = 80407.1
08/04/2016 09:24:48:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16090035 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0161s; samplesPerSecond = 79527.8
08/04/2016 09:24:48:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15800047 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0169s; samplesPerSecond = 75712.8
08/04/2016 09:24:48:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16877613 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0191s; samplesPerSecond = 67152.8
08/04/2016 09:24:48: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.15889799 * 10000; EvalErrorPrediction = 0.07400000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.141117s
08/04/2016 09:24:48: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.19'

08/04/2016 09:24:48: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: frames [190000..200000] (first sequence at sample 190000), data subset 0 of 1

08/04/2016 09:24:48: Starting minibatch loop.
08/04/2016 09:24:48:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16419497 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0182s; samplesPerSecond = 70267.9
08/04/2016 09:24:48:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15054171 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0195s; samplesPerSecond = 65657.9
08/04/2016 09:24:48:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15813110 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0171s; samplesPerSecond = 74928.3
08/04/2016 09:24:48:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14632301 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0163s; samplesPerSecond = 78604.8
08/04/2016 09:24:48:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16547060 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0164s; samplesPerSecond = 77934.7
08/04/2016 09:24:48:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17335377 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0186s; samplesPerSecond = 68850.5
08/04/2016 09:24:48:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16311560 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0181s; samplesPerSecond = 70749.5
08/04/2016 09:24:48: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.16047136 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.139286s
08/04/2016 09:24:48: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.20'

08/04/2016 09:24:48: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: frames [200000..210000] (first sequence at sample 200000), data subset 0 of 1

08/04/2016 09:24:48: Starting minibatch loop.
08/04/2016 09:24:49:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15513505 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0184s; samplesPerSecond = 69561.4
08/04/2016 09:24:49:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13780812 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0184s; samplesPerSecond = 69410.6
08/04/2016 09:24:49:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16581757 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0162s; samplesPerSecond = 78817.7
08/04/2016 09:24:49:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16512165 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0164s; samplesPerSecond = 77911.0
08/04/2016 09:24:49:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15497146 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0172s; samplesPerSecond = 74579.0
08/04/2016 09:24:49:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15194440 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0203s; samplesPerSecond = 63051.1
08/04/2016 09:24:49:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19498663 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0205s; samplesPerSecond = 62527.5
08/04/2016 09:24:49: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.16216365 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.146227s
08/04/2016 09:24:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.21'

08/04/2016 09:24:49: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: frames [210000..220000] (first sequence at sample 210000), data subset 0 of 1

08/04/2016 09:24:49: Starting minibatch loop.
08/04/2016 09:24:49:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16610198 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0192s; samplesPerSecond = 66784.9
08/04/2016 09:24:49:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17278922 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0193s; samplesPerSecond = 66153.3
08/04/2016 09:24:49:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16232779 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0198s; samplesPerSecond = 64496.6
08/04/2016 09:24:49:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16299086 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0200s; samplesPerSecond = 64073.7
08/04/2016 09:24:49:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15411987 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0200s; samplesPerSecond = 64038.4
08/04/2016 09:24:49:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16067133 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0194s; samplesPerSecond = 66044.1
08/04/2016 09:24:49:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15162716 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0195s; samplesPerSecond = 65688.2
08/04/2016 09:24:49: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.16191750 * 10000; EvalErrorPrediction = 0.07540000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.15539s
08/04/2016 09:24:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.22'

08/04/2016 09:24:49: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: frames [220000..230000] (first sequence at sample 220000), data subset 0 of 1

08/04/2016 09:24:49: Starting minibatch loop.
08/04/2016 09:24:49:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18393857 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0183s; samplesPerSecond = 69853.7
08/04/2016 09:24:49:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18948307 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0196s; samplesPerSecond = 65153.2
08/04/2016 09:24:49:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15264132 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0200s; samplesPerSecond = 63939.3
08/04/2016 09:24:49:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13502369 * 1280; EvalErrorPrediction = 0.05781250 * 1280; time = 0.0198s; samplesPerSecond = 64656.3
08/04/2016 09:24:49:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18243446 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0192s; samplesPerSecond = 66711.8
08/04/2016 09:24:49:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13560305 * 1280; EvalErrorPrediction = 0.05859375 * 1280; time = 0.0193s; samplesPerSecond = 66338.4
08/04/2016 09:24:49:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16243782 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0201s; samplesPerSecond = 63580.4
08/04/2016 09:24:49: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.16365283 * 10000; EvalErrorPrediction = 0.07530000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.154544s
08/04/2016 09:24:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.23'

08/04/2016 09:24:49: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: frames [230000..240000] (first sequence at sample 230000), data subset 0 of 1

08/04/2016 09:24:49: Starting minibatch loop.
08/04/2016 09:24:49:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14435173 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0175s; samplesPerSecond = 73323.0
08/04/2016 09:24:49:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17693714 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0176s; samplesPerSecond = 72868.0
08/04/2016 09:24:49:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14941821 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0191s; samplesPerSecond = 67068.4
08/04/2016 09:24:49:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16133490 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0204s; samplesPerSecond = 62812.8
08/04/2016 09:24:49:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17285037 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0205s; samplesPerSecond = 62350.8
08/04/2016 09:24:49:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17733898 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0203s; samplesPerSecond = 63057.3
08/04/2016 09:24:49:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17696686 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0205s; samplesPerSecond = 62335.6
08/04/2016 09:24:49: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16434812 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.154675s
08/04/2016 09:24:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.24'

08/04/2016 09:24:49: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: frames [240000..250000] (first sequence at sample 240000), data subset 0 of 1

08/04/2016 09:24:49: Starting minibatch loop.
08/04/2016 09:24:49:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14907920 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0182s; samplesPerSecond = 70194.7
08/04/2016 09:24:49:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18284020 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0195s; samplesPerSecond = 65698.3
08/04/2016 09:24:49:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16321790 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0195s; samplesPerSecond = 65715.2
08/04/2016 09:24:49:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14716640 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0198s; samplesPerSecond = 64653.0
08/04/2016 09:24:49:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17077079 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0202s; samplesPerSecond = 63335.0
08/04/2016 09:24:49:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12733593 * 1280; EvalErrorPrediction = 0.05000000 * 1280; time = 0.0201s; samplesPerSecond = 63700.6
08/04/2016 09:24:49:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16734362 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0203s; samplesPerSecond = 63029.3
08/04/2016 09:24:49: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.15856772 * 10000; EvalErrorPrediction = 0.07350000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.156566s
08/04/2016 09:24:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.25'

08/04/2016 09:24:49: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: frames [250000..260000] (first sequence at sample 250000), data subset 0 of 1

08/04/2016 09:24:49: Starting minibatch loop.
08/04/2016 09:24:49:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17357630 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0184s; samplesPerSecond = 69633.3
08/04/2016 09:24:49:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17141532 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0199s; samplesPerSecond = 64434.9
08/04/2016 09:24:49:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14688165 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0197s; samplesPerSecond = 65024.1
08/04/2016 09:24:49:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15237131 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0195s; samplesPerSecond = 65725.3
08/04/2016 09:24:49:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15460248 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0200s; samplesPerSecond = 64154.0
08/04/2016 09:24:49:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15740733 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0199s; samplesPerSecond = 64260.3
08/04/2016 09:24:49:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17380800 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0201s; samplesPerSecond = 63837.2
08/04/2016 09:24:49: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.16156001 * 10000; EvalErrorPrediction = 0.07360000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.155443s
08/04/2016 09:24:50: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.26'

08/04/2016 09:24:50: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: frames [260000..270000] (first sequence at sample 260000), data subset 0 of 1

08/04/2016 09:24:50: Starting minibatch loop.
08/04/2016 09:24:50:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17107191 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0193s; samplesPerSecond = 66469.3
08/04/2016 09:24:50:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18777130 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0194s; samplesPerSecond = 66013.4
08/04/2016 09:24:50:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16665084 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0193s; samplesPerSecond = 66338.4
08/04/2016 09:24:50:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15284142 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0198s; samplesPerSecond = 64545.4
08/04/2016 09:24:50:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14045067 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0200s; samplesPerSecond = 63964.8
08/04/2016 09:24:50:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15564556 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0202s; samplesPerSecond = 63400.9
08/04/2016 09:24:50:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16763878 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0199s; samplesPerSecond = 64186.1
08/04/2016 09:24:50: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.16426857 * 10000; EvalErrorPrediction = 0.07540000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.15576s
08/04/2016 09:24:50: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.27'

08/04/2016 09:24:50: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: frames [270000..280000] (first sequence at sample 270000), data subset 0 of 1

08/04/2016 09:24:50: Starting minibatch loop.
08/04/2016 09:24:50:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16229638 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0192s; samplesPerSecond = 66778.0
08/04/2016 09:24:50:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12958878 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 0.0188s; samplesPerSecond = 68215.7
08/04/2016 09:24:50:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17073061 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0198s; samplesPerSecond = 64810.1
08/04/2016 09:24:50:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15212483 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0201s; samplesPerSecond = 63640.4
08/04/2016 09:24:50:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16633286 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0195s; samplesPerSecond = 65614.1
08/04/2016 09:24:50:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14801626 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0189s; samplesPerSecond = 67714.1
08/04/2016 09:24:50:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17306166 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0172s; samplesPerSecond = 74263.2
08/04/2016 09:24:50: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.16230472 * 10000; EvalErrorPrediction = 0.07440000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.148552s
08/04/2016 09:24:50: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.28'

08/04/2016 09:24:50: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: frames [280000..290000] (first sequence at sample 280000), data subset 0 of 1

08/04/2016 09:24:50: Starting minibatch loop.
08/04/2016 09:24:50:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16509012 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0193s; samplesPerSecond = 66445.2
08/04/2016 09:24:50:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15534040 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0203s; samplesPerSecond = 62979.7
08/04/2016 09:24:50:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16516867 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0205s; samplesPerSecond = 62305.3
08/04/2016 09:24:50:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18409538 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0202s; samplesPerSecond = 63291.1
08/04/2016 09:24:50:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17486329 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0205s; samplesPerSecond = 62512.2
08/04/2016 09:24:50:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17175627 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0203s; samplesPerSecond = 62948.8
08/04/2016 09:24:50:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17616205 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0204s; samplesPerSecond = 62683.6
08/04/2016 09:24:50: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.16942053 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.160974s
08/04/2016 09:24:50: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.29'

08/04/2016 09:24:50: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: frames [290000..300000] (first sequence at sample 290000), data subset 0 of 1

08/04/2016 09:24:50: Starting minibatch loop.
08/04/2016 09:24:50:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17408118 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0189s; samplesPerSecond = 67703.4
08/04/2016 09:24:50:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17365248 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0198s; samplesPerSecond = 64679.1
08/04/2016 09:24:50:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19392278 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0191s; samplesPerSecond = 66896.6
08/04/2016 09:24:50:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14741282 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0195s; samplesPerSecond = 65573.8
08/04/2016 09:24:50:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17886372 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0202s; samplesPerSecond = 63209.9
08/04/2016 09:24:50:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15128288 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0202s; samplesPerSecond = 63504.7
08/04/2016 09:24:50:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15992451 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0199s; samplesPerSecond = 64205.5
08/04/2016 09:24:50: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.16842340 * 10000; EvalErrorPrediction = 0.07940000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.1555s
08/04/2016 09:24:50: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.30'

08/04/2016 09:24:50: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: frames [300000..310000] (first sequence at sample 300000), data subset 0 of 1

08/04/2016 09:24:50: Starting minibatch loop.
08/04/2016 09:24:50:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16816733 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0187s; samplesPerSecond = 68577.6
08/04/2016 09:24:50:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15148537 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0198s; samplesPerSecond = 64506.4
08/04/2016 09:24:50:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14348426 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0200s; samplesPerSecond = 63901.0
08/04/2016 09:24:50:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16080837 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0197s; samplesPerSecond = 65100.2
08/04/2016 09:24:50:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15488777 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0193s; samplesPerSecond = 66335.0
08/04/2016 09:24:50:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17153234 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0178s; samplesPerSecond = 71958.6
08/04/2016 09:24:50:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15416431 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0159s; samplesPerSecond = 80331.4
08/04/2016 09:24:50: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15978372 * 10000; EvalErrorPrediction = 0.07410000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.14614s
08/04/2016 09:24:50: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.31'

08/04/2016 09:24:50: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: frames [310000..320000] (first sequence at sample 310000), data subset 0 of 1

08/04/2016 09:24:50: Starting minibatch loop.
08/04/2016 09:24:50:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16566252 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0210s; samplesPerSecond = 61074.5
08/04/2016 09:24:50:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17639266 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0203s; samplesPerSecond = 62930.2
08/04/2016 09:24:50:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15591216 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0205s; samplesPerSecond = 62533.6
08/04/2016 09:24:50:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16105003 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0203s; samplesPerSecond = 62945.7
08/04/2016 09:24:50:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14359026 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0207s; samplesPerSecond = 61758.2
08/04/2016 09:24:50:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15249176 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0206s; samplesPerSecond = 62142.0
08/04/2016 09:24:51:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17346363 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0204s; samplesPerSecond = 62868.4
08/04/2016 09:24:51: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.16106814 * 10000; EvalErrorPrediction = 0.07460000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.162846s
08/04/2016 09:24:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.32'

08/04/2016 09:24:51: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: frames [320000..330000] (first sequence at sample 320000), data subset 0 of 1

08/04/2016 09:24:51: Starting minibatch loop.
08/04/2016 09:24:51:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13995804 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0199s; samplesPerSecond = 64218.3
08/04/2016 09:24:51:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16413385 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0198s; samplesPerSecond = 64548.7
08/04/2016 09:24:51:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17222328 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0195s; samplesPerSecond = 65776.0
08/04/2016 09:24:51:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14933004 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0196s; samplesPerSecond = 65352.8
08/04/2016 09:24:51:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16664290 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0188s; samplesPerSecond = 67933.3
08/04/2016 09:24:51:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17443581 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0199s; samplesPerSecond = 64224.8
08/04/2016 09:24:51:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16990538 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0195s; samplesPerSecond = 65597.3
08/04/2016 09:24:51: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.16118888 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.154086s
08/04/2016 09:24:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.33'

08/04/2016 09:24:51: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: frames [330000..340000] (first sequence at sample 330000), data subset 0 of 1

08/04/2016 09:24:51: Starting minibatch loop.
08/04/2016 09:24:51:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17215788 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0185s; samplesPerSecond = 69256.6
08/04/2016 09:24:51:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14596145 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0195s; samplesPerSecond = 65590.6
08/04/2016 09:24:51:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16179433 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0194s; samplesPerSecond = 65911.4
08/04/2016 09:24:51:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16490469 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0193s; samplesPerSecond = 66317.8
08/04/2016 09:24:51:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15579906 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0202s; samplesPerSecond = 63448.0
08/04/2016 09:24:51:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14913197 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0197s; samplesPerSecond = 64987.8
08/04/2016 09:24:51:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16943884 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0199s; samplesPerSecond = 64166.8
08/04/2016 09:24:51: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.16051947 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.154428s
08/04/2016 09:24:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.34'

08/04/2016 09:24:51: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: frames [340000..350000] (first sequence at sample 340000), data subset 0 of 1

08/04/2016 09:24:51: Starting minibatch loop.
08/04/2016 09:24:51:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15814173 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0187s; samplesPerSecond = 68515.1
08/04/2016 09:24:51:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19649644 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0192s; samplesPerSecond = 66729.2
08/04/2016 09:24:51:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15176747 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0191s; samplesPerSecond = 67177.5
08/04/2016 09:24:51:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16053052 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0200s; samplesPerSecond = 64041.6
08/04/2016 09:24:51:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14907022 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0199s; samplesPerSecond = 64334.5
08/04/2016 09:24:51:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14163799 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0192s; samplesPerSecond = 66521.2
08/04/2016 09:24:51:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15548096 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0178s; samplesPerSecond = 72011.3
08/04/2016 09:24:51: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15980056 * 10000; EvalErrorPrediction = 0.07440000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.152074s
08/04/2016 09:24:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.35'

08/04/2016 09:24:51: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: frames [350000..360000] (first sequence at sample 350000), data subset 0 of 1

08/04/2016 09:24:51: Starting minibatch loop.
08/04/2016 09:24:51:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17477604 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0172s; samplesPerSecond = 74327.9
08/04/2016 09:24:51:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15476400 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0160s; samplesPerSecond = 80240.7
08/04/2016 09:24:51:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15660627 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0174s; samplesPerSecond = 73656.3
08/04/2016 09:24:51:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12735906 * 1280; EvalErrorPrediction = 0.05312500 * 1280; time = 0.0184s; samplesPerSecond = 69482.1
08/04/2016 09:24:51:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16778541 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0194s; samplesPerSecond = 65891.1
08/04/2016 09:24:51:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14865680 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0182s; samplesPerSecond = 70318.1
08/04/2016 09:24:51:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16540728 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0191s; samplesPerSecond = 66973.6
08/04/2016 09:24:51: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15641394 * 10000; EvalErrorPrediction = 0.07320000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.143135s
08/04/2016 09:24:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.36'

08/04/2016 09:24:51: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: frames [360000..370000] (first sequence at sample 360000), data subset 0 of 1

08/04/2016 09:24:51: Starting minibatch loop.
08/04/2016 09:24:51:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17414389 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0189s; samplesPerSecond = 67606.8
08/04/2016 09:24:51:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14753783 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0192s; samplesPerSecond = 66521.2
08/04/2016 09:24:51:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15428255 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0201s; samplesPerSecond = 63802.2
08/04/2016 09:24:51:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16764770 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0192s; samplesPerSecond = 66632.0
08/04/2016 09:24:51:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14572754 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0201s; samplesPerSecond = 63726.0
08/04/2016 09:24:51:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16315093 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0196s; samplesPerSecond = 65386.2
08/04/2016 09:24:51:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14469414 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0199s; samplesPerSecond = 64431.7
08/04/2016 09:24:51: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15728765 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.155195s
08/04/2016 09:24:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.37'

08/04/2016 09:24:51: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: frames [370000..380000] (first sequence at sample 370000), data subset 0 of 1

08/04/2016 09:24:51: Starting minibatch loop.
08/04/2016 09:24:51:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15418490 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0192s; samplesPerSecond = 66566.1
08/04/2016 09:24:51:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14476742 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0194s; samplesPerSecond = 66013.4
08/04/2016 09:24:51:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15918562 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0202s; samplesPerSecond = 63241.1
08/04/2016 09:24:51:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16000347 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0201s; samplesPerSecond = 63786.3
08/04/2016 09:24:51:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15878444 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0185s; samplesPerSecond = 69346.6
08/04/2016 09:24:51:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17545919 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0173s; samplesPerSecond = 73843.3
08/04/2016 09:24:51:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18532972 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0177s; samplesPerSecond = 72377.7
08/04/2016 09:24:51: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.16159086 * 10000; EvalErrorPrediction = 0.07720000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.148899s
08/04/2016 09:24:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.38'

08/04/2016 09:24:51: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: frames [380000..390000] (first sequence at sample 380000), data subset 0 of 1

08/04/2016 09:24:51: Starting minibatch loop.
08/04/2016 09:24:52:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19333009 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0181s; samplesPerSecond = 70784.7
08/04/2016 09:24:52:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14980344 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0198s; samplesPerSecond = 64555.2
08/04/2016 09:24:52:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15982034 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0204s; samplesPerSecond = 62822.1
08/04/2016 09:24:52:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16126990 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0205s; samplesPerSecond = 62493.9
08/04/2016 09:24:52:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16446333 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0203s; samplesPerSecond = 62995.2
08/04/2016 09:24:52:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17011127 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0205s; samplesPerSecond = 62542.8
08/04/2016 09:24:52:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15114069 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0203s; samplesPerSecond = 63166.2
08/04/2016 09:24:52: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.16188988 * 10000; EvalErrorPrediction = 0.07460000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.158992s
08/04/2016 09:24:52: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.39'

08/04/2016 09:24:52: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: frames [390000..400000] (first sequence at sample 390000), data subset 0 of 1

08/04/2016 09:24:52: Starting minibatch loop.
08/04/2016 09:24:52:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17255225 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0199s; samplesPerSecond = 64163.6
08/04/2016 09:24:52:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14470704 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0185s; samplesPerSecond = 69376.7
08/04/2016 09:24:52:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15950906 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0168s; samplesPerSecond = 76408.8
08/04/2016 09:24:52:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16513143 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0168s; samplesPerSecond = 76222.2
08/04/2016 09:24:52:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15595059 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0169s; samplesPerSecond = 75569.7
08/04/2016 09:24:52:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15920033 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0184s; samplesPerSecond = 69429.4
08/04/2016 09:24:52:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16088982 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0201s; samplesPerSecond = 63802.2
08/04/2016 09:24:52: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15945464 * 10000; EvalErrorPrediction = 0.07380000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.145496s
08/04/2016 09:24:52: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.40'

08/04/2016 09:24:52: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: frames [400000..410000] (first sequence at sample 400000), data subset 0 of 1

08/04/2016 09:24:52: Starting minibatch loop.
08/04/2016 09:24:52:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15402119 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0199s; samplesPerSecond = 64221.6
08/04/2016 09:24:52:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15783758 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0195s; samplesPerSecond = 65637.7
08/04/2016 09:24:52:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16688983 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0199s; samplesPerSecond = 64292.5
08/04/2016 09:24:52:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16112876 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0200s; samplesPerSecond = 63865.9
08/04/2016 09:24:52:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16222310 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0199s; samplesPerSecond = 64228.0
08/04/2016 09:24:52:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16801291 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0198s; samplesPerSecond = 64679.1
08/04/2016 09:24:52:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17508726 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0195s; samplesPerSecond = 65624.2
08/04/2016 09:24:52: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.16307549 * 10000; EvalErrorPrediction = 0.07490000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.156434s
08/04/2016 09:24:52: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.41'

08/04/2016 09:24:52: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: frames [410000..420000] (first sequence at sample 410000), data subset 0 of 1

08/04/2016 09:24:52: Starting minibatch loop.
08/04/2016 09:24:52:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17599766 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0194s; samplesPerSecond = 65809.8
08/04/2016 09:24:52:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13972726 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0192s; samplesPerSecond = 66715.3
08/04/2016 09:24:52:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16362584 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0176s; samplesPerSecond = 72541.8
08/04/2016 09:24:52:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16537266 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0178s; samplesPerSecond = 72096.4
08/04/2016 09:24:52:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16740761 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0177s; samplesPerSecond = 72120.8
08/04/2016 09:24:52:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14367437 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0206s; samplesPerSecond = 62284.1
08/04/2016 09:24:52:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17447948 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0195s; samplesPerSecond = 65728.7
08/04/2016 09:24:52: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.16078950 * 10000; EvalErrorPrediction = 0.07640000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.149711s
08/04/2016 09:24:52: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.42'

08/04/2016 09:24:52: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: frames [420000..430000] (first sequence at sample 420000), data subset 0 of 1

08/04/2016 09:24:52: Starting minibatch loop.
08/04/2016 09:24:52:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17405897 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0190s; samplesPerSecond = 67407.4
08/04/2016 09:24:52:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16820377 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0178s; samplesPerSecond = 71817.3
08/04/2016 09:24:52:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14057016 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0177s; samplesPerSecond = 72308.2
08/04/2016 09:24:52:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17315536 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0172s; samplesPerSecond = 74293.3
08/04/2016 09:24:52:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16647201 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0169s; samplesPerSecond = 75856.3
08/04/2016 09:24:52:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13567629 * 1280; EvalErrorPrediction = 0.05859375 * 1280; time = 0.0199s; samplesPerSecond = 64341.0
08/04/2016 09:24:52:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16652470 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0204s; samplesPerSecond = 62692.9
08/04/2016 09:24:52: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.16044700 * 10000; EvalErrorPrediction = 0.07590000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.147784s
08/04/2016 09:24:52: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.43'

08/04/2016 09:24:52: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: frames [430000..440000] (first sequence at sample 430000), data subset 0 of 1

08/04/2016 09:24:52: Starting minibatch loop.
08/04/2016 09:24:52:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16785685 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0200s; samplesPerSecond = 63968.0
08/04/2016 09:24:52:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15041660 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0202s; samplesPerSecond = 63309.9
08/04/2016 09:24:52:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16679707 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0199s; samplesPerSecond = 64260.3
08/04/2016 09:24:52:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16997728 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0200s; samplesPerSecond = 64067.3
08/04/2016 09:24:52:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16297808 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0200s; samplesPerSecond = 64041.6
08/04/2016 09:24:52:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15169601 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0200s; samplesPerSecond = 64060.9
08/04/2016 09:24:52:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16470203 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0202s; samplesPerSecond = 63306.8
08/04/2016 09:24:52: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.16023169 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.158083s
08/04/2016 09:24:52: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.44'

08/04/2016 09:24:52: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: frames [440000..450000] (first sequence at sample 440000), data subset 0 of 1

08/04/2016 09:24:52: Starting minibatch loop.
08/04/2016 09:24:53:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13528897 * 1280; EvalErrorPrediction = 0.05937500 * 1280; time = 0.0175s; samplesPerSecond = 73276.8
08/04/2016 09:24:53:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17537030 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0195s; samplesPerSecond = 65489.9
08/04/2016 09:24:53:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15828595 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0197s; samplesPerSecond = 64829.8
08/04/2016 09:24:53:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15823574 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0200s; samplesPerSecond = 63891.4
08/04/2016 09:24:53:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17283478 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0178s; samplesPerSecond = 71962.7
08/04/2016 09:24:53:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17052946 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0192s; samplesPerSecond = 66528.1
08/04/2016 09:24:53:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16962852 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0195s; samplesPerSecond = 65681.4
08/04/2016 09:24:53: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.16324283 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.151378s
08/04/2016 09:24:53: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.45'

08/04/2016 09:24:53: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: frames [450000..460000] (first sequence at sample 450000), data subset 0 of 1

08/04/2016 09:24:53: Starting minibatch loop.
08/04/2016 09:24:53:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17114687 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0186s; samplesPerSecond = 68924.7
08/04/2016 09:24:53:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17295887 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0178s; samplesPerSecond = 72047.7
08/04/2016 09:24:53:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17313998 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0177s; samplesPerSecond = 72242.9
08/04/2016 09:24:53:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13074102 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0175s; samplesPerSecond = 73080.2
08/04/2016 09:24:53:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14684887 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0170s; samplesPerSecond = 75476.1
08/04/2016 09:24:53:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16526961 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0196s; samplesPerSecond = 65256.2
08/04/2016 09:24:53:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14926205 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0205s; samplesPerSecond = 62384.2
08/04/2016 09:24:53: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.15781416 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.147356s
08/04/2016 09:24:53: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.46'

08/04/2016 09:24:53: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: frames [460000..470000] (first sequence at sample 460000), data subset 0 of 1

08/04/2016 09:24:53: Starting minibatch loop.
08/04/2016 09:24:53:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16658335 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0204s; samplesPerSecond = 62778.9
08/04/2016 09:24:53:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17260134 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0200s; samplesPerSecond = 64121.8
08/04/2016 09:24:53:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16528909 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0200s; samplesPerSecond = 63939.3
08/04/2016 09:24:53:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15832253 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0197s; samplesPerSecond = 64921.9
08/04/2016 09:24:53:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16895666 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0203s; samplesPerSecond = 63169.3
08/04/2016 09:24:53:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16030579 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0190s; samplesPerSecond = 67241.0
08/04/2016 09:24:53:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14917755 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0203s; samplesPerSecond = 62939.5
08/04/2016 09:24:53: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.16155321 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.158644s
08/04/2016 09:24:53: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.47'

08/04/2016 09:24:53: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: frames [470000..480000] (first sequence at sample 470000), data subset 0 of 1

08/04/2016 09:24:53: Starting minibatch loop.
08/04/2016 09:24:53:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17929769 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0197s; samplesPerSecond = 64885.7
08/04/2016 09:24:53:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15065165 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0191s; samplesPerSecond = 67100.0
08/04/2016 09:24:53:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16674352 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0189s; samplesPerSecond = 67681.9
08/04/2016 09:24:53:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15457792 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0199s; samplesPerSecond = 64473.9
08/04/2016 09:24:53:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14541187 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0197s; samplesPerSecond = 65001.0
08/04/2016 09:24:53:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15152359 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0197s; samplesPerSecond = 64925.2
08/04/2016 09:24:53:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19150448 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0189s; samplesPerSecond = 67578.3
08/04/2016 09:24:53: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.16183502 * 10000; EvalErrorPrediction = 0.07460000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.153721s
08/04/2016 09:24:53: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.48'

08/04/2016 09:24:53: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: frames [480000..490000] (first sequence at sample 480000), data subset 0 of 1

08/04/2016 09:24:53: Starting minibatch loop.
08/04/2016 09:24:53:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15728606 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0180s; samplesPerSecond = 71146.7
08/04/2016 09:24:53:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14731427 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0195s; samplesPerSecond = 65630.9
08/04/2016 09:24:53:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15648661 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0200s; samplesPerSecond = 64086.5
08/04/2016 09:24:53:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16737189 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0199s; samplesPerSecond = 64344.2
08/04/2016 09:24:53:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15252876 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0200s; samplesPerSecond = 63894.6
08/04/2016 09:24:53:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16501975 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0192s; samplesPerSecond = 66593.8
08/04/2016 09:24:53:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15813417 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0201s; samplesPerSecond = 63780.0
08/04/2016 09:24:53: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.15846066 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.154963s
08/04/2016 09:24:53: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.49'

08/04/2016 09:24:53: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

08/04/2016 09:24:53: Starting minibatch loop.
08/04/2016 09:24:53:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16532567 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0185s; samplesPerSecond = 69058.5
08/04/2016 09:24:53:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16466892 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0191s; samplesPerSecond = 66875.7
08/04/2016 09:24:53:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16055660 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0193s; samplesPerSecond = 66431.4
08/04/2016 09:24:53:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17406416 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0193s; samplesPerSecond = 66221.7
08/04/2016 09:24:53:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14430056 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0188s; samplesPerSecond = 67976.6
08/04/2016 09:24:53:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14083948 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0189s; samplesPerSecond = 67872.1
08/04/2016 09:24:53:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15626698 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0178s; samplesPerSecond = 72112.7
08/04/2016 09:24:53: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15844924 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.148051s
08/04/2016 09:24:53: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn'
08/04/2016 09:24:53: CNTKCommandTrainEnd: Simple_Demo

08/04/2016 09:24:53: Action "train" complete.


08/04/2016 09:24:53: ##############################################################################
08/04/2016 09:24:53: #                                                                            #
08/04/2016 09:24:53: # Action "write"                                                             #
08/04/2016 09:24:53: #                                                                            #
08/04/2016 09:24:53: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *1]] [W0*features+B0 Gradient[50 x 1 x *1]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
000000BB1875CF70: {[B0 Value[50 x 1]] }
000000BB1875D010: {[features Value[2 x *1]] }
000000BB1875D150: {[B1 Value[50 x 1]] }
000000BB1875D330: {[B2 Value[2 x 1]] }
000000BB73DCB810: {[W1*H1+B1 Value[50 x 1 x *1]] }
000000BB73DCB9F0: {[H2 Value[50 x 1 x *1]] }
000000BB73DCBBD0: {[W0*features+B0 Value[50 x 1 x *1]] }
000000BB73DCBC70: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
000000BB73DCBD10: {[H1 Value[50 x 1 x *1]] }
000000BB73DCBDB0: {[LogOfPrior Value[2]] }
000000BB73DCBE50: {[HLast Value[2 x 1 x *1]] }
000000BB73DCC170: {[MVNormalizedFeatures Value[2 x *1]] }
000000BB73DCC210: {[W0*features Value[50 x *1]] }
000000BB73DCC2B0: {[W2 Value[2 x 50]] }
000000BB73DCC350: {[W1*H1 Value[50 x 1 x *1]] }
000000BB73DCC530: {[W2*H1 Value[2 x 1 x *1]] }
000000BB7CA6D090: {[W0 Value[50 x 2]] }
000000BB7CA6D450: {[MeanOfFeatures Value[2]] }
000000BB7CA6D630: {[labels Value[2 x *1]] }
000000BB7CA6D6D0: {[W1 Value[50 x 50]] }
000000BB7CA6DE50: {[InvStdOfFeatures Value[2]] }
000000BB7CA6DF90: {[Prior Value[2]] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/SimpleOutput*
Total Samples Evaluated = 603

08/04/2016 09:24:54: Action "write" complete.

08/04/2016 09:24:54: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu DeviceId=0 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug  4 2016 06:18:04
		Last modified date: Thu Aug  4 03:39:14 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
		Built by svcphil on dphaim-26-new
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows@3\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
08/04/2016 09:24:55: -------------------------------------------------------------------
08/04/2016 09:24:55: Build info: 

08/04/2016 09:24:55: 		Built time: Aug  4 2016 06:18:04
08/04/2016 09:24:55: 		Last modified date: Thu Aug  4 03:39:14 2016
08/04/2016 09:24:55: 		Build type: Release
08/04/2016 09:24:55: 		Build target: GPU
08/04/2016 09:24:55: 		With 1bit-SGD: no
08/04/2016 09:24:55: 		Math lib: mkl
08/04/2016 09:24:55: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/04/2016 09:24:55: 		CUB_PATH: C:\src\cub-1.4.1
08/04/2016 09:24:55: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
08/04/2016 09:24:55: 		Build Branch: HEAD
08/04/2016 09:24:55: 		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
08/04/2016 09:24:55: 		Built by svcphil on dphaim-26-new
08/04/2016 09:24:55: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows@3\Source\CNTK\
08/04/2016 09:24:55: -------------------------------------------------------------------
08/04/2016 09:24:55: -------------------------------------------------------------------
08/04/2016 09:24:55: GPU info:

08/04/2016 09:24:55: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8192 MB
08/04/2016 09:24:55: -------------------------------------------------------------------

08/04/2016 09:24:55: Running on cntk-muc02 at 2016/08/04 09:24:55
08/04/2016 09:24:55: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu  DeviceId=0  timestamping=true  makeMode=true



08/04/2016 09:24:55: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/04/2016 09:24:55: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu
DeviceId=0
timestamping=true
makeMode=true

08/04/2016 09:24:55: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/04/2016 09:24:55: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/04/2016 09:24:55: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu
DeviceId=0
timestamping=true
makeMode=true

08/04/2016 09:24:55: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/04/2016 09:24:55: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=0
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/04/2016 09:24:55: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/04/2016 09:24:55: Commands: Simple_Demo Simple_Demo_Output
08/04/2016 09:24:55: Precision = "float"
08/04/2016 09:24:55: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn
08/04/2016 09:24:55: CNTKCommandTrainInfo: Simple_Demo : 50
08/04/2016 09:24:55: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/04/2016 09:24:55: ##############################################################################
08/04/2016 09:24:55: #                                                                            #
08/04/2016 09:24:55: # Action "train"                                                             #
08/04/2016 09:24:55: #                                                                            #
08/04/2016 09:24:55: ##############################################################################

08/04/2016 09:24:55: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using GPU 0

08/04/2016 09:24:55: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/04/2016 09:24:55: Loaded model with 25 nodes on GPU 0.

08/04/2016 09:24:55: Training criterion node(s):
08/04/2016 09:24:55: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/04/2016 09:24:55: Evaluation criterion node(s):

08/04/2016 09:24:55: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
00000026A11C3EF0: {[MeanOfFeatures Value[2]] }
00000026A11C40D0: {[W1 Value[50 x 50]] }
00000026A11C4A30: {[Prior Value[2]] }
00000026A11C4CB0: {[B1 Value[50 x 1]] }
00000026A11C4D50: {[labels Value[2 x *1]] }
00000026A11C4F30: {[InvStdOfFeatures Value[2]] }
00000026A11C5070: {[B2 Value[2 x 1]] }
00000026A11C56B0: {[W0 Value[50 x 2]] }
00000026A11C5750: {[features Value[2 x *1]] }
00000026A1509640: {[EvalErrorPrediction Value[1]] }
00000026A1509820: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *1]] }
00000026A1509A00: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2*H1 Value[2 x 1 x *1]] }
00000026A1509B40: {[B2 Gradient[2 x 1]] }
00000026A1509E60: {[W0*features Value[50 x *1]] }
00000026A150A040: {[MVNormalizedFeatures Value[2 x *1]] }
00000026A150A0E0: {[H2 Value[50 x 1 x *1]] [W1*H1 Gradient[50 x 1 x *1]] }
00000026A150A180: {[CrossEntropyWithSoftmax Gradient[1]] }
00000026A150A220: {[LogOfPrior Value[2]] }
00000026A150A5E0: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
00000026A150A680: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *1]] }
00000026A150AAE0: {[W0*features+B0 Gradient[50 x 1 x *1]] [W1*H1 Value[50 x 1 x *1]] }
00000026A150AB80: {[H1 Value[50 x 1 x *1]] [W0*features Gradient[50 x *1]] }
00000026A150AD60: {[W2 Value[2 x 50]] }
00000026A150AF40: {[CrossEntropyWithSoftmax Value[1]] }
00000026A150AFE0: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] }
00000026A150B080: {[W2*H1 Gradient[2 x 1 x *1]] }
00000026A150B1C0: {[HLast Value[2 x 1 x *1]] [W2 Gradient[2 x 50]] }
00000026ACEA1EE0: {[B0 Value[50 x 1]] }

08/04/2016 09:24:55: No PreCompute nodes found, skipping PreCompute step.

08/04/2016 09:24:55: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

08/04/2016 09:24:55: Starting minibatch loop.
08/04/2016 09:24:56:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.16532567 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.2017s; samplesPerSecond = 6345.5
08/04/2016 09:24:56:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.16466892 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0175s; samplesPerSecond = 73105.3
08/04/2016 09:24:56:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.16055660 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0174s; samplesPerSecond = 73365.0
08/04/2016 09:24:56:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.17406416 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0176s; samplesPerSecond = 72917.9
08/04/2016 09:24:56:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.14430056 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0180s; samplesPerSecond = 71202.1
08/04/2016 09:24:56:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.14083948 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0191s; samplesPerSecond = 67012.2
08/04/2016 09:24:56:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.15626698 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0171s; samplesPerSecond = 74679.1
08/04/2016 09:24:56: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15844924 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.326394s
08/04/2016 09:24:56: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/models/simple.dnn'
08/04/2016 09:24:56: CNTKCommandTrainEnd: Simple_Demo

08/04/2016 09:24:56: Action "train" complete.


08/04/2016 09:24:56: ##############################################################################
08/04/2016 09:24:56: #                                                                            #
08/04/2016 09:24:56: # Action "write"                                                             #
08/04/2016 09:24:56: #                                                                            #
08/04/2016 09:24:56: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *2]] [H2 Gradient[50 x 1 x *2]] [HLast Gradient[2 x 1 x *2]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *2]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *2]] [PosteriorProb Value[2 x 1 x *2]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *2]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *2]] [W0*features+B0 Gradient[50 x 1 x *2]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *2]] [W1*H1+B1 Gradient[50 x 1 x *2]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *2]] [features Gradient[2 x *2]] [labels Gradient[2 x *2]] }
00000026A1509500: {[W1 Value[50 x 50]] }
00000026A15095A0: {[HLast Value[2 x 1 x *2]] }
00000026A1509820: {[LogOfPrior Value[2]] }
00000026A1509A00: {[H1 Value[50 x 1 x *2]] }
00000026A1509AA0: {[W0*features Value[50 x *2]] }
00000026A1509C80: {[H2 Value[50 x 1 x *2]] }
00000026A150A040: {[W2 Value[2 x 50]] }
00000026A150A2C0: {[W1*H1+B1 Value[50 x 1 x *2]] }
00000026A150A400: {[ScaledLogLikelihood Value[2 x 1 x *2]] }
00000026A150AB80: {[MVNormalizedFeatures Value[2 x *2]] }
00000026A150AD60: {[W0*features+B0 Value[50 x 1 x *2]] }
00000026A150B1C0: {[W1*H1 Value[50 x 1 x *2]] }
00000026A150B260: {[W2*H1 Value[2 x 1 x *2]] }
00000026BBDAD260: {[features Value[2 x *2]] }
00000026BBDAD300: {[B0 Value[50 x 1]] }
00000026BBDAD9E0: {[InvStdOfFeatures Value[2]] }
00000026BBDADEE0: {[B2 Value[2 x 1]] }
00000026BBDAE160: {[Prior Value[2]] }
00000026BBDAE5C0: {[MeanOfFeatures Value[2]] }
00000026BBDAE700: {[labels Value[2 x *2]] }
00000026BBDAED40: {[W0 Value[50 x 2]] }
00000026BBDAEDE0: {[B1 Value[50 x 1]] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_gpu/SimpleOutput*
Total Samples Evaluated = 603

08/04/2016 09:24:56: Action "write" complete.

08/04/2016 09:24:56: __COMPLETED__