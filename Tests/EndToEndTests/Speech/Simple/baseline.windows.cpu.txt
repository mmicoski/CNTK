CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU W3550 @ 3.07GHz
    Hardware threads: 4
    Total Memory: 12580388 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu DeviceId=-1 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug  4 2016 06:18:04
		Last modified date: Thu Aug  4 03:39:14 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
		Built by svcphil on dphaim-26-new
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows@3\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
08/04/2016 09:24:33: -------------------------------------------------------------------
08/04/2016 09:24:33: Build info: 

08/04/2016 09:24:33: 		Built time: Aug  4 2016 06:18:04
08/04/2016 09:24:33: 		Last modified date: Thu Aug  4 03:39:14 2016
08/04/2016 09:24:33: 		Build type: Release
08/04/2016 09:24:33: 		Build target: GPU
08/04/2016 09:24:33: 		With 1bit-SGD: no
08/04/2016 09:24:33: 		Math lib: mkl
08/04/2016 09:24:33: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/04/2016 09:24:33: 		CUB_PATH: C:\src\cub-1.4.1
08/04/2016 09:24:33: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
08/04/2016 09:24:33: 		Build Branch: HEAD
08/04/2016 09:24:33: 		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
08/04/2016 09:24:33: 		Built by svcphil on dphaim-26-new
08/04/2016 09:24:33: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows@3\Source\CNTK\
08/04/2016 09:24:33: -------------------------------------------------------------------
08/04/2016 09:24:33: -------------------------------------------------------------------
08/04/2016 09:24:33: GPU info:

08/04/2016 09:24:33: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8192 MB
08/04/2016 09:24:33: -------------------------------------------------------------------

08/04/2016 09:24:33: Running on cntk-muc02 at 2016/08/04 09:24:33
08/04/2016 09:24:33: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true



08/04/2016 09:24:33: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/04/2016 09:24:33: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

08/04/2016 09:24:33: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/04/2016 09:24:33: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/04/2016 09:24:33: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

08/04/2016 09:24:33: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/04/2016 09:24:33: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/04/2016 09:24:33: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/04/2016 09:24:33: Commands: Simple_Demo Simple_Demo_Output
08/04/2016 09:24:33: Precision = "float"
08/04/2016 09:24:33: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn
08/04/2016 09:24:33: CNTKCommandTrainInfo: Simple_Demo : 50
08/04/2016 09:24:33: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/04/2016 09:24:33: ##############################################################################
08/04/2016 09:24:33: #                                                                            #
08/04/2016 09:24:33: # Action "train"                                                             #
08/04/2016 09:24:33: #                                                                            #
08/04/2016 09:24:33: ##############################################################################

08/04/2016 09:24:33: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

08/04/2016 09:24:33: Creating virgin network.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/04/2016 09:24:33: Created model with 25 nodes on CPU.

08/04/2016 09:24:33: Training criterion node(s):
08/04/2016 09:24:33: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/04/2016 09:24:33: Evaluation criterion node(s):

08/04/2016 09:24:33: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *]] [PosteriorProb Value[2 x 1 x *]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *]] [features Gradient[2 x *]] [labels Gradient[2 x *]] }
000000F1B143B730: {[B0 Value[50 x 1]] }
000000F1B143B7D0: {[W1 Value[50 x 50]] }
000000F1B143BA50: {[B1 Value[50 x 1]] }
000000F1B143BCD0: {[features Value[2 x *]] }
000000F1B143BE10: {[MeanOfFeatures Value[2]] }
000000F1B143BF50: {[InvStdOfFeatures Value[2]] }
000000F1B143C1D0: {[W0 Value[50 x 2]] }
000000F1B43B4480: {[Prior Value[2]] }
000000F1B43B45C0: {[EvalErrorPrediction Value[1]] }
000000F1B43B4660: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *]] }
000000F1B43B4700: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *]] [HLast Gradient[2 x 1 x *]] }
000000F1B43B47A0: {[CrossEntropyWithSoftmax Gradient[1]] }
000000F1B43B4A20: {[LogOfPrior Value[2]] }
000000F1B43B4CA0: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *]] [W1*H1+B1 Gradient[50 x 1 x *]] [W2*H1 Value[2 x 1 x *]] }
000000F1B43B4DE0: {[W0*features Value[50 x *]] }
000000F1B43B4E80: {[H1 Value[50 x 1 x *]] [W0*features Gradient[50 x *]] }
000000F1B43B5060: {[CrossEntropyWithSoftmax Value[1]] }
000000F1B43B5100: {[W2*H1 Gradient[2 x 1 x *]] }
000000F1B43B5420: {[B2 Value[2 x 1]] }
000000F1B43B54C0: {[W0*features+B0 Gradient[50 x 1 x *]] [W1*H1 Value[50 x 1 x *]] }
000000F1B43B5560: {[H2 Value[50 x 1 x *]] [W1*H1 Gradient[50 x 1 x *]] }
000000F1B43B56A0: {[B2 Gradient[2 x 1]] }
000000F1B43B5740: {[HLast Value[2 x 1 x *]] [W2 Gradient[2 x 50]] }
000000F1B43B57E0: {[W2 Value[2 x 50]] }
000000F1B43B5A60: {[MVNormalizedFeatures Value[2 x *]] }
000000F1B43B5BA0: {[ScaledLogLikelihood Value[2 x 1 x *]] }
000000F1B43B5E20: {[labels Value[2 x *]] }
000000F1B43B61E0: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *]] }


08/04/2016 09:24:33: Precomputing --> 3 PreCompute nodes found.

08/04/2016 09:24:33: 	MeanOfFeatures = Mean()
08/04/2016 09:24:33: 	InvStdOfFeatures = InvStdDev()
08/04/2016 09:24:33: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

08/04/2016 09:24:34: Precomputing --> Completed.


08/04/2016 09:24:34: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

08/04/2016 09:24:34: Starting minibatch loop.
08/04/2016 09:24:34:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.72675591 * 1280; EvalErrorPrediction = 0.47734375 * 1280; time = 0.0176s; samplesPerSecond = 72880.5
08/04/2016 09:24:34:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.77477198 * 1280; EvalErrorPrediction = 0.46562500 * 1280; time = 0.0147s; samplesPerSecond = 86992.0
08/04/2016 09:24:34:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.72862463 * 1280; EvalErrorPrediction = 0.50546875 * 1280; time = 0.0147s; samplesPerSecond = 87157.8
08/04/2016 09:24:34:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.69235344 * 1280; EvalErrorPrediction = 0.48281250 * 1280; time = 0.0147s; samplesPerSecond = 87276.7
08/04/2016 09:24:34:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.65981674 * 1280; EvalErrorPrediction = 0.38984375 * 1280; time = 0.0146s; samplesPerSecond = 87545.3
08/04/2016 09:24:34:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.50734596 * 1280; EvalErrorPrediction = 0.11875000 * 1280; time = 0.0146s; samplesPerSecond = 87707.3
08/04/2016 09:24:34:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.19461136 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0145s; samplesPerSecond = 88227.2
08/04/2016 09:24:34: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.56532046 * 10000; EvalErrorPrediction = 0.32780000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.128265s
08/04/2016 09:24:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.1'

08/04/2016 09:24:34: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: frames [10000..20000] (first sequence at sample 10000), data subset 0 of 1

08/04/2016 09:24:34: Starting minibatch loop.
08/04/2016 09:24:34:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.23876138 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0166s; samplesPerSecond = 77322.7
08/04/2016 09:24:34:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.32010574 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0146s; samplesPerSecond = 87785.5
08/04/2016 09:24:34:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.30655484 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0155s; samplesPerSecond = 82415.8
08/04/2016 09:24:34:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.30482855 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0145s; samplesPerSecond = 88093.6
08/04/2016 09:24:34:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.21586790 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0145s; samplesPerSecond = 88544.5
08/04/2016 09:24:34:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.23753290 * 1280; EvalErrorPrediction = 0.09531250 * 1280; time = 0.0145s; samplesPerSecond = 88136.1
08/04/2016 09:24:34:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.20178528 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0147s; samplesPerSecond = 86885.7
08/04/2016 09:24:34: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.25272761 * 10000; EvalErrorPrediction = 0.08170000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.121562s
08/04/2016 09:24:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.2'

08/04/2016 09:24:34: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: frames [20000..30000] (first sequence at sample 20000), data subset 0 of 1

08/04/2016 09:24:34: Starting minibatch loop.
08/04/2016 09:24:34:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17463797 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0150s; samplesPerSecond = 85401.7
08/04/2016 09:24:34:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19916285 * 1280; EvalErrorPrediction = 0.09296875 * 1280; time = 0.0147s; samplesPerSecond = 86980.2
08/04/2016 09:24:34:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17840183 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0147s; samplesPerSecond = 87193.5
08/04/2016 09:24:34:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18710403 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0147s; samplesPerSecond = 87003.8
08/04/2016 09:24:34:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16096549 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0146s; samplesPerSecond = 87557.3
08/04/2016 09:24:34:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16064320 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0146s; samplesPerSecond = 87918.1
08/04/2016 09:24:34:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15436840 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0145s; samplesPerSecond = 88318.5
08/04/2016 09:24:34: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.17180471 * 10000; EvalErrorPrediction = 0.07780000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.119245s
08/04/2016 09:24:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.3'

08/04/2016 09:24:34: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: frames [30000..40000] (first sequence at sample 30000), data subset 0 of 1

08/04/2016 09:24:34: Starting minibatch loop.
08/04/2016 09:24:34:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15711856 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0150s; samplesPerSecond = 85550.1
08/04/2016 09:24:34:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16927757 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0147s; samplesPerSecond = 86879.8
08/04/2016 09:24:34:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15494585 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0146s; samplesPerSecond = 87611.2
08/04/2016 09:24:34:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15691328 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0147s; samplesPerSecond = 87282.6
08/04/2016 09:24:34:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17719522 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0146s; samplesPerSecond = 87731.3
08/04/2016 09:24:34:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16222134 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0145s; samplesPerSecond = 88403.9
08/04/2016 09:24:34:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17385931 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0145s; samplesPerSecond = 88245.4
08/04/2016 09:24:34: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.16146766 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.119069s
08/04/2016 09:24:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.4'

08/04/2016 09:24:34: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: frames [40000..50000] (first sequence at sample 40000), data subset 0 of 1

08/04/2016 09:24:34: Starting minibatch loop.
08/04/2016 09:24:34:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16416658 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0149s; samplesPerSecond = 85658.8
08/04/2016 09:24:34:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17445260 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0147s; samplesPerSecond = 86838.5
08/04/2016 09:24:34:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15520258 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0147s; samplesPerSecond = 87235.1
08/04/2016 09:24:34:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15464740 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0146s; samplesPerSecond = 87551.3
08/04/2016 09:24:34:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17294130 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0146s; samplesPerSecond = 87857.8
08/04/2016 09:24:34:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16416721 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0145s; samplesPerSecond = 88422.2
08/04/2016 09:24:34:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16201639 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0146s; samplesPerSecond = 87900.0
08/04/2016 09:24:34: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.16093459 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.119026s
08/04/2016 09:24:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.5'

08/04/2016 09:24:34: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: frames [50000..60000] (first sequence at sample 50000), data subset 0 of 1

08/04/2016 09:24:34: Starting minibatch loop.
08/04/2016 09:24:34:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16041746 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0150s; samplesPerSecond = 85487.2
08/04/2016 09:24:34:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16527381 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0146s; samplesPerSecond = 87401.8
08/04/2016 09:24:34:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15017257 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0146s; samplesPerSecond = 87605.2
08/04/2016 09:24:34:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13567896 * 1280; EvalErrorPrediction = 0.05937500 * 1280; time = 0.0146s; samplesPerSecond = 87797.5
08/04/2016 09:24:34:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14168000 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0146s; samplesPerSecond = 87737.3
08/04/2016 09:24:34:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17326827 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0146s; samplesPerSecond = 87881.9
08/04/2016 09:24:34:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17048359 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0146s; samplesPerSecond = 87809.6
08/04/2016 09:24:34: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.16009170 * 10000; EvalErrorPrediction = 0.07470000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.119001s
08/04/2016 09:24:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.6'

08/04/2016 09:24:34: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: frames [60000..70000] (first sequence at sample 60000), data subset 0 of 1

08/04/2016 09:24:34: Starting minibatch loop.
08/04/2016 09:24:34:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16238555 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0149s; samplesPerSecond = 86015.7
08/04/2016 09:24:34:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15796639 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0145s; samplesPerSecond = 88130.0
08/04/2016 09:24:34:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16144853 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0146s; samplesPerSecond = 87936.2
08/04/2016 09:24:34:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16109586 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0146s; samplesPerSecond = 87863.8
08/04/2016 09:24:34:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16215148 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0147s; samplesPerSecond = 87270.7
08/04/2016 09:24:34:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18283014 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0146s; samplesPerSecond = 87845.7
08/04/2016 09:24:34:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14221907 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0145s; samplesPerSecond = 88575.2
08/04/2016 09:24:34: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.16221421 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.118657s
08/04/2016 09:24:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.7'

08/04/2016 09:24:34: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: frames [70000..80000] (first sequence at sample 70000), data subset 0 of 1

08/04/2016 09:24:34: Starting minibatch loop.
08/04/2016 09:24:34:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17869349 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0147s; samplesPerSecond = 86791.4
08/04/2016 09:24:35:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16913075 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0146s; samplesPerSecond = 87803.5
08/04/2016 09:24:35:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17272568 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0148s; samplesPerSecond = 86609.4
08/04/2016 09:24:35:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17325859 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0154s; samplesPerSecond = 83355.0
08/04/2016 09:24:35:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16214824 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0145s; samplesPerSecond = 88385.6
08/04/2016 09:24:35:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14548283 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0145s; samplesPerSecond = 88513.9
08/04/2016 09:24:35:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14632044 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0144s; samplesPerSecond = 89105.5
08/04/2016 09:24:35: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.16492756 * 10000; EvalErrorPrediction = 0.07470000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.119203s
08/04/2016 09:24:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.8'

08/04/2016 09:24:35: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: frames [80000..90000] (first sequence at sample 80000), data subset 0 of 1

08/04/2016 09:24:35: Starting minibatch loop.
08/04/2016 09:24:35:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16760304 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0149s; samplesPerSecond = 86079.4
08/04/2016 09:24:35:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15157678 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0146s; samplesPerSecond = 87833.7
08/04/2016 09:24:35:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17359042 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0151s; samplesPerSecond = 84869.4
08/04/2016 09:24:35:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16399121 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0146s; samplesPerSecond = 87455.6
08/04/2016 09:24:35:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.20167885 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0153s; samplesPerSecond = 83769.6
08/04/2016 09:24:35:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16135578 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0150s; samplesPerSecond = 85163.0
08/04/2016 09:24:35:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15681486 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0145s; samplesPerSecond = 88190.7
08/04/2016 09:24:35: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.16556660 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.120384s
08/04/2016 09:24:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.9'

08/04/2016 09:24:35: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: frames [90000..100000] (first sequence at sample 90000), data subset 0 of 1

08/04/2016 09:24:35: Starting minibatch loop.
08/04/2016 09:24:35:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17514851 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0147s; samplesPerSecond = 87128.2
08/04/2016 09:24:35:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16324730 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0147s; samplesPerSecond = 87336.2
08/04/2016 09:24:35:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17278378 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0145s; samplesPerSecond = 88385.6
08/04/2016 09:24:35:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16541038 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0158s; samplesPerSecond = 81249.2
08/04/2016 09:24:35:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15411234 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0145s; samplesPerSecond = 88355.1
08/04/2016 09:24:35:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15369711 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0144s; samplesPerSecond = 88716.4
08/04/2016 09:24:35:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16190395 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0145s; samplesPerSecond = 88403.9
08/04/2016 09:24:35: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.16913378 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.119245s
08/04/2016 09:24:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.10'

08/04/2016 09:24:35: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: frames [100000..110000] (first sequence at sample 100000), data subset 0 of 1

08/04/2016 09:24:35: Starting minibatch loop.
08/04/2016 09:24:35:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16674324 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0148s; samplesPerSecond = 86247.6
08/04/2016 09:24:35:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17134408 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0145s; samplesPerSecond = 88184.6
08/04/2016 09:24:35:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17461047 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0145s; samplesPerSecond = 88556.8
08/04/2016 09:24:35:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16201138 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0157s; samplesPerSecond = 81721.3
08/04/2016 09:24:35:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15794187 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0146s; samplesPerSecond = 87881.9
08/04/2016 09:24:35:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16354799 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0145s; samplesPerSecond = 88379.5
08/04/2016 09:24:35:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14419966 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0144s; samplesPerSecond = 88587.4
08/04/2016 09:24:35: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16278403 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.119397s
08/04/2016 09:24:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.11'

08/04/2016 09:24:35: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: frames [110000..120000] (first sequence at sample 110000), data subset 0 of 1

08/04/2016 09:24:35: Starting minibatch loop.
08/04/2016 09:24:35:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15064534 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0148s; samplesPerSecond = 86738.5
08/04/2016 09:24:35:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17868544 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0146s; samplesPerSecond = 87863.8
08/04/2016 09:24:35:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17257438 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0160s; samplesPerSecond = 80055.0
08/04/2016 09:24:35:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15488348 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0145s; samplesPerSecond = 88458.9
08/04/2016 09:24:35:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15025730 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0145s; samplesPerSecond = 88251.5
08/04/2016 09:24:35:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17353544 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0145s; samplesPerSecond = 88569.1
08/04/2016 09:24:35:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15665979 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0144s; samplesPerSecond = 88642.7
08/04/2016 09:24:35: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16366721 * 10000; EvalErrorPrediction = 0.07380000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.11963s
08/04/2016 09:24:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.12'

08/04/2016 09:24:35: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: frames [120000..130000] (first sequence at sample 120000), data subset 0 of 1

08/04/2016 09:24:35: Starting minibatch loop.
08/04/2016 09:24:35:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19339819 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0148s; samplesPerSecond = 86703.2
08/04/2016 09:24:35:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19745948 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0146s; samplesPerSecond = 87863.8
08/04/2016 09:24:35:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16066325 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0158s; samplesPerSecond = 80920.5
08/04/2016 09:24:35:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18645759 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0146s; samplesPerSecond = 87839.7
08/04/2016 09:24:35:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18124270 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0144s; samplesPerSecond = 88581.3
08/04/2016 09:24:35:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15986290 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0144s; samplesPerSecond = 88784.1
08/04/2016 09:24:35:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15541077 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0144s; samplesPerSecond = 88864.2
08/04/2016 09:24:35: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.17610636 * 10000; EvalErrorPrediction = 0.08050000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.119428s
08/04/2016 09:24:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.13'

08/04/2016 09:24:35: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: frames [130000..140000] (first sequence at sample 130000), data subset 0 of 1

08/04/2016 09:24:35: Starting minibatch loop.
08/04/2016 09:24:35:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17031057 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0148s; samplesPerSecond = 86691.5
08/04/2016 09:24:35:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14735816 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0146s; samplesPerSecond = 87653.2
08/04/2016 09:24:35:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17346001 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0161s; samplesPerSecond = 79716.0
08/04/2016 09:24:35:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16896081 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0145s; samplesPerSecond = 88294.1
08/04/2016 09:24:35:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16787095 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0145s; samplesPerSecond = 88422.2
08/04/2016 09:24:35:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16633806 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0145s; samplesPerSecond = 87990.7
08/04/2016 09:24:35:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15905561 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0145s; samplesPerSecond = 88575.2
08/04/2016 09:24:35: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.16478131 * 10000; EvalErrorPrediction = 0.07640000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.120044s
08/04/2016 09:24:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.14'

08/04/2016 09:24:35: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: frames [140000..150000] (first sequence at sample 140000), data subset 0 of 1

08/04/2016 09:24:35: Starting minibatch loop.
08/04/2016 09:24:35:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16883886 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0776s; samplesPerSecond = 16495.5
08/04/2016 09:24:36:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16287494 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0148s; samplesPerSecond = 86445.6
08/04/2016 09:24:36:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17327459 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0147s; samplesPerSecond = 86950.6
08/04/2016 09:24:36:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16894221 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0145s; samplesPerSecond = 88300.2
08/04/2016 09:24:36:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18094525 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0145s; samplesPerSecond = 88446.7
08/04/2016 09:24:36:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16865711 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0144s; samplesPerSecond = 88661.1
08/04/2016 09:24:36:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17507868 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0145s; samplesPerSecond = 88391.7
08/04/2016 09:24:36: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.16990380 * 10000; EvalErrorPrediction = 0.07780000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.181396s
08/04/2016 09:24:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.15'

08/04/2016 09:24:36: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: frames [150000..160000] (first sequence at sample 150000), data subset 0 of 1

08/04/2016 09:24:36: Starting minibatch loop.
08/04/2016 09:24:36:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15770645 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0147s; samplesPerSecond = 86921.1
08/04/2016 09:24:36:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16707361 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0145s; samplesPerSecond = 88294.1
08/04/2016 09:24:36:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18856184 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0145s; samplesPerSecond = 88465.0
08/04/2016 09:24:36:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16302176 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0145s; samplesPerSecond = 88446.7
08/04/2016 09:24:36:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15800428 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0145s; samplesPerSecond = 88166.4
08/04/2016 09:24:36:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15820351 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0146s; samplesPerSecond = 87827.6
08/04/2016 09:24:36:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15753212 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0144s; samplesPerSecond = 89037.3
08/04/2016 09:24:36: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.16437841 * 10000; EvalErrorPrediction = 0.07790000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.118161s
08/04/2016 09:24:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.16'

08/04/2016 09:24:36: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: frames [160000..170000] (first sequence at sample 160000), data subset 0 of 1

08/04/2016 09:24:36: Starting minibatch loop.
08/04/2016 09:24:36:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15217276 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0149s; samplesPerSecond = 86096.7
08/04/2016 09:24:36:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16241877 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0157s; samplesPerSecond = 81539.0
08/04/2016 09:24:36:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16790841 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0146s; samplesPerSecond = 87378.0
08/04/2016 09:24:36:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15698781 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0145s; samplesPerSecond = 88355.1
08/04/2016 09:24:36:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14820914 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0145s; samplesPerSecond = 88471.1
08/04/2016 09:24:36:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15909219 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0144s; samplesPerSecond = 88630.4
08/04/2016 09:24:36:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15645866 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0145s; samplesPerSecond = 88306.3
08/04/2016 09:24:36: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.15805072 * 10000; EvalErrorPrediction = 0.07500000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.119438s
08/04/2016 09:24:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.17'

08/04/2016 09:24:36: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: frames [170000..180000] (first sequence at sample 170000), data subset 0 of 1

08/04/2016 09:24:36: Starting minibatch loop.
08/04/2016 09:24:36:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15811032 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0174s; samplesPerSecond = 73483.0
08/04/2016 09:24:36:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15140492 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0157s; samplesPerSecond = 81300.8
08/04/2016 09:24:36:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16847210 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0146s; samplesPerSecond = 87725.3
08/04/2016 09:24:36:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15020189 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0145s; samplesPerSecond = 88057.2
08/04/2016 09:24:36:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18007369 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0146s; samplesPerSecond = 87906.1
08/04/2016 09:24:36:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16677599 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0144s; samplesPerSecond = 88642.7
08/04/2016 09:24:36:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17990894 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0144s; samplesPerSecond = 88728.7
08/04/2016 09:24:36: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.16535060 * 10000; EvalErrorPrediction = 0.07660000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.122054s
08/04/2016 09:24:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.18'

08/04/2016 09:24:36: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: frames [180000..190000] (first sequence at sample 180000), data subset 0 of 1

08/04/2016 09:24:36: Starting minibatch loop.
08/04/2016 09:24:36:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15684172 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0168s; samplesPerSecond = 76127.0
08/04/2016 09:24:36:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15271095 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0147s; samplesPerSecond = 87336.2
08/04/2016 09:24:36:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15635433 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0145s; samplesPerSecond = 88093.6
08/04/2016 09:24:36:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16877069 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0145s; samplesPerSecond = 88538.4
08/04/2016 09:24:36:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16100845 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0144s; samplesPerSecond = 88710.2
08/04/2016 09:24:36:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15801468 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0145s; samplesPerSecond = 88483.3
08/04/2016 09:24:36:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16867952 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0146s; samplesPerSecond = 87803.5
08/04/2016 09:24:36: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.15876036 * 10000; EvalErrorPrediction = 0.07360000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.121s
08/04/2016 09:24:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.19'

08/04/2016 09:24:36: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: frames [190000..200000] (first sequence at sample 190000), data subset 0 of 1

08/04/2016 09:24:36: Starting minibatch loop.
08/04/2016 09:24:36:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16384429 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0161s; samplesPerSecond = 79577.2
08/04/2016 09:24:36:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15079457 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0147s; samplesPerSecond = 87318.4
08/04/2016 09:24:36:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15797715 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0145s; samplesPerSecond = 88245.4
08/04/2016 09:24:36:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14629111 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0145s; samplesPerSecond = 88099.7
08/04/2016 09:24:36:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16561332 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0148s; samplesPerSecond = 86270.8
08/04/2016 09:24:36:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17343311 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0145s; samplesPerSecond = 87978.6
08/04/2016 09:24:36:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16282845 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0145s; samplesPerSecond = 88446.7
08/04/2016 09:24:36: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.16038694 * 10000; EvalErrorPrediction = 0.07670000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.11997s
08/04/2016 09:24:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.20'

08/04/2016 09:24:36: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: frames [200000..210000] (first sequence at sample 200000), data subset 0 of 1

08/04/2016 09:24:36: Starting minibatch loop.
08/04/2016 09:24:36:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15459213 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0150s; samplesPerSecond = 85123.4
08/04/2016 09:24:36:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13769214 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0147s; samplesPerSecond = 87354.1
08/04/2016 09:24:36:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16590097 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0145s; samplesPerSecond = 88300.2
08/04/2016 09:24:36:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16497707 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0145s; samplesPerSecond = 88020.9
08/04/2016 09:24:36:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15469160 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0144s; samplesPerSecond = 88636.5
08/04/2016 09:24:36:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15172610 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0390s; samplesPerSecond = 32791.1
08/04/2016 09:24:36:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19432163 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0148s; samplesPerSecond = 86206.9
08/04/2016 09:24:36: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.16184220 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.143504s
08/04/2016 09:24:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.21'

08/04/2016 09:24:36: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: frames [210000..220000] (first sequence at sample 210000), data subset 0 of 1

08/04/2016 09:24:36: Starting minibatch loop.
08/04/2016 09:24:36:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16504048 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0149s; samplesPerSecond = 85831.2
08/04/2016 09:24:36:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17136976 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0146s; samplesPerSecond = 87767.4
08/04/2016 09:24:36:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16169128 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0145s; samplesPerSecond = 88057.2
08/04/2016 09:24:36:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16252909 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0144s; samplesPerSecond = 88599.7
08/04/2016 09:24:36:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15357113 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0146s; samplesPerSecond = 87773.4
08/04/2016 09:24:37:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16020756 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0145s; samplesPerSecond = 88520.1
08/04/2016 09:24:37:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15129299 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0146s; samplesPerSecond = 87563.3
08/04/2016 09:24:37: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.16124636 * 10000; EvalErrorPrediction = 0.07450000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.118533s
08/04/2016 09:24:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.22'

08/04/2016 09:24:37: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: frames [220000..230000] (first sequence at sample 220000), data subset 0 of 1

08/04/2016 09:24:37: Starting minibatch loop.
08/04/2016 09:24:37:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18378443 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0149s; samplesPerSecond = 86114.1
08/04/2016 09:24:37:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18931304 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0146s; samplesPerSecond = 87912.1
08/04/2016 09:24:37:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15250726 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0145s; samplesPerSecond = 88227.2
08/04/2016 09:24:37:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13500133 * 1280; EvalErrorPrediction = 0.05859375 * 1280; time = 0.0154s; samplesPerSecond = 82982.2
08/04/2016 09:24:37:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18212810 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0151s; samplesPerSecond = 84583.4
08/04/2016 09:24:37:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13553762 * 1280; EvalErrorPrediction = 0.05859375 * 1280; time = 0.0145s; samplesPerSecond = 88136.1
08/04/2016 09:24:37:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16234798 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0145s; samplesPerSecond = 88416.1
08/04/2016 09:24:37: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.16352368 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.119862s
08/04/2016 09:24:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.23'

08/04/2016 09:24:37: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: frames [230000..240000] (first sequence at sample 230000), data subset 0 of 1

08/04/2016 09:24:37: Starting minibatch loop.
08/04/2016 09:24:37:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14428782 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0148s; samplesPerSecond = 86294.1
08/04/2016 09:24:37:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17680445 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0146s; samplesPerSecond = 87966.5
08/04/2016 09:24:37:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14938660 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0147s; samplesPerSecond = 87140.0
08/04/2016 09:24:37:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16131940 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0145s; samplesPerSecond = 88033.0
08/04/2016 09:24:37:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17282743 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0156s; samplesPerSecond = 82046.0
08/04/2016 09:24:37:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17751913 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0145s; samplesPerSecond = 88403.9
08/04/2016 09:24:37:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17699394 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0145s; samplesPerSecond = 88294.1
08/04/2016 09:24:37: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16429568 * 10000; EvalErrorPrediction = 0.07630000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.119692s
08/04/2016 09:24:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.24'

08/04/2016 09:24:37: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: frames [240000..250000] (first sequence at sample 240000), data subset 0 of 1

08/04/2016 09:24:37: Starting minibatch loop.
08/04/2016 09:24:37:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14880639 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0149s; samplesPerSecond = 86131.5
08/04/2016 09:24:37:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18213335 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0144s; samplesPerSecond = 88654.9
08/04/2016 09:24:37:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16309893 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0145s; samplesPerSecond = 88227.2
08/04/2016 09:24:37:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14718146 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0145s; samplesPerSecond = 88397.8
08/04/2016 09:24:37:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17083640 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0156s; samplesPerSecond = 82151.3
08/04/2016 09:24:37:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12731724 * 1280; EvalErrorPrediction = 0.05000000 * 1280; time = 0.0145s; samplesPerSecond = 88105.7
08/04/2016 09:24:37:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16735802 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0144s; samplesPerSecond = 88618.1
08/04/2016 09:24:37: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.15844290 * 10000; EvalErrorPrediction = 0.07350000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.119234s
08/04/2016 09:24:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.25'

08/04/2016 09:24:37: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: frames [250000..260000] (first sequence at sample 250000), data subset 0 of 1

08/04/2016 09:24:37: Starting minibatch loop.
08/04/2016 09:24:37:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17389761 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0148s; samplesPerSecond = 86422.3
08/04/2016 09:24:37:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17134043 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0146s; samplesPerSecond = 87641.2
08/04/2016 09:24:37:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14665477 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0145s; samplesPerSecond = 88130.0
08/04/2016 09:24:37:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15193381 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0145s; samplesPerSecond = 88123.9
08/04/2016 09:24:37:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15419469 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0156s; samplesPerSecond = 81851.9
08/04/2016 09:24:37:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15713940 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0146s; samplesPerSecond = 87894.0
08/04/2016 09:24:37:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17371769 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0145s; samplesPerSecond = 88269.8
08/04/2016 09:24:37: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.16142396 * 10000; EvalErrorPrediction = 0.07380000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.119537s
08/04/2016 09:24:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.26'

08/04/2016 09:24:37: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: frames [260000..270000] (first sequence at sample 260000), data subset 0 of 1

08/04/2016 09:24:37: Starting minibatch loop.
08/04/2016 09:24:37:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17110803 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0148s; samplesPerSecond = 86486.5
08/04/2016 09:24:37:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18830428 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0145s; samplesPerSecond = 88190.7
08/04/2016 09:24:37:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16626384 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0145s; samplesPerSecond = 88452.8
08/04/2016 09:24:37:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15299683 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0156s; samplesPerSecond = 82051.3
08/04/2016 09:24:37:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14037313 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0145s; samplesPerSecond = 88513.9
08/04/2016 09:24:37:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15567169 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0144s; samplesPerSecond = 88667.2
08/04/2016 09:24:37:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16763086 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0145s; samplesPerSecond = 88520.1
08/04/2016 09:24:37: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.16431793 * 10000; EvalErrorPrediction = 0.07500000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.119103s
08/04/2016 09:24:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.27'

08/04/2016 09:24:37: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: frames [270000..280000] (first sequence at sample 270000), data subset 0 of 1

08/04/2016 09:24:37: Starting minibatch loop.
08/04/2016 09:24:37:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16230083 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0150s; samplesPerSecond = 85613.0
08/04/2016 09:24:37:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12933979 * 1280; EvalErrorPrediction = 0.05546875 * 1280; time = 0.0146s; samplesPerSecond = 87815.6
08/04/2016 09:24:37:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17079887 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0146s; samplesPerSecond = 87966.5
08/04/2016 09:24:37:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15217948 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0145s; samplesPerSecond = 88275.9
08/04/2016 09:24:37:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16644773 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0146s; samplesPerSecond = 87725.3
08/04/2016 09:24:37:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14809389 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0156s; samplesPerSecond = 81820.5
08/04/2016 09:24:37:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17308741 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0145s; samplesPerSecond = 88397.8
08/04/2016 09:24:37: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.16228301 * 10000; EvalErrorPrediction = 0.07430000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.119686s
08/04/2016 09:24:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.28'

08/04/2016 09:24:37: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: frames [280000..290000] (first sequence at sample 280000), data subset 0 of 1

08/04/2016 09:24:37: Starting minibatch loop.
08/04/2016 09:24:37:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16509199 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0148s; samplesPerSecond = 86527.4
08/04/2016 09:24:37:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15551765 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0145s; samplesPerSecond = 88123.9
08/04/2016 09:24:37:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16555283 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0147s; samplesPerSecond = 87372.0
08/04/2016 09:24:37:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.18459663 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0147s; samplesPerSecond = 87300.5
08/04/2016 09:24:37:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17517347 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0144s; samplesPerSecond = 88605.8
08/04/2016 09:24:37:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17199516 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0152s; samplesPerSecond = 84149.6
08/04/2016 09:24:37:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17614899 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0159s; samplesPerSecond = 80640.1
08/04/2016 09:24:37: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.16964619 * 10000; EvalErrorPrediction = 0.07570000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.12061s
08/04/2016 09:24:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.29'

08/04/2016 09:24:37: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: frames [290000..300000] (first sequence at sample 290000), data subset 0 of 1

08/04/2016 09:24:37: Starting minibatch loop.
08/04/2016 09:24:37:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17371194 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0149s; samplesPerSecond = 86189.5
08/04/2016 09:24:37:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17337294 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0146s; samplesPerSecond = 87791.5
08/04/2016 09:24:37:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19336770 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0146s; samplesPerSecond = 87413.8
08/04/2016 09:24:38:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14708915 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0146s; samplesPerSecond = 87791.5
08/04/2016 09:24:38:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17869973 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0146s; samplesPerSecond = 87485.5
08/04/2016 09:24:38:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15119219 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0145s; samplesPerSecond = 88483.3
08/04/2016 09:24:38:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16005888 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0152s; samplesPerSecond = 84099.9
08/04/2016 09:24:38: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.16819099 * 10000; EvalErrorPrediction = 0.07920000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.119908s
08/04/2016 09:24:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.30'

08/04/2016 09:24:38: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: frames [300000..310000] (first sequence at sample 300000), data subset 0 of 1

08/04/2016 09:24:38: Starting minibatch loop.
08/04/2016 09:24:38:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16788696 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0148s; samplesPerSecond = 86504.0
08/04/2016 09:24:38:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15131205 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0145s; samplesPerSecond = 87990.7
08/04/2016 09:24:38:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14348452 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0145s; samplesPerSecond = 88202.9
08/04/2016 09:24:38:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16072025 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0145s; samplesPerSecond = 88544.5
08/04/2016 09:24:38:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15484633 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0144s; samplesPerSecond = 88759.4
08/04/2016 09:24:38:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17155132 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0144s; samplesPerSecond = 88685.7
08/04/2016 09:24:38:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15408573 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0153s; samplesPerSecond = 83671.1
08/04/2016 09:24:38: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15971046 * 10000; EvalErrorPrediction = 0.07430000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.119371s
08/04/2016 09:24:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.31'

08/04/2016 09:24:38: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: frames [310000..320000] (first sequence at sample 310000), data subset 0 of 1

08/04/2016 09:24:38: Starting minibatch loop.
08/04/2016 09:24:38:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16567378 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0148s; samplesPerSecond = 86195.3
08/04/2016 09:24:38:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17629437 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0146s; samplesPerSecond = 87479.5
08/04/2016 09:24:38:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15588441 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0145s; samplesPerSecond = 88428.3
08/04/2016 09:24:38:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16099830 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0145s; samplesPerSecond = 88422.2
08/04/2016 09:24:38:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14362230 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0144s; samplesPerSecond = 88605.8
08/04/2016 09:24:38:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15248966 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0145s; samplesPerSecond = 88202.9
08/04/2016 09:24:38:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17333612 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0145s; samplesPerSecond = 88349.0
08/04/2016 09:24:38: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.16101975 * 10000; EvalErrorPrediction = 0.07460000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.119431s
08/04/2016 09:24:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.32'

08/04/2016 09:24:38: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: frames [320000..330000] (first sequence at sample 320000), data subset 0 of 1

08/04/2016 09:24:38: Starting minibatch loop.
08/04/2016 09:24:38:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13991036 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0148s; samplesPerSecond = 86656.3
08/04/2016 09:24:38:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16409264 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0145s; samplesPerSecond = 87990.7
08/04/2016 09:24:38:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17210898 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0145s; samplesPerSecond = 88465.0
08/04/2016 09:24:38:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14921389 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0144s; samplesPerSecond = 88728.7
08/04/2016 09:24:38:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16666551 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0145s; samplesPerSecond = 88300.2
08/04/2016 09:24:38:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17444291 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0146s; samplesPerSecond = 87857.8
08/04/2016 09:24:38:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17008858 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0145s; samplesPerSecond = 88166.4
08/04/2016 09:24:38: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.16118842 * 10000; EvalErrorPrediction = 0.07550000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.11939s
08/04/2016 09:24:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.33'

08/04/2016 09:24:38: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: frames [330000..340000] (first sequence at sample 330000), data subset 0 of 1

08/04/2016 09:24:38: Starting minibatch loop.
08/04/2016 09:24:38:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17220008 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0148s; samplesPerSecond = 86288.3
08/04/2016 09:24:38:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14596088 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0145s; samplesPerSecond = 88045.1
08/04/2016 09:24:38:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16194715 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0145s; samplesPerSecond = 88312.4
08/04/2016 09:24:38:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16477880 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0146s; samplesPerSecond = 87942.3
08/04/2016 09:24:38:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15581260 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0145s; samplesPerSecond = 88550.7
08/04/2016 09:24:38:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14914045 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0144s; samplesPerSecond = 88679.5
08/04/2016 09:24:38:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16961269 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0144s; samplesPerSecond = 88587.4
08/04/2016 09:24:38: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.16057609 * 10000; EvalErrorPrediction = 0.07620000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.119407s
08/04/2016 09:24:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.34'

08/04/2016 09:24:38: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: frames [340000..350000] (first sequence at sample 340000), data subset 0 of 1

08/04/2016 09:24:38: Starting minibatch loop.
08/04/2016 09:24:38:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15830075 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0146s; samplesPerSecond = 87641.2
08/04/2016 09:24:38:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19673082 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0145s; samplesPerSecond = 87996.7
08/04/2016 09:24:38:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15168073 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0146s; samplesPerSecond = 87755.4
08/04/2016 09:24:38:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16068010 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0145s; samplesPerSecond = 88324.6
08/04/2016 09:24:38:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14927697 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0145s; samplesPerSecond = 88312.4
08/04/2016 09:24:38:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14174156 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0146s; samplesPerSecond = 87960.4
08/04/2016 09:24:38:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15567713 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0153s; samplesPerSecond = 83928.9
08/04/2016 09:24:38: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15990869 * 10000; EvalErrorPrediction = 0.07400000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.119068s
08/04/2016 09:24:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.35'

08/04/2016 09:24:38: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: frames [350000..360000] (first sequence at sample 350000), data subset 0 of 1

08/04/2016 09:24:38: Starting minibatch loop.
08/04/2016 09:24:38:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17481974 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0150s; samplesPerSecond = 85339.0
08/04/2016 09:24:38:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15480882 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0146s; samplesPerSecond = 87869.8
08/04/2016 09:24:38:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15659103 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0145s; samplesPerSecond = 88355.1
08/04/2016 09:24:38:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12725639 * 1280; EvalErrorPrediction = 0.05312500 * 1280; time = 0.0149s; samplesPerSecond = 85653.1
08/04/2016 09:24:38:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16772804 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0149s; samplesPerSecond = 86148.9
08/04/2016 09:24:38:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14862843 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0149s; samplesPerSecond = 85859.9
08/04/2016 09:24:38:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16541023 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0154s; samplesPerSecond = 83208.7
08/04/2016 09:24:38: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15640579 * 10000; EvalErrorPrediction = 0.07320000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.121205s
08/04/2016 09:24:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.36'

08/04/2016 09:24:38: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: frames [360000..370000] (first sequence at sample 360000), data subset 0 of 1

08/04/2016 09:24:38: Starting minibatch loop.
08/04/2016 09:24:38:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17418479 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0148s; samplesPerSecond = 86294.1
08/04/2016 09:24:38:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14746903 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0145s; samplesPerSecond = 88349.0
08/04/2016 09:24:38:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15439336 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0147s; samplesPerSecond = 87294.6
08/04/2016 09:24:38:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16765628 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0145s; samplesPerSecond = 88045.1
08/04/2016 09:24:38:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14585981 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0146s; samplesPerSecond = 87455.6
08/04/2016 09:24:38:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16325750 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0145s; samplesPerSecond = 88215.0
08/04/2016 09:24:38:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14468937 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0145s; samplesPerSecond = 88257.6
08/04/2016 09:24:38: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15734576 * 10000; EvalErrorPrediction = 0.07520000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.119851s
08/04/2016 09:24:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.37'

08/04/2016 09:24:38: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: frames [370000..380000] (first sequence at sample 370000), data subset 0 of 1

08/04/2016 09:24:38: Starting minibatch loop.
08/04/2016 09:24:38:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15427316 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0148s; samplesPerSecond = 86562.5
08/04/2016 09:24:38:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14476846 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0146s; samplesPerSecond = 87869.8
08/04/2016 09:24:39:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15904868 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0147s; samplesPerSecond = 87092.6
08/04/2016 09:24:39:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16007791 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0148s; samplesPerSecond = 86709.1
08/04/2016 09:24:39:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15896268 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0145s; samplesPerSecond = 88275.9
08/04/2016 09:24:39:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17531824 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0171s; samplesPerSecond = 74836.3
08/04/2016 09:24:39:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18566666 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0145s; samplesPerSecond = 88452.8
08/04/2016 09:24:39: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.16168400 * 10000; EvalErrorPrediction = 0.07680000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.122625s
08/04/2016 09:24:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.38'

08/04/2016 09:24:39: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: frames [380000..390000] (first sequence at sample 380000), data subset 0 of 1

08/04/2016 09:24:39: Starting minibatch loop.
08/04/2016 09:24:39:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19348662 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0149s; samplesPerSecond = 86172.1
08/04/2016 09:24:39:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14996903 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0146s; samplesPerSecond = 87695.3
08/04/2016 09:24:39:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15999389 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0145s; samplesPerSecond = 87978.6
08/04/2016 09:24:39:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16160607 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0145s; samplesPerSecond = 88532.3
08/04/2016 09:24:39:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16470418 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0145s; samplesPerSecond = 88538.4
08/04/2016 09:24:39:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17031994 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0144s; samplesPerSecond = 88630.4
08/04/2016 09:24:39:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15134487 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0144s; samplesPerSecond = 88814.9
08/04/2016 09:24:39: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.16207993 * 10000; EvalErrorPrediction = 0.07450000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.119362s
08/04/2016 09:24:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.39'

08/04/2016 09:24:39: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: frames [390000..400000] (first sequence at sample 390000), data subset 0 of 1

08/04/2016 09:24:39: Starting minibatch loop.
08/04/2016 09:24:39:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17258300 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0148s; samplesPerSecond = 86545.0
08/04/2016 09:24:39:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14488608 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0145s; samplesPerSecond = 88172.5
08/04/2016 09:24:39:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15964518 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0147s; samplesPerSecond = 87068.9
08/04/2016 09:24:39:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16551828 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0150s; samplesPerSecond = 85430.2
08/04/2016 09:24:39:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15624290 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0146s; samplesPerSecond = 87857.8
08/04/2016 09:24:39:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15955114 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0146s; samplesPerSecond = 87695.3
08/04/2016 09:24:39:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16108866 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0145s; samplesPerSecond = 88020.9
08/04/2016 09:24:39: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15967141 * 10000; EvalErrorPrediction = 0.07390000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.120315s
08/04/2016 09:24:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.40'

08/04/2016 09:24:39: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: frames [400000..410000] (first sequence at sample 400000), data subset 0 of 1

08/04/2016 09:24:39: Starting minibatch loop.
08/04/2016 09:24:39:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15408424 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0148s; samplesPerSecond = 86463.1
08/04/2016 09:24:39:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15796574 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0145s; samplesPerSecond = 88233.3
08/04/2016 09:24:39:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16707165 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0145s; samplesPerSecond = 88039.1
08/04/2016 09:24:39:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16096821 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0145s; samplesPerSecond = 88002.8
08/04/2016 09:24:39:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16167560 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0145s; samplesPerSecond = 88142.1
08/04/2016 09:24:39:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16747828 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0145s; samplesPerSecond = 88556.8
08/04/2016 09:24:39:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17522974 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0157s; samplesPerSecond = 81663.9
08/04/2016 09:24:39: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.16304825 * 10000; EvalErrorPrediction = 0.07500000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.119402s
08/04/2016 09:24:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.41'

08/04/2016 09:24:39: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: frames [410000..420000] (first sequence at sample 410000), data subset 0 of 1

08/04/2016 09:24:39: Starting minibatch loop.
08/04/2016 09:24:39:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17663202 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0149s; samplesPerSecond = 86172.1
08/04/2016 09:24:39:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14007065 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0147s; samplesPerSecond = 87140.0
08/04/2016 09:24:39:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16382353 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0146s; samplesPerSecond = 87863.8
08/04/2016 09:24:39:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16566653 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0146s; samplesPerSecond = 87918.1
08/04/2016 09:24:39:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16741762 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0145s; samplesPerSecond = 88233.3
08/04/2016 09:24:39:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14400730 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0145s; samplesPerSecond = 88410.0
08/04/2016 09:24:39:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17479286 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0156s; samplesPerSecond = 81872.8
08/04/2016 09:24:39: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.16107144 * 10000; EvalErrorPrediction = 0.07680000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.119721s
08/04/2016 09:24:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.42'

08/04/2016 09:24:39: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: frames [420000..430000] (first sequence at sample 420000), data subset 0 of 1

08/04/2016 09:24:39: Starting minibatch loop.
08/04/2016 09:24:39:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17429997 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0148s; samplesPerSecond = 86259.2
08/04/2016 09:24:39:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16836199 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0145s; samplesPerSecond = 87996.7
08/04/2016 09:24:39:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14081168 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0145s; samplesPerSecond = 88130.0
08/04/2016 09:24:39:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17329431 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0145s; samplesPerSecond = 88452.8
08/04/2016 09:24:39:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16642962 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0145s; samplesPerSecond = 88501.7
08/04/2016 09:24:39:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13549490 * 1280; EvalErrorPrediction = 0.05859375 * 1280; time = 0.0153s; samplesPerSecond = 83736.8
08/04/2016 09:24:39:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16639977 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0149s; samplesPerSecond = 86004.2
08/04/2016 09:24:39: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.16050563 * 10000; EvalErrorPrediction = 0.07580000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.11938s
08/04/2016 09:24:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.43'

08/04/2016 09:24:39: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: frames [430000..440000] (first sequence at sample 430000), data subset 0 of 1

08/04/2016 09:24:39: Starting minibatch loop.
08/04/2016 09:24:39:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16802047 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0149s; samplesPerSecond = 86044.6
08/04/2016 09:24:39:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15054713 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0146s; samplesPerSecond = 87863.8
08/04/2016 09:24:39:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16692009 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0145s; samplesPerSecond = 88330.7
08/04/2016 09:24:39:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17027082 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0145s; samplesPerSecond = 88063.3
08/04/2016 09:24:39:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16314883 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0146s; samplesPerSecond = 87749.4
08/04/2016 09:24:39:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15210333 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0144s; samplesPerSecond = 88741.0
08/04/2016 09:24:39:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16481752 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0157s; samplesPerSecond = 81383.5
08/04/2016 09:24:39: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.16043721 * 10000; EvalErrorPrediction = 0.07660000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.119605s
08/04/2016 09:24:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.44'

08/04/2016 09:24:39: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: frames [440000..450000] (first sequence at sample 440000), data subset 0 of 1

08/04/2016 09:24:39: Starting minibatch loop.
08/04/2016 09:24:39:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13533802 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0149s; samplesPerSecond = 86154.7
08/04/2016 09:24:39:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17538409 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0146s; samplesPerSecond = 87401.8
08/04/2016 09:24:39:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15831847 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0145s; samplesPerSecond = 88063.3
08/04/2016 09:24:39:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15842171 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0145s; samplesPerSecond = 88471.1
08/04/2016 09:24:39:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17317686 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0145s; samplesPerSecond = 88550.7
08/04/2016 09:24:39:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17048645 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0144s; samplesPerSecond = 88790.2
08/04/2016 09:24:39:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16983061 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0156s; samplesPerSecond = 82035.5
08/04/2016 09:24:39: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.16337107 * 10000; EvalErrorPrediction = 0.07650000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.119371s
08/04/2016 09:24:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.45'

08/04/2016 09:24:39: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: frames [450000..460000] (first sequence at sample 450000), data subset 0 of 1

08/04/2016 09:24:39: Starting minibatch loop.
08/04/2016 09:24:40:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17156162 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0149s; samplesPerSecond = 85779.4
08/04/2016 09:24:40:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17324831 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0147s; samplesPerSecond = 87027.5
08/04/2016 09:24:40:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17326558 * 1280; EvalErrorPrediction = 0.09296875 * 1280; time = 0.0147s; samplesPerSecond = 87122.2
08/04/2016 09:24:40:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13059897 * 1280; EvalErrorPrediction = 0.06093750 * 1280; time = 0.0145s; samplesPerSecond = 88202.9
08/04/2016 09:24:40:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14695468 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0144s; samplesPerSecond = 88599.7
08/04/2016 09:24:40:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16528926 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0155s; samplesPerSecond = 82490.2
08/04/2016 09:24:40:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14933701 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0145s; samplesPerSecond = 88196.8
08/04/2016 09:24:40: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.15793384 * 10000; EvalErrorPrediction = 0.07460000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.119648s
08/04/2016 09:24:40: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.46'

08/04/2016 09:24:40: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: frames [460000..470000] (first sequence at sample 460000), data subset 0 of 1

08/04/2016 09:24:40: Starting minibatch loop.
08/04/2016 09:24:40:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16656508 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0148s; samplesPerSecond = 86212.7
08/04/2016 09:24:40:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17256234 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0145s; samplesPerSecond = 88014.9
08/04/2016 09:24:40:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16525519 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0145s; samplesPerSecond = 88562.9
08/04/2016 09:24:40:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15838065 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0144s; samplesPerSecond = 88679.5
08/04/2016 09:24:40:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16896300 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0144s; samplesPerSecond = 88673.4
08/04/2016 09:24:40:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16051702 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0157s; samplesPerSecond = 81742.1
08/04/2016 09:24:40:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14918270 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0145s; samplesPerSecond = 88057.2
08/04/2016 09:24:40: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.16157202 * 10000; EvalErrorPrediction = 0.07520000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.120158s
08/04/2016 09:24:40: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.47'

08/04/2016 09:24:40: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: frames [470000..480000] (first sequence at sample 470000), data subset 0 of 1

08/04/2016 09:24:40: Starting minibatch loop.
08/04/2016 09:24:40:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17962695 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0149s; samplesPerSecond = 86137.3
08/04/2016 09:24:40:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15037714 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0146s; samplesPerSecond = 87833.7
08/04/2016 09:24:40:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16664879 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0145s; samplesPerSecond = 88458.9
08/04/2016 09:24:40:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15427337 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0157s; samplesPerSecond = 81311.1
08/04/2016 09:24:40:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14517913 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0145s; samplesPerSecond = 88196.8
08/04/2016 09:24:40:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15140610 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0145s; samplesPerSecond = 88330.7
08/04/2016 09:24:40:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19099951 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0145s; samplesPerSecond = 88513.9
08/04/2016 09:24:40: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.16168030 * 10000; EvalErrorPrediction = 0.07410000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.119868s
08/04/2016 09:24:40: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.48'

08/04/2016 09:24:40: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: frames [480000..490000] (first sequence at sample 480000), data subset 0 of 1

08/04/2016 09:24:40: Starting minibatch loop.
08/04/2016 09:24:40:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15733607 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0149s; samplesPerSecond = 86009.9
08/04/2016 09:24:40:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14742897 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0146s; samplesPerSecond = 87731.3
08/04/2016 09:24:40:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15640397 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0146s; samplesPerSecond = 87611.2
08/04/2016 09:24:40:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16741486 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0154s; samplesPerSecond = 83306.2
08/04/2016 09:24:40:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15246959 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0152s; samplesPerSecond = 84354.8
08/04/2016 09:24:40:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16499605 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0146s; samplesPerSecond = 87551.3
08/04/2016 09:24:40:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15810537 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0145s; samplesPerSecond = 88556.8
08/04/2016 09:24:40: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.15845322 * 10000; EvalErrorPrediction = 0.07510000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.120027s
08/04/2016 09:24:40: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.49'

08/04/2016 09:24:40: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

08/04/2016 09:24:40: Starting minibatch loop.
08/04/2016 09:24:40:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16533539 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0149s; samplesPerSecond = 86009.9
08/04/2016 09:24:40:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16508112 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0145s; samplesPerSecond = 88008.8
08/04/2016 09:24:40:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16056883 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0145s; samplesPerSecond = 87996.7
08/04/2016 09:24:40:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17441664 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0145s; samplesPerSecond = 88282.0
08/04/2016 09:24:40:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14452634 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0145s; samplesPerSecond = 88288.0
08/04/2016 09:24:40:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14106503 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0157s; samplesPerSecond = 81528.7
08/04/2016 09:24:40:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15638657 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0144s; samplesPerSecond = 88753.3
08/04/2016 09:24:40: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15865303 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.11946s
08/04/2016 09:24:40: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn'
08/04/2016 09:24:40: CNTKCommandTrainEnd: Simple_Demo

08/04/2016 09:24:40: Action "train" complete.


08/04/2016 09:24:40: ##############################################################################
08/04/2016 09:24:40: #                                                                            #
08/04/2016 09:24:40: # Action "write"                                                             #
08/04/2016 09:24:40: #                                                                            #
08/04/2016 09:24:40: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *1]] [W0*features+B0 Gradient[50 x 1 x *1]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
000000F1B143B550: {[H2 Value[50 x 1 x *1]] }
000000F1B143B870: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
000000F1B143B9B0: {[LogOfPrior Value[2]] }
000000F1B143BA50: {[W0*features Value[50 x *1]] }
000000F1B143BD70: {[H1 Value[50 x 1 x *1]] }
000000F1B143BE10: {[W1*H1+B1 Value[50 x 1 x *1]] }
000000F1B143BEB0: {[HLast Value[2 x 1 x *1]] }
000000F1B143C090: {[MVNormalizedFeatures Value[2 x *1]] }
000000F1B143C1D0: {[W1*H1 Value[50 x 1 x *1]] }
000000F1B143C310: {[W0*features+B0 Value[50 x 1 x *1]] }
000000F1B143C450: {[W2*H1 Value[2 x 1 x *1]] }
000000F1B45FE9F0: {[features Value[2 x *1]] }
000000F1B45FEA90: {[B1 Value[50 x 1]] }
000000F1B45FEBD0: {[InvStdOfFeatures Value[2]] }
000000F1B45FEEF0: {[labels Value[2 x *1]] }
000000F1B45FF170: {[B2 Value[2 x 1]] }
000000F1B45FF5D0: {[Prior Value[2]] }
000000F1B45FF710: {[W0 Value[50 x 2]] }
000000F1B45FFA30: {[MeanOfFeatures Value[2]] }
000000F1B45FFD50: {[W1 Value[50 x 50]] }
000000F1B45FFE90: {[B0 Value[50 x 1]] }
000000F1B4600070: {[W2 Value[2 x 50]] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

08/04/2016 09:24:40: Action "write" complete.

08/04/2016 09:24:40: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu DeviceId=-1 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug  4 2016 06:18:04
		Last modified date: Thu Aug  4 03:39:14 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
		Built by svcphil on dphaim-26-new
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows@3\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
08/04/2016 09:24:41: -------------------------------------------------------------------
08/04/2016 09:24:41: Build info: 

08/04/2016 09:24:41: 		Built time: Aug  4 2016 06:18:04
08/04/2016 09:24:41: 		Last modified date: Thu Aug  4 03:39:14 2016
08/04/2016 09:24:41: 		Build type: Release
08/04/2016 09:24:41: 		Build target: GPU
08/04/2016 09:24:41: 		With 1bit-SGD: no
08/04/2016 09:24:41: 		Math lib: mkl
08/04/2016 09:24:41: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/04/2016 09:24:41: 		CUB_PATH: C:\src\cub-1.4.1
08/04/2016 09:24:41: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
08/04/2016 09:24:41: 		Build Branch: HEAD
08/04/2016 09:24:41: 		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
08/04/2016 09:24:41: 		Built by svcphil on dphaim-26-new
08/04/2016 09:24:41: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows@3\Source\CNTK\
08/04/2016 09:24:41: -------------------------------------------------------------------
08/04/2016 09:24:42: -------------------------------------------------------------------
08/04/2016 09:24:42: GPU info:

08/04/2016 09:24:42: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8192 MB
08/04/2016 09:24:42: -------------------------------------------------------------------

08/04/2016 09:24:42: Running on cntk-muc02 at 2016/08/04 09:24:42
08/04/2016 09:24:42: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  makeMode=true



08/04/2016 09:24:42: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/04/2016 09:24:42: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/04/2016 09:24:42: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/04/2016 09:24:42: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/04/2016 09:24:42: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/04/2016 09:24:42: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/04/2016 09:24:42: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/04/2016 09:24:42: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/04/2016 09:24:42: Commands: Simple_Demo Simple_Demo_Output
08/04/2016 09:24:42: Precision = "float"
08/04/2016 09:24:42: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn
08/04/2016 09:24:42: CNTKCommandTrainInfo: Simple_Demo : 50
08/04/2016 09:24:42: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/04/2016 09:24:42: ##############################################################################
08/04/2016 09:24:42: #                                                                            #
08/04/2016 09:24:42: # Action "train"                                                             #
08/04/2016 09:24:42: #                                                                            #
08/04/2016 09:24:42: ##############################################################################

08/04/2016 09:24:42: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

08/04/2016 09:24:42: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/04/2016 09:24:42: Loaded model with 25 nodes on CPU.

08/04/2016 09:24:42: Training criterion node(s):
08/04/2016 09:24:42: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/04/2016 09:24:42: Evaluation criterion node(s):

08/04/2016 09:24:42: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
000000687CDB2D30: {[LogOfPrior Value[2]] }
000000687CDB2DD0: {[H1 Value[50 x 1 x *1]] [W0*features Gradient[50 x *1]] }
000000687CDB2E70: {[H2 Value[50 x 1 x *1]] [W1*H1 Gradient[50 x 1 x *1]] }
000000687CDB2FB0: {[B2 Gradient[2 x 1]] }
000000687CDB30F0: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2*H1 Value[2 x 1 x *1]] }
000000687CDB32D0: {[HLast Value[2 x 1 x *1]] [W2 Gradient[2 x 50]] }
000000687CDB3370: {[CrossEntropyWithSoftmax Gradient[1]] }
000000687CDB3550: {[MVNormalizedFeatures Value[2 x *1]] }
000000687CDB35F0: {[W2 Value[2 x 50]] }
000000687CDB3690: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
000000687CDB3C30: {[W0*features+B0 Gradient[50 x 1 x *1]] [W1*H1 Value[50 x 1 x *1]] }
000000687CDB3CD0: {[W0 Value[50 x 2]] }
000000687CDB3E10: {[CrossEntropyWithSoftmax Value[1]] }
000000687CDB3F50: {[Prior Value[2]] }
000000687CDB4090: {[W0*features Value[50 x *1]] }
000000687CDB4130: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *1]] }
000000687CDB44F0: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] }
000000687CDB4630: {[W2*H1 Gradient[2 x 1 x *1]] }
000000687CDB4770: {[MeanOfFeatures Value[2]] }
000000687CDB4810: {[W1 Value[50 x 50]] }
000000687CDB4950: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *1]] }
000000687CDB4A90: {[EvalErrorPrediction Value[1]] }
000000687FA6A450: {[B1 Value[50 x 1]] }
000000687FA6A810: {[labels Value[2 x *1]] }
000000687FA6A9F0: {[B2 Value[2 x 1]] }
000000687FA6AB30: {[features Value[2 x *1]] }
000000687FA6ABD0: {[InvStdOfFeatures Value[2]] }
000000687FA6B210: {[B0 Value[50 x 1]] }

08/04/2016 09:24:42: No PreCompute nodes found, skipping PreCompute step.

08/04/2016 09:24:42: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

08/04/2016 09:24:42: Starting minibatch loop.
08/04/2016 09:24:42:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.16533539 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0355s; samplesPerSecond = 36083.8
08/04/2016 09:24:42:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.16508112 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0165s; samplesPerSecond = 77684.0
08/04/2016 09:24:42:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.16056883 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0154s; samplesPerSecond = 83030.6
08/04/2016 09:24:42:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.17441664 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0155s; samplesPerSecond = 82815.7
08/04/2016 09:24:42:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.14452634 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0155s; samplesPerSecond = 82431.7
08/04/2016 09:24:42:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.14106503 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0155s; samplesPerSecond = 82794.3
08/04/2016 09:24:42:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.15638657 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0154s; samplesPerSecond = 83036.0
08/04/2016 09:24:42: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15865303 * 10000; EvalErrorPrediction = 0.07610000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.147781s
08/04/2016 09:24:42: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/models/simple.dnn'
08/04/2016 09:24:42: CNTKCommandTrainEnd: Simple_Demo

08/04/2016 09:24:42: Action "train" complete.


08/04/2016 09:24:42: ##############################################################################
08/04/2016 09:24:42: #                                                                            #
08/04/2016 09:24:42: # Action "write"                                                             #
08/04/2016 09:24:42: #                                                                            #
08/04/2016 09:24:42: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

0000000000000000: {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *2]] [H2 Gradient[50 x 1 x *2]] [HLast Gradient[2 x 1 x *2]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *2]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *2]] [PosteriorProb Value[2 x 1 x *2]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *2]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *2]] [W0*features+B0 Gradient[50 x 1 x *2]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *2]] [W1*H1+B1 Gradient[50 x 1 x *2]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *2]] [features Gradient[2 x *2]] [labels Gradient[2 x *2]] }
0000006809228080: {[InvStdOfFeatures Value[2]] }
0000006809228580: {[MeanOfFeatures Value[2]] }
0000006809228620: {[W0 Value[50 x 2]] }
00000068092286C0: {[W2 Value[2 x 50]] }
00000068092289E0: {[B1 Value[50 x 1]] }
0000006809228B20: {[B0 Value[50 x 1]] }
0000006809228F80: {[B2 Value[2 x 1]] }
0000006809229160: {[features Value[2 x *2]] }
00000068092293E0: {[Prior Value[2]] }
0000006809229700: {[W1 Value[50 x 50]] }
0000006809229B60: {[labels Value[2 x *2]] }
000000687FA6A590: {[H1 Value[50 x 1 x *2]] }
000000687FA6A6D0: {[W2*H1 Value[2 x 1 x *2]] }
000000687FA6A770: {[MVNormalizedFeatures Value[2 x *2]] }
000000687FA6A8B0: {[H2 Value[50 x 1 x *2]] }
000000687FA6AC70: {[LogOfPrior Value[2]] }
000000687FA6AD10: {[W0*features Value[50 x *2]] }
000000687FA6ADB0: {[W0*features+B0 Value[50 x 1 x *2]] }
000000687FA6AF90: {[ScaledLogLikelihood Value[2 x 1 x *2]] }
000000687FA6B0D0: {[W1*H1 Value[50 x 1 x *2]] }
000000687FA6B170: {[W1*H1+B1 Value[50 x 1 x *2]] }
000000687FA6B210: {[HLast Value[2 x 1 x *2]] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160804091806.347762\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

08/04/2016 09:24:42: Action "write" complete.

08/04/2016 09:24:42: __COMPLETED__