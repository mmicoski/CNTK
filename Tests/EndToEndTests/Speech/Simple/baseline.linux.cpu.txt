CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu DeviceId=-1 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug  4 2016 13:05:36
		Last modified date: Thu Aug  4 12:33:33 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
		Built by philly on 643085f7f8c2
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
08/04/2016 13:56:16: -------------------------------------------------------------------
08/04/2016 13:56:16: Build info: 

08/04/2016 13:56:16: 		Built time: Aug  4 2016 13:05:36
08/04/2016 13:56:16: 		Last modified date: Thu Aug  4 12:33:33 2016
08/04/2016 13:56:16: 		Build type: release
08/04/2016 13:56:16: 		Build target: GPU
08/04/2016 13:56:16: 		With 1bit-SGD: no
08/04/2016 13:56:16: 		Math lib: mkl
08/04/2016 13:56:16: 		CUDA_PATH: /usr/local/cuda-7.5
08/04/2016 13:56:16: 		CUB_PATH: /usr/local/cub-1.4.1
08/04/2016 13:56:16: 		CUDNN_PATH: /usr/local/cudnn-4.0
08/04/2016 13:56:16: 		Build Branch: HEAD
08/04/2016 13:56:16: 		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
08/04/2016 13:56:16: 		Built by philly on 643085f7f8c2
08/04/2016 13:56:16: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
08/04/2016 13:56:16: -------------------------------------------------------------------
08/04/2016 13:56:17: -------------------------------------------------------------------
08/04/2016 13:56:17: GPU info:

08/04/2016 13:56:17: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:56:17: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:56:17: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:56:17: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:56:17: -------------------------------------------------------------------

08/04/2016 13:56:17: Running on localhost at 2016/08/04 13:56:17
08/04/2016 13:56:17: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu  DeviceId=-1  timestamping=true



08/04/2016 13:56:17: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/04/2016 13:56:17: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

08/04/2016 13:56:17: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/04/2016 13:56:17: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/04/2016 13:56:17: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

08/04/2016 13:56:17: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/04/2016 13:56:17: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/04/2016 13:56:17: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/04/2016 13:56:17: Commands: Simple_Demo Simple_Demo_Output
08/04/2016 13:56:17: Precision = "float"
08/04/2016 13:56:17: CNTKModelPath: /tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn
08/04/2016 13:56:17: CNTKCommandTrainInfo: Simple_Demo : 50
08/04/2016 13:56:17: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/04/2016 13:56:17: ##############################################################################
08/04/2016 13:56:17: #                                                                            #
08/04/2016 13:56:17: # Action "train"                                                             #
08/04/2016 13:56:17: #                                                                            #
08/04/2016 13:56:17: ##############################################################################

08/04/2016 13:56:17: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

08/04/2016 13:56:17: Creating virgin network.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/04/2016 13:56:17: Created model with 25 nodes on CPU.

08/04/2016 13:56:17: Training criterion node(s):
08/04/2016 13:56:17: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/04/2016 13:56:17: Evaluation criterion node(s):

08/04/2016 13:56:17: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *]] [PosteriorProb Value[2 x 1 x *]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *]] [features Gradient[2 x *]] [labels Gradient[2 x *]] }
0x238e668: {[InvStdOfFeatures Value[2]] }
0x238fa58: {[W0 Value[50 x 2]] }
0x2390028: {[B0 Value[50 x 1]] }
0x2390f18: {[W1 Value[50 x 50]] }
0x2393a68: {[B1 Value[50 x 1]] }
0x2394948: {[W2 Value[2 x 50]] }
0x2394f18: {[B2 Value[2 x 1]] }
0x23959f8: {[labels Value[2 x *]] }
0x2396778: {[Prior Value[2]] }
0x239c088: {[EvalErrorPrediction Value[1]] }
0x239c228: {[ScaledLogLikelihood Value[2 x 1 x *]] }
0x239c3e8: {[CrossEntropyWithSoftmax Value[1]] }
0x239c938: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *]] }
0x239caa8: {[LogOfPrior Value[2]] }
0x239e208: {[MVNormalizedFeatures Value[2 x *]] }
0x239e9c8: {[W0*features Value[50 x *]] }
0x239ebd8: {[H1 Value[50 x 1 x *]] [W0*features Gradient[50 x *]] }
0x239ed98: {[W0*features+B0 Gradient[50 x 1 x *]] [W1*H1 Value[50 x 1 x *]] }
0x239ef58: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *]] }
0x239f118: {[H2 Value[50 x 1 x *]] [W1*H1 Gradient[50 x 1 x *]] }
0x239f2d8: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *]] [W1*H1+B1 Gradient[50 x 1 x *]] [W2*H1 Value[2 x 1 x *]] }
0x239f498: {[HLast Value[2 x 1 x *]] [W2 Gradient[2 x 50]] }
0x239fff8: {[CrossEntropyWithSoftmax Gradient[1]] }
0x242a408: {[features Value[2 x *]] }
0x25ff128: {[MeanOfFeatures Value[2]] }
0x26eca88: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *]] [HLast Gradient[2 x 1 x *]] }
0x26ecc48: {[W2*H1 Gradient[2 x 1 x *]] }
0x26ece08: {[B2 Gradient[2 x 1]] }


08/04/2016 13:56:17: Precomputing --> 3 PreCompute nodes found.

08/04/2016 13:56:17: 	MeanOfFeatures = Mean()
08/04/2016 13:56:17: 	InvStdOfFeatures = InvStdDev()
08/04/2016 13:56:17: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

08/04/2016 13:56:18: Precomputing --> Completed.


08/04/2016 13:56:18: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 0: frames [0..10000] (first sequence at sample 0), data subset 0 of 1

08/04/2016 13:56:18: Starting minibatch loop.
08/04/2016 13:56:18:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.95388699 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.0878s; samplesPerSecond = 14572.3
08/04/2016 13:56:18:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.96805096 * 1280; EvalErrorPrediction = 0.51875000 * 1280; time = 0.0558s; samplesPerSecond = 22930.4
08/04/2016 13:56:18:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.85298004 * 1280; EvalErrorPrediction = 0.50703125 * 1280; time = 0.0647s; samplesPerSecond = 19776.3
08/04/2016 13:56:18:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.82870445 * 1280; EvalErrorPrediction = 0.53046875 * 1280; time = 0.0546s; samplesPerSecond = 23457.8
08/04/2016 13:56:18:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.77647324 * 1280; EvalErrorPrediction = 0.49921875 * 1280; time = 0.0641s; samplesPerSecond = 19968.5
08/04/2016 13:56:18:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.75239029 * 1280; EvalErrorPrediction = 0.50859375 * 1280; time = 0.0439s; samplesPerSecond = 29142.6
08/04/2016 13:56:18:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.74115143 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.0458s; samplesPerSecond = 27973.3
08/04/2016 13:56:18: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.82724395 * 10000; EvalErrorPrediction = 0.50660000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.487886s
08/04/2016 13:56:18: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.1'

08/04/2016 13:56:18: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: frames [10000..20000] (first sequence at sample 10000), data subset 0 of 1

08/04/2016 13:56:18: Starting minibatch loop.
08/04/2016 13:56:18:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.74591827 * 1280; EvalErrorPrediction = 0.50156250 * 1280; time = 0.0390s; samplesPerSecond = 32783.5
08/04/2016 13:56:18:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.73711109 * 1280; EvalErrorPrediction = 0.50312500 * 1280; time = 0.0480s; samplesPerSecond = 26673.3
08/04/2016 13:56:18:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.77000561 * 1280; EvalErrorPrediction = 0.52187500 * 1280; time = 0.0427s; samplesPerSecond = 29949.9
08/04/2016 13:56:18:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.75718117 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.0522s; samplesPerSecond = 24501.8
08/04/2016 13:56:18:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.73313942 * 1280; EvalErrorPrediction = 0.50937500 * 1280; time = 0.0454s; samplesPerSecond = 28215.0
08/04/2016 13:56:18:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.71255798 * 1280; EvalErrorPrediction = 0.48984375 * 1280; time = 0.0487s; samplesPerSecond = 26258.0
08/04/2016 13:56:18:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69696198 * 1280; EvalErrorPrediction = 0.50703125 * 1280; time = 0.0690s; samplesPerSecond = 18561.5
08/04/2016 13:56:18: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.73229712 * 10000; EvalErrorPrediction = 0.50360000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.458031s
08/04/2016 13:56:18: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.2'

08/04/2016 13:56:18: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: frames [20000..30000] (first sequence at sample 20000), data subset 0 of 1

08/04/2016 13:56:18: Starting minibatch loop.
08/04/2016 13:56:19:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71668873 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.1393s; samplesPerSecond = 9189.5
08/04/2016 13:56:19:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.74703245 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.1474s; samplesPerSecond = 8683.1
08/04/2016 13:56:19:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.74001799 * 1280; EvalErrorPrediction = 0.48437500 * 1280; time = 0.0948s; samplesPerSecond = 13499.7
08/04/2016 13:56:19:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.71496048 * 1280; EvalErrorPrediction = 0.48671875 * 1280; time = 0.1032s; samplesPerSecond = 12408.8
08/04/2016 13:56:19:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.71307373 * 1280; EvalErrorPrediction = 0.50000000 * 1280; time = 0.0368s; samplesPerSecond = 34761.8
08/04/2016 13:56:19:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70211945 * 1280; EvalErrorPrediction = 0.50390625 * 1280; time = 0.0305s; samplesPerSecond = 42025.1
08/04/2016 13:56:19:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70786667 * 1280; EvalErrorPrediction = 0.49687500 * 1280; time = 0.0363s; samplesPerSecond = 35219.0
08/04/2016 13:56:19: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.71798784 * 10000; EvalErrorPrediction = 0.49520000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.616721s
08/04/2016 13:56:19: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.3'

08/04/2016 13:56:19: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: frames [30000..40000] (first sequence at sample 30000), data subset 0 of 1

08/04/2016 13:56:19: Starting minibatch loop.
08/04/2016 13:56:19:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.69908242 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.0520s; samplesPerSecond = 24610.7
08/04/2016 13:56:19:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.70071168 * 1280; EvalErrorPrediction = 0.50625000 * 1280; time = 0.0543s; samplesPerSecond = 23581.9
08/04/2016 13:56:19:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.69738913 * 1280; EvalErrorPrediction = 0.51796875 * 1280; time = 0.0393s; samplesPerSecond = 32567.5
08/04/2016 13:56:19:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.69421196 * 1280; EvalErrorPrediction = 0.49531250 * 1280; time = 0.0594s; samplesPerSecond = 21547.4
08/04/2016 13:56:19:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.69607239 * 1280; EvalErrorPrediction = 0.48906250 * 1280; time = 0.0590s; samplesPerSecond = 21678.4
08/04/2016 13:56:19:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70347900 * 1280; EvalErrorPrediction = 0.50859375 * 1280; time = 0.0459s; samplesPerSecond = 27895.8
08/04/2016 13:56:19:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70025673 * 1280; EvalErrorPrediction = 0.47734375 * 1280; time = 0.0410s; samplesPerSecond = 31240.1
08/04/2016 13:56:19: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.69871011 * 10000; EvalErrorPrediction = 0.50120000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.390082s
08/04/2016 13:56:19: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.4'

08/04/2016 13:56:19: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: frames [40000..50000] (first sequence at sample 40000), data subset 0 of 1

08/04/2016 13:56:19: Starting minibatch loop.
08/04/2016 13:56:20:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70594125 * 1280; EvalErrorPrediction = 0.52578125 * 1280; time = 0.0714s; samplesPerSecond = 17936.2
08/04/2016 13:56:20:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.70099931 * 1280; EvalErrorPrediction = 0.49531250 * 1280; time = 0.0809s; samplesPerSecond = 15829.8
08/04/2016 13:56:20:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.69464769 * 1280; EvalErrorPrediction = 0.49062500 * 1280; time = 0.0484s; samplesPerSecond = 26446.3
08/04/2016 13:56:20:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.71469688 * 1280; EvalErrorPrediction = 0.50703125 * 1280; time = 0.0694s; samplesPerSecond = 18433.7
08/04/2016 13:56:20:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.71029339 * 1280; EvalErrorPrediction = 0.48906250 * 1280; time = 0.0822s; samplesPerSecond = 15568.2
08/04/2016 13:56:20:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.72695656 * 1280; EvalErrorPrediction = 0.48281250 * 1280; time = 0.0528s; samplesPerSecond = 24239.7
08/04/2016 13:56:20:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.71200142 * 1280; EvalErrorPrediction = 0.47968750 * 1280; time = 0.0487s; samplesPerSecond = 26282.8
08/04/2016 13:56:20: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.70825366 * 10000; EvalErrorPrediction = 0.49560000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.494847s
08/04/2016 13:56:20: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.5'

08/04/2016 13:56:20: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: frames [50000..60000] (first sequence at sample 50000), data subset 0 of 1

08/04/2016 13:56:20: Starting minibatch loop.
08/04/2016 13:56:20:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71296167 * 1280; EvalErrorPrediction = 0.52109375 * 1280; time = 0.0486s; samplesPerSecond = 26314.7
08/04/2016 13:56:20:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.69506178 * 1280; EvalErrorPrediction = 0.48828125 * 1280; time = 0.0451s; samplesPerSecond = 28373.2
08/04/2016 13:56:20:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.69431229 * 1280; EvalErrorPrediction = 0.49765625 * 1280; time = 0.0363s; samplesPerSecond = 35303.5
08/04/2016 13:56:20:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.69347229 * 1280; EvalErrorPrediction = 0.48359375 * 1280; time = 0.0422s; samplesPerSecond = 30328.9
08/04/2016 13:56:20:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.69991341 * 1280; EvalErrorPrediction = 0.50078125 * 1280; time = 0.0395s; samplesPerSecond = 32436.3
08/04/2016 13:56:20:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70211754 * 1280; EvalErrorPrediction = 0.48515625 * 1280; time = 0.0516s; samplesPerSecond = 24804.8
08/04/2016 13:56:20:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.71661835 * 1280; EvalErrorPrediction = 0.52734375 * 1280; time = 0.0391s; samplesPerSecond = 32753.3
08/04/2016 13:56:20: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.70385576 * 10000; EvalErrorPrediction = 0.50080000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.346426s
08/04/2016 13:56:20: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.6'

08/04/2016 13:56:20: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: frames [60000..70000] (first sequence at sample 60000), data subset 0 of 1

08/04/2016 13:56:20: Starting minibatch loop.
08/04/2016 13:56:20:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71003432 * 1280; EvalErrorPrediction = 0.52109375 * 1280; time = 0.0395s; samplesPerSecond = 32417.4
08/04/2016 13:56:20:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.70102534 * 1280; EvalErrorPrediction = 0.48906250 * 1280; time = 0.0620s; samplesPerSecond = 20643.5
08/04/2016 13:56:20:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.69591055 * 1280; EvalErrorPrediction = 0.50703125 * 1280; time = 0.0350s; samplesPerSecond = 36539.1
08/04/2016 13:56:21:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.69730377 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.0512s; samplesPerSecond = 24986.3
08/04/2016 13:56:21:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.70023346 * 1280; EvalErrorPrediction = 0.49843750 * 1280; time = 0.0636s; samplesPerSecond = 20118.2
08/04/2016 13:56:21:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.69664421 * 1280; EvalErrorPrediction = 0.52500000 * 1280; time = 0.0399s; samplesPerSecond = 32094.7
08/04/2016 13:56:21:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69250069 * 1280; EvalErrorPrediction = 0.48046875 * 1280; time = 0.0502s; samplesPerSecond = 25474.7
08/04/2016 13:56:21: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.69854004 * 10000; EvalErrorPrediction = 0.50320000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.397562s
08/04/2016 13:56:21: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.7'

08/04/2016 13:56:21: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: frames [70000..80000] (first sequence at sample 70000), data subset 0 of 1

08/04/2016 13:56:21: Starting minibatch loop.
08/04/2016 13:56:21:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.69390483 * 1280; EvalErrorPrediction = 0.46875000 * 1280; time = 0.0796s; samplesPerSecond = 16071.5
08/04/2016 13:56:21:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.69576030 * 1280; EvalErrorPrediction = 0.50703125 * 1280; time = 0.0463s; samplesPerSecond = 27664.3
08/04/2016 13:56:21:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.69685125 * 1280; EvalErrorPrediction = 0.48984375 * 1280; time = 0.0453s; samplesPerSecond = 28241.1
08/04/2016 13:56:21:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.69542370 * 1280; EvalErrorPrediction = 0.50703125 * 1280; time = 0.0694s; samplesPerSecond = 18451.8
08/04/2016 13:56:21:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.69556465 * 1280; EvalErrorPrediction = 0.51796875 * 1280; time = 0.0431s; samplesPerSecond = 29682.5
08/04/2016 13:56:21:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.69835892 * 1280; EvalErrorPrediction = 0.49062500 * 1280; time = 0.0410s; samplesPerSecond = 31221.8
08/04/2016 13:56:21:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70024757 * 1280; EvalErrorPrediction = 0.52031250 * 1280; time = 0.0398s; samplesPerSecond = 32128.5
08/04/2016 13:56:21: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.69644053 * 10000; EvalErrorPrediction = 0.50160000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.408354s
08/04/2016 13:56:21: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.8'

08/04/2016 13:56:21: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: frames [80000..90000] (first sequence at sample 80000), data subset 0 of 1

08/04/2016 13:56:21: Starting minibatch loop.
08/04/2016 13:56:21:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70310450 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.0468s; samplesPerSecond = 27355.7
08/04/2016 13:56:21:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.70304842 * 1280; EvalErrorPrediction = 0.48671875 * 1280; time = 0.0581s; samplesPerSecond = 22035.5
08/04/2016 13:56:21:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.70074444 * 1280; EvalErrorPrediction = 0.50781250 * 1280; time = 0.0412s; samplesPerSecond = 31060.4
08/04/2016 13:56:21:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.70891666 * 1280; EvalErrorPrediction = 0.51953125 * 1280; time = 0.0392s; samplesPerSecond = 32693.9
08/04/2016 13:56:21:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.70991802 * 1280; EvalErrorPrediction = 0.50546875 * 1280; time = 0.0443s; samplesPerSecond = 28881.5
08/04/2016 13:56:21:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.69735374 * 1280; EvalErrorPrediction = 0.49687500 * 1280; time = 0.0353s; samplesPerSecond = 36238.0
08/04/2016 13:56:21:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70280762 * 1280; EvalErrorPrediction = 0.50546875 * 1280; time = 0.0405s; samplesPerSecond = 31637.7
08/04/2016 13:56:21: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.70404629 * 10000; EvalErrorPrediction = 0.50100000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.338069s
08/04/2016 13:56:21: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.9'

08/04/2016 13:56:21: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: frames [90000..100000] (first sequence at sample 90000), data subset 0 of 1

08/04/2016 13:56:21: Starting minibatch loop.
08/04/2016 13:56:22:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70547481 * 1280; EvalErrorPrediction = 0.50781250 * 1280; time = 0.0573s; samplesPerSecond = 22346.8
08/04/2016 13:56:22:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.72443137 * 1280; EvalErrorPrediction = 0.52031250 * 1280; time = 0.0412s; samplesPerSecond = 31032.6
08/04/2016 13:56:22:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.71928835 * 1280; EvalErrorPrediction = 0.49687500 * 1280; time = 0.0430s; samplesPerSecond = 29743.2
08/04/2016 13:56:22:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.71950722 * 1280; EvalErrorPrediction = 0.48750000 * 1280; time = 0.0554s; samplesPerSecond = 23089.3
08/04/2016 13:56:22:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.71714573 * 1280; EvalErrorPrediction = 0.51484375 * 1280; time = 0.0306s; samplesPerSecond = 41887.6
08/04/2016 13:56:22:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.71305771 * 1280; EvalErrorPrediction = 0.47890625 * 1280; time = 0.0648s; samplesPerSecond = 19746.4
08/04/2016 13:56:22:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70979691 * 1280; EvalErrorPrediction = 0.51250000 * 1280; time = 0.1147s; samplesPerSecond = 11157.9
08/04/2016 13:56:22: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.71332549 * 10000; EvalErrorPrediction = 0.50220000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.466646s
08/04/2016 13:56:22: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.10'

08/04/2016 13:56:22: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: frames [100000..110000] (first sequence at sample 100000), data subset 0 of 1

08/04/2016 13:56:22: Starting minibatch loop.
08/04/2016 13:56:22:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.69991164 * 1280; EvalErrorPrediction = 0.50859375 * 1280; time = 0.0954s; samplesPerSecond = 13417.5
08/04/2016 13:56:22:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.70034795 * 1280; EvalErrorPrediction = 0.50078125 * 1280; time = 0.0433s; samplesPerSecond = 29578.3
08/04/2016 13:56:22:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.70344315 * 1280; EvalErrorPrediction = 0.48906250 * 1280; time = 0.0437s; samplesPerSecond = 29281.2
08/04/2016 13:56:22:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.70426121 * 1280; EvalErrorPrediction = 0.50625000 * 1280; time = 0.0464s; samplesPerSecond = 27591.0
08/04/2016 13:56:22:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.69540443 * 1280; EvalErrorPrediction = 0.46250000 * 1280; time = 0.0464s; samplesPerSecond = 27560.7
08/04/2016 13:56:22:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.71095734 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.0556s; samplesPerSecond = 23038.6
08/04/2016 13:56:22:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70806999 * 1280; EvalErrorPrediction = 0.49921875 * 1280; time = 0.0449s; samplesPerSecond = 28483.7
08/04/2016 13:56:22: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.70492339 * 10000; EvalErrorPrediction = 0.49840000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.425318s
08/04/2016 13:56:22: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.11'

08/04/2016 13:56:22: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: frames [110000..120000] (first sequence at sample 110000), data subset 0 of 1

08/04/2016 13:56:22: Starting minibatch loop.
08/04/2016 13:56:22:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70961823 * 1280; EvalErrorPrediction = 0.49062500 * 1280; time = 0.0550s; samplesPerSecond = 23254.5
08/04/2016 13:56:22:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.71287904 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.0519s; samplesPerSecond = 24677.6
08/04/2016 13:56:23:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.70973139 * 1280; EvalErrorPrediction = 0.50390625 * 1280; time = 0.0430s; samplesPerSecond = 29791.0
08/04/2016 13:56:23:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.71923542 * 1280; EvalErrorPrediction = 0.53125000 * 1280; time = 0.0601s; samplesPerSecond = 21297.1
08/04/2016 13:56:23:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.69978256 * 1280; EvalErrorPrediction = 0.50312500 * 1280; time = 0.0437s; samplesPerSecond = 29305.4
08/04/2016 13:56:23:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70222473 * 1280; EvalErrorPrediction = 0.49609375 * 1280; time = 0.0411s; samplesPerSecond = 31155.7
08/04/2016 13:56:23:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.71590462 * 1280; EvalErrorPrediction = 0.49375000 * 1280; time = 0.0666s; samplesPerSecond = 19221.8
08/04/2016 13:56:23: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.71162095 * 10000; EvalErrorPrediction = 0.50180000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.40828s
08/04/2016 13:56:23: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.12'

08/04/2016 13:56:23: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: frames [120000..130000] (first sequence at sample 120000), data subset 0 of 1

08/04/2016 13:56:23: Starting minibatch loop.
08/04/2016 13:56:23:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.77541642 * 1280; EvalErrorPrediction = 0.46796875 * 1280; time = 0.0400s; samplesPerSecond = 32012.8
08/04/2016 13:56:23:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.76934695 * 1280; EvalErrorPrediction = 0.48750000 * 1280; time = 0.0441s; samplesPerSecond = 29025.6
08/04/2016 13:56:23:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.75980186 * 1280; EvalErrorPrediction = 0.48984375 * 1280; time = 0.0497s; samplesPerSecond = 25773.7
08/04/2016 13:56:23:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.72439041 * 1280; EvalErrorPrediction = 0.49453125 * 1280; time = 0.0565s; samplesPerSecond = 22656.5
08/04/2016 13:56:23:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.73180790 * 1280; EvalErrorPrediction = 0.49609375 * 1280; time = 0.0700s; samplesPerSecond = 18275.3
08/04/2016 13:56:23:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70451279 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.0495s; samplesPerSecond = 25842.4
08/04/2016 13:56:23:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70035629 * 1280; EvalErrorPrediction = 0.52500000 * 1280; time = 0.0486s; samplesPerSecond = 26320.1
08/04/2016 13:56:23: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.73364673 * 10000; EvalErrorPrediction = 0.49340000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.4227s
08/04/2016 13:56:23: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.13'

08/04/2016 13:56:23: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: frames [130000..140000] (first sequence at sample 130000), data subset 0 of 1

08/04/2016 13:56:23: Starting minibatch loop.
08/04/2016 13:56:23:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.69958048 * 1280; EvalErrorPrediction = 0.48984375 * 1280; time = 0.0414s; samplesPerSecond = 30932.8
08/04/2016 13:56:23:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.69922590 * 1280; EvalErrorPrediction = 0.50625000 * 1280; time = 0.0402s; samplesPerSecond = 31805.2
08/04/2016 13:56:23:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.70048771 * 1280; EvalErrorPrediction = 0.50703125 * 1280; time = 0.0365s; samplesPerSecond = 35047.4
08/04/2016 13:56:23:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.71184616 * 1280; EvalErrorPrediction = 0.51875000 * 1280; time = 0.0401s; samplesPerSecond = 31915.4
08/04/2016 13:56:23:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.69908276 * 1280; EvalErrorPrediction = 0.49140625 * 1280; time = 0.0425s; samplesPerSecond = 30103.5
08/04/2016 13:56:23:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.69459610 * 1280; EvalErrorPrediction = 0.50000000 * 1280; time = 0.0478s; samplesPerSecond = 26785.0
08/04/2016 13:56:24:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69395027 * 1280; EvalErrorPrediction = 0.50625000 * 1280; time = 0.0586s; samplesPerSecond = 21835.6
08/04/2016 13:56:24: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.69945850 * 10000; EvalErrorPrediction = 0.50280000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.348911s
08/04/2016 13:56:24: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.14'

08/04/2016 13:56:24: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: frames [140000..150000] (first sequence at sample 140000), data subset 0 of 1

08/04/2016 13:56:24: Starting minibatch loop.
08/04/2016 13:56:24:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71183653 * 1280; EvalErrorPrediction = 0.51015625 * 1280; time = 0.0363s; samplesPerSecond = 35246.2
08/04/2016 13:56:24:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.70774050 * 1280; EvalErrorPrediction = 0.46875000 * 1280; time = 0.0488s; samplesPerSecond = 26212.9
08/04/2016 13:56:24:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.70496845 * 1280; EvalErrorPrediction = 0.47812500 * 1280; time = 0.0310s; samplesPerSecond = 41350.3
08/04/2016 13:56:24:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.69899368 * 1280; EvalErrorPrediction = 0.48671875 * 1280; time = 0.0514s; samplesPerSecond = 24901.3
08/04/2016 13:56:24:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.70140018 * 1280; EvalErrorPrediction = 0.47812500 * 1280; time = 0.0663s; samplesPerSecond = 19293.1
08/04/2016 13:56:24:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70315132 * 1280; EvalErrorPrediction = 0.50703125 * 1280; time = 0.0486s; samplesPerSecond = 26339.6
08/04/2016 13:56:24:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70875702 * 1280; EvalErrorPrediction = 0.52265625 * 1280; time = 0.0432s; samplesPerSecond = 29615.9
08/04/2016 13:56:24: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.70676069 * 10000; EvalErrorPrediction = 0.49820000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.416065s
08/04/2016 13:56:24: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.15'

08/04/2016 13:56:24: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: frames [150000..160000] (first sequence at sample 150000), data subset 0 of 1

08/04/2016 13:56:24: Starting minibatch loop.
08/04/2016 13:56:24:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71198573 * 1280; EvalErrorPrediction = 0.49062500 * 1280; time = 0.0539s; samplesPerSecond = 23742.4
08/04/2016 13:56:24:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.69631286 * 1280; EvalErrorPrediction = 0.48750000 * 1280; time = 0.0760s; samplesPerSecond = 16847.0
08/04/2016 13:56:24:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.69536085 * 1280; EvalErrorPrediction = 0.50781250 * 1280; time = 0.1221s; samplesPerSecond = 10485.4
08/04/2016 13:56:24:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.69447155 * 1280; EvalErrorPrediction = 0.49609375 * 1280; time = 0.0484s; samplesPerSecond = 26419.5
08/04/2016 13:56:24:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.69721394 * 1280; EvalErrorPrediction = 0.48359375 * 1280; time = 0.0628s; samplesPerSecond = 20370.8
08/04/2016 13:56:24:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70483322 * 1280; EvalErrorPrediction = 0.47343750 * 1280; time = 0.0405s; samplesPerSecond = 31585.4
08/04/2016 13:56:24:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69378166 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.0812s; samplesPerSecond = 15760.6
08/04/2016 13:56:25: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.69921997 * 10000; EvalErrorPrediction = 0.49280000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.525328s
08/04/2016 13:56:25: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.16'

08/04/2016 13:56:25: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: frames [160000..170000] (first sequence at sample 160000), data subset 0 of 1

08/04/2016 13:56:25: Starting minibatch loop.
08/04/2016 13:56:25:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.69844508 * 1280; EvalErrorPrediction = 0.48906250 * 1280; time = 0.0428s; samplesPerSecond = 29929.6
08/04/2016 13:56:25:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.69641671 * 1280; EvalErrorPrediction = 0.50859375 * 1280; time = 0.0432s; samplesPerSecond = 29604.3
08/04/2016 13:56:25:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.69190826 * 1280; EvalErrorPrediction = 0.48359375 * 1280; time = 0.0523s; samplesPerSecond = 24493.9
08/04/2016 13:56:25:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.69766731 * 1280; EvalErrorPrediction = 0.47265625 * 1280; time = 0.0449s; samplesPerSecond = 28528.8
08/04/2016 13:56:25:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.70928288 * 1280; EvalErrorPrediction = 0.51640625 * 1280; time = 0.0480s; samplesPerSecond = 26650.0
08/04/2016 13:56:25:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.71303253 * 1280; EvalErrorPrediction = 0.48828125 * 1280; time = 0.0526s; samplesPerSecond = 24324.9
08/04/2016 13:56:25:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.72171516 * 1280; EvalErrorPrediction = 0.50546875 * 1280; time = 0.0406s; samplesPerSecond = 31527.9
08/04/2016 13:56:25: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.70401846 * 10000; EvalErrorPrediction = 0.49400000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.409705s
08/04/2016 13:56:25: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.17'

08/04/2016 13:56:25: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: frames [170000..180000] (first sequence at sample 170000), data subset 0 of 1

08/04/2016 13:56:25: Starting minibatch loop.
08/04/2016 13:56:25:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70839391 * 1280; EvalErrorPrediction = 0.52187500 * 1280; time = 0.1348s; samplesPerSecond = 9498.2
08/04/2016 13:56:25:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.70065541 * 1280; EvalErrorPrediction = 0.49218750 * 1280; time = 0.0838s; samplesPerSecond = 15271.5
08/04/2016 13:56:25:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.70551863 * 1280; EvalErrorPrediction = 0.50156250 * 1280; time = 0.0860s; samplesPerSecond = 14883.5
08/04/2016 13:56:25:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.70250492 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.0429s; samplesPerSecond = 29846.6
08/04/2016 13:56:25:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.69419155 * 1280; EvalErrorPrediction = 0.51718750 * 1280; time = 0.0414s; samplesPerSecond = 30901.5
08/04/2016 13:56:25:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.69587173 * 1280; EvalErrorPrediction = 0.48750000 * 1280; time = 0.0790s; samplesPerSecond = 16197.8
08/04/2016 13:56:25:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70199738 * 1280; EvalErrorPrediction = 0.51406250 * 1280; time = 0.0429s; samplesPerSecond = 29859.1
08/04/2016 13:56:25: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.70097256 * 10000; EvalErrorPrediction = 0.50480000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.545875s
08/04/2016 13:56:25: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.18'

08/04/2016 13:56:25: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: frames [180000..190000] (first sequence at sample 180000), data subset 0 of 1

08/04/2016 13:56:25: Starting minibatch loop.
08/04/2016 13:56:26:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.69720778 * 1280; EvalErrorPrediction = 0.46875000 * 1280; time = 0.0401s; samplesPerSecond = 31938.5
08/04/2016 13:56:26:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.65973792 * 1280; EvalErrorPrediction = 0.39921875 * 1280; time = 0.0429s; samplesPerSecond = 29827.8
08/04/2016 13:56:26:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.58150129 * 1280; EvalErrorPrediction = 0.33437500 * 1280; time = 0.0589s; samplesPerSecond = 21739.5
08/04/2016 13:56:26:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.44130116 * 1280; EvalErrorPrediction = 0.20312500 * 1280; time = 0.0442s; samplesPerSecond = 28938.3
08/04/2016 13:56:26:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.27846851 * 1280; EvalErrorPrediction = 0.10781250 * 1280; time = 0.0442s; samplesPerSecond = 28967.1
08/04/2016 13:56:26:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.20421238 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0442s; samplesPerSecond = 28952.1
08/04/2016 13:56:26:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.23771133 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0645s; samplesPerSecond = 19843.1
08/04/2016 13:56:26: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.41665547 * 10000; EvalErrorPrediction = 0.22040000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.391422s
08/04/2016 13:56:26: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.19'

08/04/2016 13:56:26: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: frames [190000..200000] (first sequence at sample 190000), data subset 0 of 1

08/04/2016 13:56:26: Starting minibatch loop.
08/04/2016 13:56:26:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.23279221 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0380s; samplesPerSecond = 33725.0
08/04/2016 13:56:26:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.21454771 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0408s; samplesPerSecond = 31361.0
08/04/2016 13:56:26:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.20506496 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0411s; samplesPerSecond = 31129.2
08/04/2016 13:56:26:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17603455 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0364s; samplesPerSecond = 35205.5
08/04/2016 13:56:26:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19496088 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0397s; samplesPerSecond = 32220.7
08/04/2016 13:56:26:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18030500 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0821s; samplesPerSecond = 15599.7
08/04/2016 13:56:26:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18337708 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0539s; samplesPerSecond = 23725.7
08/04/2016 13:56:26: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.19616757 * 10000; EvalErrorPrediction = 0.07880000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.376143s
08/04/2016 13:56:26: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.20'

08/04/2016 13:56:26: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: frames [200000..210000] (first sequence at sample 200000), data subset 0 of 1

08/04/2016 13:56:26: Starting minibatch loop.
08/04/2016 13:56:26:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17199899 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0581s; samplesPerSecond = 22026.1
08/04/2016 13:56:26:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15936936 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0852s; samplesPerSecond = 15020.7
08/04/2016 13:56:26:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18839002 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0577s; samplesPerSecond = 22181.4
08/04/2016 13:56:26:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17181163 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0570s; samplesPerSecond = 22455.7
08/04/2016 13:56:27:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15914507 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0617s; samplesPerSecond = 20752.6
08/04/2016 13:56:27:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15397816 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0459s; samplesPerSecond = 27874.0
08/04/2016 13:56:27:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18697186 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0534s; samplesPerSecond = 23992.1
08/04/2016 13:56:27: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.17277338 * 10000; EvalErrorPrediction = 0.07720000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.459607s
08/04/2016 13:56:27: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.21'

08/04/2016 13:56:27: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: frames [210000..220000] (first sequence at sample 210000), data subset 0 of 1

08/04/2016 13:56:27: Starting minibatch loop.
08/04/2016 13:56:27:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16214670 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0922s; samplesPerSecond = 13882.0
08/04/2016 13:56:27:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16322557 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0931s; samplesPerSecond = 13746.1
08/04/2016 13:56:27:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14523754 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0733s; samplesPerSecond = 17452.5
08/04/2016 13:56:27:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16846561 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0474s; samplesPerSecond = 26975.8
08/04/2016 13:56:27:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15109735 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0626s; samplesPerSecond = 20450.9
08/04/2016 13:56:27:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15218782 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0388s; samplesPerSecond = 32949.8
08/04/2016 13:56:27:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14314003 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0431s; samplesPerSecond = 29729.4
08/04/2016 13:56:27: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.15525283 * 10000; EvalErrorPrediction = 0.07500000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.514094s
08/04/2016 13:56:27: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.22'

08/04/2016 13:56:27: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: frames [220000..230000] (first sequence at sample 220000), data subset 0 of 1

08/04/2016 13:56:27: Starting minibatch loop.
08/04/2016 13:56:27:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15785203 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0335s; samplesPerSecond = 38253.5
08/04/2016 13:56:27:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17765379 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0301s; samplesPerSecond = 42496.7
08/04/2016 13:56:27:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14487529 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0628s; samplesPerSecond = 20388.7
08/04/2016 13:56:27:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12898722 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0458s; samplesPerSecond = 27965.9
08/04/2016 13:56:27:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18071141 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0424s; samplesPerSecond = 30205.1
08/04/2016 13:56:27:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13638606 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0406s; samplesPerSecond = 31530.2
08/04/2016 13:56:28:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15594101 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0405s; samplesPerSecond = 31566.7
08/04/2016 13:56:28: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.15570183 * 10000; EvalErrorPrediction = 0.07720000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.329927s
08/04/2016 13:56:28: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.23'

08/04/2016 13:56:28: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: frames [230000..240000] (first sequence at sample 230000), data subset 0 of 1

08/04/2016 13:56:28: Starting minibatch loop.
08/04/2016 13:56:28:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13819342 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0651s; samplesPerSecond = 19653.3
08/04/2016 13:56:28:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18159609 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0616s; samplesPerSecond = 20762.4
08/04/2016 13:56:28:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14341960 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0387s; samplesPerSecond = 33052.7
08/04/2016 13:56:28:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15305433 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0436s; samplesPerSecond = 29363.2
08/04/2016 13:56:28:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16941381 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0903s; samplesPerSecond = 14169.3
08/04/2016 13:56:28:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17220097 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0580s; samplesPerSecond = 22078.1
08/04/2016 13:56:28:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17676287 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0424s; samplesPerSecond = 30190.1
08/04/2016 13:56:28: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.16506849 * 10000; EvalErrorPrediction = 0.08180000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.44223s
08/04/2016 13:56:28: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.24'

08/04/2016 13:56:28: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: frames [240000..250000] (first sequence at sample 240000), data subset 0 of 1

08/04/2016 13:56:28: Starting minibatch loop.
08/04/2016 13:56:28:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16359271 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0554s; samplesPerSecond = 23116.0
08/04/2016 13:56:28:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18456107 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0437s; samplesPerSecond = 29310.7
08/04/2016 13:56:28:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17498393 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0420s; samplesPerSecond = 30484.2
08/04/2016 13:56:28:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15608902 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0445s; samplesPerSecond = 28770.5
08/04/2016 13:56:28:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17116418 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0494s; samplesPerSecond = 25926.7
08/04/2016 13:56:28:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12361946 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 0.0339s; samplesPerSecond = 37775.9
08/04/2016 13:56:28:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16122704 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0591s; samplesPerSecond = 21661.5
08/04/2016 13:56:28: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16104740 * 10000; EvalErrorPrediction = 0.07860000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.384435s
08/04/2016 13:56:28: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.25'

08/04/2016 13:56:28: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: frames [250000..260000] (first sequence at sample 250000), data subset 0 of 1

08/04/2016 13:56:28: Starting minibatch loop.
08/04/2016 13:56:28:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15851723 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0478s; samplesPerSecond = 26770.4
08/04/2016 13:56:28:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17445284 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0471s; samplesPerSecond = 27200.5
08/04/2016 13:56:29:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14722712 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0422s; samplesPerSecond = 30332.5
08/04/2016 13:56:29:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17697682 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0385s; samplesPerSecond = 33262.3
08/04/2016 13:56:29:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18040953 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0733s; samplesPerSecond = 17458.2
08/04/2016 13:56:29:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16045313 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0400s; samplesPerSecond = 31988.8
08/04/2016 13:56:29:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17958317 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0431s; samplesPerSecond = 29690.8
08/04/2016 13:56:29: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.16682238 * 10000; EvalErrorPrediction = 0.08040000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.372241s
08/04/2016 13:56:29: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.26'

08/04/2016 13:56:29: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: frames [260000..270000] (first sequence at sample 260000), data subset 0 of 1

08/04/2016 13:56:29: Starting minibatch loop.
08/04/2016 13:56:29:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15378945 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0845s; samplesPerSecond = 15142.0
08/04/2016 13:56:29:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16407278 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0497s; samplesPerSecond = 25731.7
08/04/2016 13:56:29:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17003627 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0860s; samplesPerSecond = 14889.1
08/04/2016 13:56:29:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13985147 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0445s; samplesPerSecond = 28773.1
08/04/2016 13:56:29:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14217367 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0623s; samplesPerSecond = 20553.0
08/04/2016 13:56:29:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15432105 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0357s; samplesPerSecond = 35860.4
08/04/2016 13:56:29:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16528149 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0453s; samplesPerSecond = 28231.1
08/04/2016 13:56:29: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.15654271 * 10000; EvalErrorPrediction = 0.07780000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.444648s
08/04/2016 13:56:29: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.27'

08/04/2016 13:56:29: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: frames [270000..280000] (first sequence at sample 270000), data subset 0 of 1

08/04/2016 13:56:29: Starting minibatch loop.
08/04/2016 13:56:29:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15670730 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0377s; samplesPerSecond = 33962.2
08/04/2016 13:56:29:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13261188 * 1280; EvalErrorPrediction = 0.05468750 * 1280; time = 0.0558s; samplesPerSecond = 22937.4
08/04/2016 13:56:29:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17829342 * 1280; EvalErrorPrediction = 0.09296875 * 1280; time = 0.0539s; samplesPerSecond = 23751.2
08/04/2016 13:56:29:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14538617 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0400s; samplesPerSecond = 32024.0
08/04/2016 13:56:29:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16018119 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0450s; samplesPerSecond = 28462.8
08/04/2016 13:56:29:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14456038 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0426s; samplesPerSecond = 30017.4
08/04/2016 13:56:29:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16905909 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0326s; samplesPerSecond = 39296.3
08/04/2016 13:56:30: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.15899316 * 10000; EvalErrorPrediction = 0.07720000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.336653s
08/04/2016 13:56:30: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.28'

08/04/2016 13:56:30: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: frames [280000..290000] (first sequence at sample 280000), data subset 0 of 1

08/04/2016 13:56:30: Starting minibatch loop.
08/04/2016 13:56:30:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16690173 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0471s; samplesPerSecond = 27168.1
08/04/2016 13:56:30:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14944787 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0419s; samplesPerSecond = 30554.8
08/04/2016 13:56:30:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15300684 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0586s; samplesPerSecond = 21840.8
08/04/2016 13:56:30:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17176800 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0414s; samplesPerSecond = 30894.0
08/04/2016 13:56:30:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16331739 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0646s; samplesPerSecond = 19805.4
08/04/2016 13:56:30:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16353312 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.1349s; samplesPerSecond = 9489.4
08/04/2016 13:56:30:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16163511 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.1303s; samplesPerSecond = 9821.0
08/04/2016 13:56:30: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.15952449 * 10000; EvalErrorPrediction = 0.08010000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.590797s
08/04/2016 13:56:30: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.29'

08/04/2016 13:56:30: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: frames [290000..300000] (first sequence at sample 290000), data subset 0 of 1

08/04/2016 13:56:30: Starting minibatch loop.
08/04/2016 13:56:30:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17038417 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0447s; samplesPerSecond = 28652.0
08/04/2016 13:56:30:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15585735 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0699s; samplesPerSecond = 18311.4
08/04/2016 13:56:30:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15389488 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0557s; samplesPerSecond = 22972.0
08/04/2016 13:56:30:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13553610 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0585s; samplesPerSecond = 21890.4
08/04/2016 13:56:30:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16654711 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0419s; samplesPerSecond = 30573.0
08/04/2016 13:56:30:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13753681 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0490s; samplesPerSecond = 26132.0
08/04/2016 13:56:30:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14719267 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0356s; samplesPerSecond = 35999.6
08/04/2016 13:56:31: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.15234232 * 10000; EvalErrorPrediction = 0.07860000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.385877s
08/04/2016 13:56:31: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.30'

08/04/2016 13:56:31: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: frames [300000..310000] (first sequence at sample 300000), data subset 0 of 1

08/04/2016 13:56:31: Starting minibatch loop.
08/04/2016 13:56:31:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15083717 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0808s; samplesPerSecond = 15836.7
08/04/2016 13:56:31:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14541281 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0716s; samplesPerSecond = 17871.4
08/04/2016 13:56:31:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14569614 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0666s; samplesPerSecond = 19219.8
08/04/2016 13:56:31:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15457211 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0508s; samplesPerSecond = 25174.1
08/04/2016 13:56:31:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14794283 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0632s; samplesPerSecond = 20255.1
08/04/2016 13:56:31:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15519171 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0461s; samplesPerSecond = 27759.1
08/04/2016 13:56:31:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15347385 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0397s; samplesPerSecond = 32225.6
08/04/2016 13:56:31: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15286260 * 10000; EvalErrorPrediction = 0.07770000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.467112s
08/04/2016 13:56:31: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.31'

08/04/2016 13:56:31: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: frames [310000..320000] (first sequence at sample 310000), data subset 0 of 1

08/04/2016 13:56:31: Starting minibatch loop.
08/04/2016 13:56:31:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16528465 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0588s; samplesPerSecond = 21770.9
08/04/2016 13:56:31:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17478119 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0444s; samplesPerSecond = 28815.8
08/04/2016 13:56:31:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15400040 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0380s; samplesPerSecond = 33709.0
08/04/2016 13:56:31:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15513558 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0385s; samplesPerSecond = 33225.2
08/04/2016 13:56:31:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14281683 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0427s; samplesPerSecond = 30008.9
08/04/2016 13:56:31:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14572625 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0632s; samplesPerSecond = 20260.2
08/04/2016 13:56:31:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15571814 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0388s; samplesPerSecond = 33031.4
08/04/2016 13:56:31: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.15555485 * 10000; EvalErrorPrediction = 0.08080000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.365594s
08/04/2016 13:56:31: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.32'

08/04/2016 13:56:31: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: frames [320000..330000] (first sequence at sample 320000), data subset 0 of 1

08/04/2016 13:56:31: Starting minibatch loop.
08/04/2016 13:56:31:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14382381 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0405s; samplesPerSecond = 31589.3
08/04/2016 13:56:31:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15294588 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0479s; samplesPerSecond = 26712.3
08/04/2016 13:56:31:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15526693 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0481s; samplesPerSecond = 26610.7
08/04/2016 13:56:32:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14622874 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0859s; samplesPerSecond = 14908.0
08/04/2016 13:56:32:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16108193 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0409s; samplesPerSecond = 31316.5
08/04/2016 13:56:32:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15701184 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0427s; samplesPerSecond = 29942.2
08/04/2016 13:56:32:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15636120 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0426s; samplesPerSecond = 30066.7
08/04/2016 13:56:32: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15164596 * 10000; EvalErrorPrediction = 0.07970000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.411334s
08/04/2016 13:56:32: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.33'

08/04/2016 13:56:32: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: frames [330000..340000] (first sequence at sample 330000), data subset 0 of 1

08/04/2016 13:56:32: Starting minibatch loop.
08/04/2016 13:56:32:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15995210 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.2236s; samplesPerSecond = 5723.7
08/04/2016 13:56:32:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14499305 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.1833s; samplesPerSecond = 6983.5
08/04/2016 13:56:32:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15010016 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.1196s; samplesPerSecond = 10700.8
08/04/2016 13:56:32:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14694967 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0418s; samplesPerSecond = 30655.7
08/04/2016 13:56:32:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14326777 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0405s; samplesPerSecond = 31641.7
08/04/2016 13:56:32:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14544940 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0496s; samplesPerSecond = 25803.3
08/04/2016 13:56:32:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15656776 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0473s; samplesPerSecond = 27086.5
08/04/2016 13:56:33: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15044874 * 10000; EvalErrorPrediction = 0.07690000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.759293s
08/04/2016 13:56:33: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.34'

08/04/2016 13:56:33: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: frames [340000..350000] (first sequence at sample 340000), data subset 0 of 1

08/04/2016 13:56:33: Starting minibatch loop.
08/04/2016 13:56:33:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14754088 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0435s; samplesPerSecond = 29456.4
08/04/2016 13:56:33:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17477088 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.1460s; samplesPerSecond = 8769.0
08/04/2016 13:56:33:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15553596 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0431s; samplesPerSecond = 29724.6
08/04/2016 13:56:33:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15690260 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0650s; samplesPerSecond = 19678.7
08/04/2016 13:56:33:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15011435 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0750s; samplesPerSecond = 17059.2
08/04/2016 13:56:33:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13358073 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0628s; samplesPerSecond = 20376.3
08/04/2016 13:56:33:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14275351 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0706s; samplesPerSecond = 18131.3
08/04/2016 13:56:33: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15324899 * 10000; EvalErrorPrediction = 0.07940000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.546099s
08/04/2016 13:56:33: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.35'

08/04/2016 13:56:33: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: frames [350000..360000] (first sequence at sample 350000), data subset 0 of 1

08/04/2016 13:56:33: Starting minibatch loop.
08/04/2016 13:56:33:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16814933 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0405s; samplesPerSecond = 31596.4
08/04/2016 13:56:33:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14357436 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0571s; samplesPerSecond = 22406.6
08/04/2016 13:56:33:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14905589 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0477s; samplesPerSecond = 26816.4
08/04/2016 13:56:33:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12688069 * 1280; EvalErrorPrediction = 0.05468750 * 1280; time = 0.0430s; samplesPerSecond = 29746.0
08/04/2016 13:56:33:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15100965 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0394s; samplesPerSecond = 32525.3
08/04/2016 13:56:33:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14138694 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0405s; samplesPerSecond = 31597.1
08/04/2016 13:56:33:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15822191 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0512s; samplesPerSecond = 25017.6
08/04/2016 13:56:33: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.14852607 * 10000; EvalErrorPrediction = 0.07440000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.346211s
08/04/2016 13:56:33: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.36'

08/04/2016 13:56:33: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: frames [360000..370000] (first sequence at sample 360000), data subset 0 of 1

08/04/2016 13:56:33: Starting minibatch loop.
08/04/2016 13:56:33:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16918678 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0660s; samplesPerSecond = 19398.3
08/04/2016 13:56:34:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14449601 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0363s; samplesPerSecond = 35241.3
08/04/2016 13:56:34:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14142461 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0321s; samplesPerSecond = 39931.4
08/04/2016 13:56:34:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16014857 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0442s; samplesPerSecond = 28991.4
08/04/2016 13:56:34:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14730439 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0403s; samplesPerSecond = 31724.8
08/04/2016 13:56:34:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15811968 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0347s; samplesPerSecond = 36900.4
08/04/2016 13:56:34:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14146738 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0925s; samplesPerSecond = 13839.2
08/04/2016 13:56:34: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.15149464 * 10000; EvalErrorPrediction = 0.07830000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.398975s
08/04/2016 13:56:34: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.37'

08/04/2016 13:56:34: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: frames [370000..380000] (first sequence at sample 370000), data subset 0 of 1

08/04/2016 13:56:34: Starting minibatch loop.
08/04/2016 13:56:34:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14870226 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.1811s; samplesPerSecond = 7067.8
08/04/2016 13:56:34:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14043787 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0766s; samplesPerSecond = 16712.4
08/04/2016 13:56:34:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14806423 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0488s; samplesPerSecond = 26246.2
08/04/2016 13:56:34:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15348649 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0305s; samplesPerSecond = 41998.9
08/04/2016 13:56:34:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16215634 * 1280; EvalErrorPrediction = 0.09296875 * 1280; time = 0.0305s; samplesPerSecond = 42007.2
08/04/2016 13:56:34:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18351860 * 1280; EvalErrorPrediction = 0.09531250 * 1280; time = 0.0300s; samplesPerSecond = 42636.8
08/04/2016 13:56:34:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18021975 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0411s; samplesPerSecond = 31154.9
08/04/2016 13:56:34: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.15762806 * 10000; EvalErrorPrediction = 0.08150000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.482675s
08/04/2016 13:56:34: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.38'

08/04/2016 13:56:34: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: frames [380000..390000] (first sequence at sample 380000), data subset 0 of 1

08/04/2016 13:56:34: Starting minibatch loop.
08/04/2016 13:56:34:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16699712 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0383s; samplesPerSecond = 33384.6
08/04/2016 13:56:34:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14548721 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.1363s; samplesPerSecond = 9392.9
08/04/2016 13:56:35:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15591757 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.1324s; samplesPerSecond = 9671.2
08/04/2016 13:56:35:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15796304 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0631s; samplesPerSecond = 20281.4
08/04/2016 13:56:35:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16055398 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0508s; samplesPerSecond = 25219.7
08/04/2016 13:56:35:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15695095 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0429s; samplesPerSecond = 29808.3
08/04/2016 13:56:35:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13774548 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0706s; samplesPerSecond = 18124.7
08/04/2016 13:56:35: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.15348557 * 10000; EvalErrorPrediction = 0.07880000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.574038s
08/04/2016 13:56:35: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.39'

08/04/2016 13:56:35: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: frames [390000..400000] (first sequence at sample 390000), data subset 0 of 1

08/04/2016 13:56:35: Starting minibatch loop.
08/04/2016 13:56:35:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16656249 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0338s; samplesPerSecond = 37909.1
08/04/2016 13:56:35:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12926486 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0293s; samplesPerSecond = 43712.9
08/04/2016 13:56:35:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14740891 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0913s; samplesPerSecond = 14012.2
08/04/2016 13:56:35:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15587821 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0450s; samplesPerSecond = 28435.6
08/04/2016 13:56:35:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14922662 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0476s; samplesPerSecond = 26867.6
08/04/2016 13:56:35:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14609118 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0522s; samplesPerSecond = 24512.2
08/04/2016 13:56:35:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15192356 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0317s; samplesPerSecond = 40391.3
08/04/2016 13:56:35: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.14964708 * 10000; EvalErrorPrediction = 0.07620000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.371851s
08/04/2016 13:56:35: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.40'

08/04/2016 13:56:35: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: frames [400000..410000] (first sequence at sample 400000), data subset 0 of 1

08/04/2016 13:56:35: Starting minibatch loop.
08/04/2016 13:56:35:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15286179 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0600s; samplesPerSecond = 21350.1
08/04/2016 13:56:35:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14542961 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0401s; samplesPerSecond = 31908.3
08/04/2016 13:56:35:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15526195 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0427s; samplesPerSecond = 29949.2
08/04/2016 13:56:35:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14589567 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0421s; samplesPerSecond = 30376.4
08/04/2016 13:56:35:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15836959 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0342s; samplesPerSecond = 37424.7
08/04/2016 13:56:35:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15966015 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0302s; samplesPerSecond = 42430.5
08/04/2016 13:56:36:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.20243835 * 1280; EvalErrorPrediction = 0.11484375 * 1280; time = 0.0305s; samplesPerSecond = 41921.9
08/04/2016 13:56:36: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.16085637 * 10000; EvalErrorPrediction = 0.08540000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.31257s
08/04/2016 13:56:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.41'

08/04/2016 13:56:36: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: frames [410000..420000] (first sequence at sample 410000), data subset 0 of 1

08/04/2016 13:56:36: Starting minibatch loop.
08/04/2016 13:56:36:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18347971 * 1280; EvalErrorPrediction = 0.09609375 * 1280; time = 0.0296s; samplesPerSecond = 43228.6
08/04/2016 13:56:36:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13446050 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0664s; samplesPerSecond = 19271.9
08/04/2016 13:56:36:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15499790 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0440s; samplesPerSecond = 29059.9
08/04/2016 13:56:36:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15999503 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.1172s; samplesPerSecond = 10917.4
08/04/2016 13:56:36:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16586809 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0492s; samplesPerSecond = 26032.1
08/04/2016 13:56:36:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14672604 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0385s; samplesPerSecond = 33222.6
08/04/2016 13:56:36:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18086157 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0411s; samplesPerSecond = 31177.7
08/04/2016 13:56:36: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15932316 * 10000; EvalErrorPrediction = 0.08150000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.427203s
08/04/2016 13:56:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.42'

08/04/2016 13:56:36: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: frames [420000..430000] (first sequence at sample 420000), data subset 0 of 1

08/04/2016 13:56:36: Starting minibatch loop.
08/04/2016 13:56:36:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16088761 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0697s; samplesPerSecond = 18353.6
08/04/2016 13:56:36:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15061613 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0582s; samplesPerSecond = 22010.1
08/04/2016 13:56:36:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13726888 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0390s; samplesPerSecond = 32858.4
08/04/2016 13:56:36:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15200911 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0437s; samplesPerSecond = 29295.3
08/04/2016 13:56:36:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15453978 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0567s; samplesPerSecond = 22580.5
08/04/2016 13:56:36:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13324957 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0443s; samplesPerSecond = 28894.6
08/04/2016 13:56:36:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15860958 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0447s; samplesPerSecond = 28661.0
08/04/2016 13:56:36: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.14981448 * 10000; EvalErrorPrediction = 0.07640000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.397003s
08/04/2016 13:56:36: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.43'

08/04/2016 13:56:36: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: frames [430000..440000] (first sequence at sample 430000), data subset 0 of 1

08/04/2016 13:56:36: Starting minibatch loop.
08/04/2016 13:56:36:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.21357241 * 1280; EvalErrorPrediction = 0.11640625 * 1280; time = 0.0386s; samplesPerSecond = 33183.8
08/04/2016 13:56:36:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15679336 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0313s; samplesPerSecond = 40957.4
08/04/2016 13:56:36:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17429566 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0306s; samplesPerSecond = 41838.3
08/04/2016 13:56:37:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16049871 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0305s; samplesPerSecond = 42033.4
08/04/2016 13:56:37:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16055527 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0350s; samplesPerSecond = 36543.2
08/04/2016 13:56:37:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14624605 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0338s; samplesPerSecond = 37818.4
08/04/2016 13:56:37:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15504007 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0566s; samplesPerSecond = 22606.5
08/04/2016 13:56:37: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.16432490 * 10000; EvalErrorPrediction = 0.08650000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.341011s
08/04/2016 13:56:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.44'

08/04/2016 13:56:37: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: frames [440000..450000] (first sequence at sample 440000), data subset 0 of 1

08/04/2016 13:56:37: Starting minibatch loop.
08/04/2016 13:56:37:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13983439 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.1176s; samplesPerSecond = 10887.2
08/04/2016 13:56:37:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17509104 * 1280; EvalErrorPrediction = 0.09843750 * 1280; time = 0.2646s; samplesPerSecond = 4838.2
08/04/2016 13:56:37:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14840012 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0943s; samplesPerSecond = 13572.5
08/04/2016 13:56:37:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13573937 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0595s; samplesPerSecond = 21509.4
08/04/2016 13:56:37:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14269590 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0633s; samplesPerSecond = 20223.1
08/04/2016 13:56:37:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15744114 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0381s; samplesPerSecond = 33580.8
08/04/2016 13:56:37:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15774803 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0446s; samplesPerSecond = 28697.6
08/04/2016 13:56:37: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.15168179 * 10000; EvalErrorPrediction = 0.07980000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.721027s
08/04/2016 13:56:37: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.45'

08/04/2016 13:56:37: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: frames [450000..460000] (first sequence at sample 450000), data subset 0 of 1

08/04/2016 13:56:37: Starting minibatch loop.
08/04/2016 13:56:37:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16510248 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0444s; samplesPerSecond = 28854.8
08/04/2016 13:56:38:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15626600 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0315s; samplesPerSecond = 40689.2
08/04/2016 13:56:38:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16486700 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0303s; samplesPerSecond = 42187.1
08/04/2016 13:56:38:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12424998 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0415s; samplesPerSecond = 30815.9
08/04/2016 13:56:38:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15367961 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0614s; samplesPerSecond = 20846.2
08/04/2016 13:56:38:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15873713 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0428s; samplesPerSecond = 29879.3
08/04/2016 13:56:38:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14912014 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0873s; samplesPerSecond = 14669.0
08/04/2016 13:56:38: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.15289617 * 10000; EvalErrorPrediction = 0.07800000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.379752s
08/04/2016 13:56:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.46'

08/04/2016 13:56:38: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: frames [460000..470000] (first sequence at sample 460000), data subset 0 of 1

08/04/2016 13:56:38: Starting minibatch loop.
08/04/2016 13:56:38:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16056395 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0397s; samplesPerSecond = 32258.1
08/04/2016 13:56:38:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15433502 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0603s; samplesPerSecond = 21240.6
08/04/2016 13:56:38:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15512433 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0425s; samplesPerSecond = 30146.0
08/04/2016 13:56:38:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14751096 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0533s; samplesPerSecond = 24023.1
08/04/2016 13:56:38:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14745121 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0655s; samplesPerSecond = 19533.0
08/04/2016 13:56:38:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14224262 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0420s; samplesPerSecond = 30498.7
08/04/2016 13:56:38:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13882265 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0432s; samplesPerSecond = 29608.4
08/04/2016 13:56:38: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.14945847 * 10000; EvalErrorPrediction = 0.07660000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.385662s
08/04/2016 13:56:38: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.47'

08/04/2016 13:56:38: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: frames [470000..480000] (first sequence at sample 470000), data subset 0 of 1

08/04/2016 13:56:38: Starting minibatch loop.
08/04/2016 13:56:38:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16344445 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0326s; samplesPerSecond = 39203.7
08/04/2016 13:56:38:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13980522 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0305s; samplesPerSecond = 41953.5
08/04/2016 13:56:38:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15477612 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0813s; samplesPerSecond = 15753.5
08/04/2016 13:56:38:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14302855 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0527s; samplesPerSecond = 24302.3
08/04/2016 13:56:38:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14690127 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0494s; samplesPerSecond = 25901.0
08/04/2016 13:56:38:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13862257 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0362s; samplesPerSecond = 35328.9
08/04/2016 13:56:39:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16758471 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0578s; samplesPerSecond = 22130.8
08/04/2016 13:56:39: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.15063077 * 10000; EvalErrorPrediction = 0.07650000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.375922s
08/04/2016 13:56:39: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.48'

08/04/2016 13:56:39: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: frames [480000..490000] (first sequence at sample 480000), data subset 0 of 1

08/04/2016 13:56:39: Starting minibatch loop.
08/04/2016 13:56:39:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15444551 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0508s; samplesPerSecond = 25187.9
08/04/2016 13:56:39:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14152763 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0580s; samplesPerSecond = 22076.2
08/04/2016 13:56:39:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14774129 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0441s; samplesPerSecond = 29015.7
08/04/2016 13:56:39:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16334229 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0653s; samplesPerSecond = 19606.3
08/04/2016 13:56:39:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14751935 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0660s; samplesPerSecond = 19384.8
08/04/2016 13:56:39:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16289992 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0390s; samplesPerSecond = 32802.8
08/04/2016 13:56:39:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15982933 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0404s; samplesPerSecond = 31674.5
08/04/2016 13:56:39: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.15365596 * 10000; EvalErrorPrediction = 0.07820000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.409834s
08/04/2016 13:56:39: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.49'

08/04/2016 13:56:39: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

08/04/2016 13:56:39: Starting minibatch loop.
08/04/2016 13:56:39:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16831330 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0470s; samplesPerSecond = 27228.2
08/04/2016 13:56:39:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15856899 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0562s; samplesPerSecond = 22775.8
08/04/2016 13:56:39:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15265706 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0427s; samplesPerSecond = 29961.1
08/04/2016 13:56:39:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16776123 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0405s; samplesPerSecond = 31613.5
08/04/2016 13:56:39:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14149656 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0453s; samplesPerSecond = 28256.1
08/04/2016 13:56:39:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13524547 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.1017s; samplesPerSecond = 12588.8
08/04/2016 13:56:39:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14816017 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0551s; samplesPerSecond = 23215.7
08/04/2016 13:56:39: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15279540 * 10000; EvalErrorPrediction = 0.07720000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.437046s
08/04/2016 13:56:39: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn'
08/04/2016 13:56:39: CNTKCommandTrainEnd: Simple_Demo

08/04/2016 13:56:39: Action "train" complete.


08/04/2016 13:56:39: ##############################################################################
08/04/2016 13:56:39: #                                                                            #
08/04/2016 13:56:39: # Action "write"                                                             #
08/04/2016 13:56:39: #                                                                            #
08/04/2016 13:56:39: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *1]] [W0*features+B0 Gradient[50 x 1 x *1]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
0x7f7eefb259f8: {[B0 Value[50 x 1]] }
0x7f7eefb26678: {[B1 Value[50 x 1]] }
0x7f7eefb272b8: {[B2 Value[2 x 1]] }
0x7f7eefb44b08: {[features Value[2 x *1]] }
0x7f7eefb454a8: {[MeanOfFeatures Value[2]] }
0x7f7eefb45878: {[InvStdOfFeatures Value[2]] }
0x7f7eefb462b8: {[labels Value[2 x *1]] }
0x7f7eefb475b8: {[Prior Value[2]] }
0x7f7eefb477f8: {[W0 Value[50 x 2]] }
0x7f7eefb48168: {[W2 Value[2 x 50]] }
0x7f7eefb48b78: {[W1 Value[50 x 50]] }
0x7f7eefb5d6c8: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
0x7f7eefb5db58: {[LogOfPrior Value[2]] }
0x7f7eefb5eff8: {[MVNormalizedFeatures Value[2 x *1]] }
0x7f7eefb5f5e8: {[W0*features Value[50 x *1]] }
0x7f7eefb5f998: {[W0*features+B0 Value[50 x 1 x *1]] }
0x7f7eefb5faf8: {[H1 Value[50 x 1 x *1]] }
0x7f7eefb5fc58: {[W1*H1 Value[50 x 1 x *1]] }
0x7f7eefb5fe18: {[W1*H1+B1 Value[50 x 1 x *1]] }
0x7f7eefb5ffd8: {[H2 Value[50 x 1 x *1]] }
0x7f7eefb60198: {[W2*H1 Value[2 x 1 x *1]] }
0x7f7eefb60358: {[HLast Value[2 x 1 x *1]] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

08/04/2016 13:56:39: Action "write" complete.

08/04/2016 13:56:39: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple OutputDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu DeviceId=-1 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug  4 2016 13:05:36
		Last modified date: Thu Aug  4 12:33:33 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-4.0
		Build Branch: HEAD
		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
		Built by philly on 643085f7f8c2
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
08/04/2016 13:56:40: -------------------------------------------------------------------
08/04/2016 13:56:40: Build info: 

08/04/2016 13:56:40: 		Built time: Aug  4 2016 13:05:36
08/04/2016 13:56:40: 		Last modified date: Thu Aug  4 12:33:33 2016
08/04/2016 13:56:40: 		Build type: release
08/04/2016 13:56:40: 		Build target: GPU
08/04/2016 13:56:40: 		With 1bit-SGD: no
08/04/2016 13:56:40: 		Math lib: mkl
08/04/2016 13:56:40: 		CUDA_PATH: /usr/local/cuda-7.5
08/04/2016 13:56:40: 		CUB_PATH: /usr/local/cub-1.4.1
08/04/2016 13:56:40: 		CUDNN_PATH: /usr/local/cudnn-4.0
08/04/2016 13:56:40: 		Build Branch: HEAD
08/04/2016 13:56:40: 		Build SHA1: 0f61695dfc335f2406284d335678f57c215e6e9c
08/04/2016 13:56:40: 		Built by philly on 643085f7f8c2
08/04/2016 13:56:40: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
08/04/2016 13:56:40: -------------------------------------------------------------------
08/04/2016 13:56:41: -------------------------------------------------------------------
08/04/2016 13:56:41: GPU info:

08/04/2016 13:56:41: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:56:41: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:56:41: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:56:41: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3071 MB
08/04/2016 13:56:41: -------------------------------------------------------------------

08/04/2016 13:56:41: Running on localhost at 2016/08/04 13:56:41
08/04/2016 13:56:41: Command line: 
/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple/cntk.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple  OutputDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  makeMode=true



08/04/2016 13:56:41: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/04/2016 13:56:41: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/04/2016 13:56:41: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/04/2016 13:56:41: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/04/2016 13:56:41: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
RunDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu
DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
OutputDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/04/2016 13:56:41: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/04/2016 13:56:41: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Simple
configparameters: cntk.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=/home/philly/jenkins/workspace/CNTK-Test-Linux-W1/Tests/EndToEndTests/Speech/Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/04/2016 13:56:41: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/04/2016 13:56:41: Commands: Simple_Demo Simple_Demo_Output
08/04/2016 13:56:41: Precision = "float"
08/04/2016 13:56:41: CNTKModelPath: /tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn
08/04/2016 13:56:41: CNTKCommandTrainInfo: Simple_Demo : 50
08/04/2016 13:56:41: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/04/2016 13:56:41: ##############################################################################
08/04/2016 13:56:41: #                                                                            #
08/04/2016 13:56:41: # Action "train"                                                             #
08/04/2016 13:56:41: #                                                                            #
08/04/2016 13:56:41: ##############################################################################

08/04/2016 13:56:41: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

08/04/2016 13:56:41: Starting from checkpoint. Loading network from '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/04/2016 13:56:41: Loaded model with 25 nodes on CPU.

08/04/2016 13:56:41: Training criterion node(s):
08/04/2016 13:56:41: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/04/2016 13:56:41: Evaluation criterion node(s):

08/04/2016 13:56:41: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *1]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *1]] [PosteriorProb Value[2 x 1 x *1]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *1]] [features Gradient[2 x *1]] [labels Gradient[2 x *1]] }
0x2b10d18: {[B0 Value[50 x 1]] }
0x2b10ef8: {[B2 Value[2 x 1]] }
0x2b11d58: {[B1 Value[50 x 1]] }
0x2b12ab8: {[features Value[2 x *1]] }
0x2b141c8: {[InvStdOfFeatures Value[2]] }
0x2b14b88: {[labels Value[2 x *1]] }
0x2b153e8: {[MeanOfFeatures Value[2]] }
0x2b15648: {[Prior Value[2]] }
0x2b16118: {[W0 Value[50 x 2]] }
0x2b16ab8: {[W1 Value[50 x 50]] }
0x2b17b98: {[W2 Value[2 x 50]] }
0x2b1f678: {[EvalErrorPrediction Value[1]] }
0x2b1f968: {[ScaledLogLikelihood Value[2 x 1 x *1]] }
0x2b1fb28: {[CrossEntropyWithSoftmax Value[1]] }
0x2b20008: {[W0 Gradient[50 x 2]] [W0*features+B0 Value[50 x 1 x *1]] }
0x2b20138: {[LogOfPrior Value[2]] }
0x2ee2a38: {[MVNormalizedFeatures Value[2 x *1]] }
0x2ee31f8: {[W0*features Value[50 x *1]] }
0x2ee3408: {[H1 Value[50 x 1 x *1]] [W0*features Gradient[50 x *1]] }
0x2ee35c8: {[W0*features+B0 Gradient[50 x 1 x *1]] [W1*H1 Value[50 x 1 x *1]] }
0x2ee3788: {[W1 Gradient[50 x 50]] [W1*H1+B1 Value[50 x 1 x *1]] }
0x2ee3948: {[H2 Value[50 x 1 x *1]] [W1*H1 Gradient[50 x 1 x *1]] }
0x2ee3b08: {[B0 Gradient[50 x 1]] [H1 Gradient[50 x 1 x *1]] [W1*H1+B1 Gradient[50 x 1 x *1]] [W2*H1 Value[2 x 1 x *1]] }
0x2ee3cc8: {[HLast Value[2 x 1 x *1]] [W2 Gradient[2 x 50]] }
0x2ee47f8: {[CrossEntropyWithSoftmax Gradient[1]] }
0x2ee49b8: {[B1 Gradient[50 x 1]] [H2 Gradient[50 x 1 x *1]] [HLast Gradient[2 x 1 x *1]] }
0x2ee4b78: {[W2*H1 Gradient[2 x 1 x *1]] }
0x2ee4d38: {[B2 Gradient[2 x 1]] }

08/04/2016 13:56:41: No PreCompute nodes found, skipping PreCompute step.

08/04/2016 13:56:41: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: frames [490000..500000] (first sequence at sample 490000), data subset 0 of 1

08/04/2016 13:56:41: Starting minibatch loop.
08/04/2016 13:56:41:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.16831330 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.3041s; samplesPerSecond = 4209.7
08/04/2016 13:56:41:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.15856899 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0591s; samplesPerSecond = 21645.0
08/04/2016 13:56:41:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.15265706 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0392s; samplesPerSecond = 32638.9
08/04/2016 13:56:41:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.16776123 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0642s; samplesPerSecond = 19941.1
08/04/2016 13:56:41:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.14149656 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0329s; samplesPerSecond = 38942.5
08/04/2016 13:56:41:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.13524547 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0441s; samplesPerSecond = 29002.6
08/04/2016 13:56:41:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.14816017 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0849s; samplesPerSecond = 15069.1
08/04/2016 13:56:41: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.15279540 * 10000; EvalErrorPrediction = 0.07720000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.670126s
08/04/2016 13:56:41: SGD: Saving checkpoint model '/tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/models/simple.dnn'
08/04/2016 13:56:41: CNTKCommandTrainEnd: Simple_Demo

08/04/2016 13:56:41: Action "train" complete.


08/04/2016 13:56:41: ##############################################################################
08/04/2016 13:56:41: #                                                                            #
08/04/2016 13:56:41: # Action "write"                                                             #
08/04/2016 13:56:41: #                                                                            #
08/04/2016 13:56:41: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing Structure:

(nil): {[B0 Gradient[50 x 1]] [B1 Gradient[50 x 1]] [B2 Gradient[2 x 1]] [CrossEntropyWithSoftmax Gradient[1]] [CrossEntropyWithSoftmax Value[1]] [EvalErrorPrediction Gradient[1]] [EvalErrorPrediction Value[1]] [H1 Gradient[50 x 1 x *2]] [H2 Gradient[50 x 1 x *2]] [HLast Gradient[2 x 1 x *2]] [InvStdOfFeatures Gradient[2]] [LogOfPrior Gradient[2]] [MVNormalizedFeatures Gradient[2 x *2]] [MeanOfFeatures Gradient[2]] [PosteriorProb Gradient[2 x 1 x *2]] [PosteriorProb Value[2 x 1 x *2]] [Prior Gradient[2]] [ScaledLogLikelihood Gradient[2 x 1 x *2]] [W0 Gradient[50 x 2]] [W0*features Gradient[50 x *2]] [W0*features+B0 Gradient[50 x 1 x *2]] [W1 Gradient[50 x 50]] [W1*H1 Gradient[50 x 1 x *2]] [W1*H1+B1 Gradient[50 x 1 x *2]] [W2 Gradient[2 x 50]] [W2*H1 Gradient[2 x 1 x *2]] [features Gradient[2 x *2]] [labels Gradient[2 x *2]] }
0x7f4d04729a28: {[ScaledLogLikelihood Value[2 x 1 x *2]] }
0x7f4d0472a5b8: {[B0 Value[50 x 1]] }
0x7f4d0472a658: {[features Value[2 x *2]] }
0x7f4d0472ad38: {[B1 Value[50 x 1]] }
0x7f4d0472b2b8: {[B2 Value[2 x 1]] }
0x7f4d04740fa8: {[InvStdOfFeatures Value[2]] }
0x7f4d04741998: {[labels Value[2 x *2]] }
0x7f4d047421f8: {[MeanOfFeatures Value[2]] }
0x7f4d047424c8: {[Prior Value[2]] }
0x7f4d04743638: {[W0 Value[50 x 2]] }
0x7f4d047438b8: {[W1 Value[50 x 50]] }
0x7f4d04744968: {[W2 Value[2 x 50]] }
0x7f4d0474cae8: {[MVNormalizedFeatures Value[2 x *2]] }
0x7f4d0474cb88: {[LogOfPrior Value[2]] }
0x7f4d0474e538: {[W0*features Value[50 x *2]] }
0x7f4d0474e638: {[W0*features+B0 Value[50 x 1 x *2]] }
0x7f4d0474ea68: {[H1 Value[50 x 1 x *2]] }
0x7f4d0474ebc8: {[W1*H1 Value[50 x 1 x *2]] }
0x7f4d0474ed88: {[W1*H1+B1 Value[50 x 1 x *2]] }
0x7f4d0474ef48: {[H2 Value[50 x 1 x *2]] }
0x7f4d0474f108: {[W2*H1 Value[2 x 1 x *2]] }
0x7f4d0474f2c8: {[HLast Value[2 x 1 x *2]] }

Minibatch[0]: ActualMBSize = 603
Written to /tmp/cntk-test-20160804135211.433559/Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

08/04/2016 13:56:41: Action "write" complete.

08/04/2016 13:56:41: __COMPLETED__